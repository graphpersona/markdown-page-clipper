1. [1 Introduction](https://arxiv.org/html/2504.15909v2#S1 "In Synergizing RAG and Reasoning: A Systematic Review")
2. [2 Overview](https://arxiv.org/html/2504.15909v2#S2 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [2.1 Definition](https://arxiv.org/html/2504.15909v2#S2.SS1 "In 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [2.2 Taxonomy](https://arxiv.org/html/2504.15909v2#S2.SS2 "In 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [2.2.1 Synergy Purpose](https://arxiv.org/html/2504.15909v2#S2.SS2.SSS1 "In 2.2. Taxonomy ‚Ä£ 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [2.2.2 Synergy Paradigms](https://arxiv.org/html/2504.15909v2#S2.SS2.SSS2 "In 2.2. Taxonomy ‚Ä£ 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [2.2.3 Synergy Implementation](https://arxiv.org/html/2504.15909v2#S2.SS2.SSS3 "In 2.2. Taxonomy ‚Ä£ 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
3. [3 The purpose of the synergy](https://arxiv.org/html/2504.15909v2#S3 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [3.1 Reasoning-Augmented Retrieval](https://arxiv.org/html/2504.15909v2#S3.SS1 "In 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [3.1.1 Semantic Disparities Between Queries and Documents](https://arxiv.org/html/2504.15909v2#S3.SS1.SSS1 "In 3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [3.1.2 Inflexible Intent Disambiguation](https://arxiv.org/html/2504.15909v2#S3.SS1.SSS2 "In 3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [3.1.3 Inefficient Coordination of Multi-Source Heterogeneous Data](https://arxiv.org/html/2504.15909v2#S3.SS1.SSS3 "In 3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [3.1.4 Incompleteness and Incoherence in Complex Retrieval Tasks](https://arxiv.org/html/2504.15909v2#S3.SS1.SSS4 "In 3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      5. [3.1.5 Trade-offs Between Retrieval Efficiency and Precision](https://arxiv.org/html/2504.15909v2#S3.SS1.SSS5 "In 3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [3.2 Retrieval-Augmented Reasoning](https://arxiv.org/html/2504.15909v2#S3.SS2 "In 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [3.2.1 Knowledge Gap in Multi-step Reasoning](https://arxiv.org/html/2504.15909v2#S3.SS2.SSS1 "In 3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [3.2.2 Reasoning Discontinuity Caused by Domain Knowledge Boundaries](https://arxiv.org/html/2504.15909v2#S3.SS2.SSS2 "In 3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [3.2.3 Search Space Explosion and Local Optima Traps](https://arxiv.org/html/2504.15909v2#S3.SS2.SSS3 "In 3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [3.2.4 Dynamic Knowledge Requirements in Multi-Step Reasoning](https://arxiv.org/html/2504.15909v2#S3.SS2.SSS4 "In 3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      5. [3.2.5 Insufficient Depth and Breadth of Reasoning](https://arxiv.org/html/2504.15909v2#S3.SS2.SSS5 "In 3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
4. [4 Patterns of synergy](https://arxiv.org/html/2504.15909v2#S4 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [4.1 Pre-defined workflow](https://arxiv.org/html/2504.15909v2#S4.SS1 "In 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [4.1.1 Pre-Retrieval Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS1.SSS1 "In 4.1. Pre-defined workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [4.1.2 Post-Retrieval Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS1.SSS2 "In 4.1. Pre-defined workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [4.1.3 Hybrid Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS1.SSS3 "In 4.1. Pre-defined workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [4.2 Dynamic RAG Workflow](https://arxiv.org/html/2504.15909v2#S4.SS2 "In 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [4.2.1 Proactivity-Driven Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS2.SSS1 "In 4.2. Dynamic RAG Workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [4.2.2 Reflection-Driven Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS2.SSS2 "In 4.2. Dynamic RAG Workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [4.2.3 Feedback-Driven Reasoning](https://arxiv.org/html/2504.15909v2#S4.SS2.SSS3 "In 4.2. Dynamic RAG Workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
5. [5 Implementation and Optimization](https://arxiv.org/html/2504.15909v2#S5 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [5.1 Reasoning Process](https://arxiv.org/html/2504.15909v2#S5.SS1 "In 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [5.1.1 LLM CoT](https://arxiv.org/html/2504.15909v2#S5.SS1.SSS1 "In 5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [5.1.2 Special Token Prediction](https://arxiv.org/html/2504.15909v2#S5.SS1.SSS2 "In 5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [5.1.3 Search-Driven Reasoning](https://arxiv.org/html/2504.15909v2#S5.SS1.SSS3 "In 5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [5.1.4 Reasoning on Graph](https://arxiv.org/html/2504.15909v2#S5.SS1.SSS4 "In 5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      5. [5.1.5 External Solver](https://arxiv.org/html/2504.15909v2#S5.SS1.SSS5 "In 5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [5.2 Reasoning Optimization](https://arxiv.org/html/2504.15909v2#S5.SS2 "In 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [5.2.1 Prompt-Based](https://arxiv.org/html/2504.15909v2#S5.SS2.SSS1 "In 5.2. Reasoning Optimization ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [5.2.2 Tuning-Based](https://arxiv.org/html/2504.15909v2#S5.SS2.SSS2 "In 5.2. Reasoning Optimization ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [5.2.3 RL-Based](https://arxiv.org/html/2504.15909v2#S5.SS2.SSS3 "In 5.2. Reasoning Optimization ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
6. [6 Downstream Tasks and Evaluation](https://arxiv.org/html/2504.15909v2#S6 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [6.1 Knowledge-Intensive Tasks](https://arxiv.org/html/2504.15909v2#S6.SS1 "In 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [Limited Challenge](https://arxiv.org/html/2504.15909v2#S6.SS1.SSS0.Px1 "In 6.1. Knowledge-Intensive Tasks ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [Lack of Specificity](https://arxiv.org/html/2504.15909v2#S6.SS1.SSS0.Px2 "In 6.1. Knowledge-Intensive Tasks ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [Task Uniformity](https://arxiv.org/html/2504.15909v2#S6.SS1.SSS0.Px3 "In 6.1. Knowledge-Intensive Tasks ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [Insufficient Dimensions](https://arxiv.org/html/2504.15909v2#S6.SS1.SSS0.Px4 "In 6.1. Knowledge-Intensive Tasks ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [6.2 New Tasks on RAG+Reasoning](https://arxiv.org/html/2504.15909v2#S6.SS2 "In 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [6.2.1 Deep Research](https://arxiv.org/html/2504.15909v2#S6.SS2.SSS1 "In 6.2. New Tasks on RAG+Reasoning ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [6.2.2 PhD (Expert)-Level Complex Reasoning](https://arxiv.org/html/2504.15909v2#S6.SS2.SSS2 "In 6.2. New Tasks on RAG+Reasoning ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   3. [6.3 Challenges and Future Directions](https://arxiv.org/html/2504.15909v2#S6.SS3 "In 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [6.3.1 Complex Domain Tasks](https://arxiv.org/html/2504.15909v2#S6.SS3.SSS1 "In 6.3. Challenges and Future Directions ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [6.3.2 Decision Support and Active Retrieval](https://arxiv.org/html/2504.15909v2#S6.SS3.SSS2 "In 6.3. Challenges and Future Directions ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
7. [7 Cost and Risk](https://arxiv.org/html/2504.15909v2#S7 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [7.1 Cost Trade-off in RAG+Reasoning](https://arxiv.org/html/2504.15909v2#S7.SS1 "In 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [7.1.1 Non-Linear Growth of Computational Resources](https://arxiv.org/html/2504.15909v2#S7.SS1.SSS1 "In 7.1. Cost Trade-off in RAG+Reasoning ‚Ä£ 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [7.1.2 Implicit Token Inflation](https://arxiv.org/html/2504.15909v2#S7.SS1.SSS2 "In 7.1. Cost Trade-off in RAG+Reasoning ‚Ä£ 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [7.1.3 Marginal Decline in Retrieval Efficiency](https://arxiv.org/html/2504.15909v2#S7.SS1.SSS3 "In 7.1. Cost Trade-off in RAG+Reasoning ‚Ä£ 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [7.1.4 Toward a Cost Model Framework](https://arxiv.org/html/2504.15909v2#S7.SS1.SSS4 "In 7.1. Cost Trade-off in RAG+Reasoning ‚Ä£ 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [7.2 Potential Risk of Over-Thinking](https://arxiv.org/html/2504.15909v2#S7.SS2 "In 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
8. [8 Practical Guide](https://arxiv.org/html/2504.15909v2#S8 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [8.1 Domain characteristics](https://arxiv.org/html/2504.15909v2#S8.SS1 "In 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [8.1.1 Finance](https://arxiv.org/html/2504.15909v2#S8.SS1.SSS1 "In 8.1. Domain characteristics ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [8.1.2 Healthcare](https://arxiv.org/html/2504.15909v2#S8.SS1.SSS2 "In 8.1. Domain characteristics ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [8.1.3 Legal Services](https://arxiv.org/html/2504.15909v2#S8.SS1.SSS3 "In 8.1. Domain characteristics ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [8.1.4 Personal Assistants](https://arxiv.org/html/2504.15909v2#S8.SS1.SSS4 "In 8.1. Domain characteristics ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [8.2 Do‚Äôs and Don‚Äôts](https://arxiv.org/html/2504.15909v2#S8.SS2 "In 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [8.2.1 Structured Reasoning Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS1 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [8.2.2 Dynamic Demand-Responsive Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS2 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [8.2.3 Deterministic Decision-Making Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS3 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      4. [8.2.4 Time-Sensitive Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS4 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      5. [8.2.5 Risk-Sensitive Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS5 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      6. [8.2.6 Complex Path Exploration Scenarios](https://arxiv.org/html/2504.15909v2#S8.SS2.SSS6 "In 8.2. Do‚Äôs and Don‚Äôts ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   3. [8.3 Opportunity Points](https://arxiv.org/html/2504.15909v2#S8.SS3 "In 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      1. [8.3.1 Data and Indexing](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS1 "In 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         1. [Cold-Hot Tiered Indexing and Dynamic Context Management](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS1.Px1 "In 8.3.1. Data and Indexing ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         2. [Cross-Institution Knowledge Base Construction](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS1.Px2 "In 8.3.1. Data and Indexing ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         3. [Fine-Grained Layering and Confidence Grading](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS1.Px3 "In 8.3.1. Data and Indexing ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      2. [8.3.2 Models and Methodologies](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS2 "In 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         1. [Event-Driven Active Retrieval](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS2.Px1 "In 8.3.2. Models and Methodologies ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         2. [Spatiotemporal-Aware Retrieval and Association](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS2.Px2 "In 8.3.2. Models and Methodologies ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         3. [Multimodal Fusion in Retrieval and Reasoning](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS2.Px3 "In 8.3.2. Models and Methodologies ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         4. [Dynamic Risk Propagation Modeling and Management](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS2.Px4 "In 8.3.2. Models and Methodologies ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
      3. [8.3.3 Application Services](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS3 "In 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         1. [Validation of Logical Chain Completeness](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS3.Px1 "In 8.3.3. Application Services ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         2. [Intervenable Generation During Reasoning](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS3.Px2 "In 8.3.3. Application Services ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         3. [Risk Decision Interception Firewalls](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS3.Px3 "In 8.3.3. Application Services ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
         4. [Edge-Cloud Collaborative Retrieval and Reasoning](https://arxiv.org/html/2504.15909v2#S8.SS3.SSS3.Px4 "In 8.3.3. Application Services ‚Ä£ 8.3. Opportunity Points ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
9. [9 Future Trends](https://arxiv.org/html/2504.15909v2#S9 "In Synergizing RAG and Reasoning: A Systematic Review")
   1. [9.1 The Integration of RAG and Graph](https://arxiv.org/html/2504.15909v2#S9.SS1 "In 9. Future Trends ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   2. [9.2 Multi-Model Collaboration](https://arxiv.org/html/2504.15909v2#S9.SS2 "In 9. Future Trends ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   3. [9.3 Multi-Modal Collaboration](https://arxiv.org/html/2504.15909v2#S9.SS3 "In 9. Future Trends ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
   4. [9.4 Customized Reinforcement Learning](https://arxiv.org/html/2504.15909v2#S9.SS4 "In 9. Future Trends ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")
10. [10 Conclusion](https://arxiv.org/html/2504.15909v2#S10 "In Synergizing RAG and Reasoning: A Systematic Review")

\useforestlibrary

edges
\useunder\ul

# Synergizing RAG and Reasoning: A Systematic Review

Yunfan Gao
Shanghai Research Institute for Intelligent Autonomous Systems, Tongji UniversityChina
gaoyunfan1602@gmail.com
,
Yun Xiong
Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan UniversityChina
yunx@fudan.edu.cn
,
Yijie Zhong
College of Design and Innovation, Tongji UniversityChina
dun.haski@gmail.com
,
Yuxi Bi
College of Design and Innovation, Tongji UniversityChina
yuxibi@gmail.com
,
Ming Xue
Percena AIChina
mxue@percena.co
¬†and
Haofen Wang
College of Design and Innovation, Tongji UniversityChina
carter.whfcarter@gmail.com

###### Abstract.

Recent breakthroughs in large language models (LLMs), particularly in reasoning capabilities, have propelled Retrieval-Augmented Generation (RAG) to unprecedented levels. By synergizing retrieval mechanisms with advanced reasoning, LLMs can now tackle increasingly complex problems. This paper presents a systematic review of the collaborative interplay between RAG and reasoning, clearly defining ‚Äùreasoning‚Äù within the RAG context. It construct a comprehensive taxonomy encompassing multi-dimensional collaborative objectives, representative paradigms, and technical implementations, and analyze the bidirectional synergy methods. Additionally, we critically evaluate current limitations in RAG assessment, including the absence of intermediate supervision for multi-step reasoning and practical challenges related to cost-risk trade-offs. To bridge theory and practice, we provide practical guidelines tailored to diverse real-world applications. Finally, we identify promising research directions, such as graph-based knowledge integration, hybrid model collaboration, and RL-driven optimization. Overall, this work presents a theoretical framework and practical foundation to advance RAG systems in academia and industry, fostering the next generation of RAG solutions.

‚Ä†‚Ä†copyright: none
![Refer to caption](extracted/6386523/Images/timeline.png)

Figure 1. Timeline of studies on RAG-reasoning synergy. From a technical perspective, the approaches can be categorized into Prompt-Based, Tuning-Based, and RL-Based methods. A notable trend is the increasing use of Reinforcement Learning to enhance RAG systems, particularly following the prosperity of test-time scaling. Meanwhile, Prompt-Based and Tuning-Based methods continue to evolve in parallel, demonstrating that there are multiple pathways to integrating reasoning capabilities into RAG systems.

## 1. Introduction

Recent breakthroughs in Large Language Models (LLMs) like OpenAI O1¬†(Jaech et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib40)) and DeepSeek-R1¬†(Guo et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib26)) have shifted the paradigm from ‚Äùpre-training scaling‚Äù to ‚Äùtest-time scaling‚Äù¬†(Muennighoff et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib64)). Unlike traditional language models that improve via corpus accumulation during pre-training, these models enhance performance in complex tasks‚Äîsuch as mathematical derivation and code generation¬†(He et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib30))‚Äîthrough post-training innovations during the inference phase (e.g., Long-CoT thinking¬†(Chen et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib9))). This shift has led to the emergence of ‚ÄùLarge Reasoning Models‚Äù (LRMs)¬†(Xu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib100)) with advanced internal reasoning abilities.

These advancements have not only boosted basic model capabilities but also opened new avenues for application technologies like Retrieval-Augmented Generation (RAG)¬†(Gao et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib22)). Serving as a key link between language models and external knowledge, RAG overcomes traditional LLMs‚Äô limits in knowledge freshness, domain specificity, and factual accuracy by retrieving real-time non-parametric information and integrating it into the context. This enhances information processing and reduces hallucination risks in knowledge-intensive tasks.

Technological evolution is advancing RAG architectures through innovations like query rewriting¬†(Ma et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib62)), re-ranking¬†(Abdallah et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib2)), and hybrid retrieval¬†(Wang et¬†al., [2024d](https://arxiv.org/html/2504.15909v2#bib.bib89)), creating an Advanced RAG paradigm focused on pre-retrieval optimization and post-retrieval refinement. Modular RAG¬†(Gao et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib23)) further breaks down these systems into component-based, service-oriented architectures, using orchestration to tackle practical challenges.

Despite improvements in query intent recognition and knowledge use, challenges of RAG remain in demanding tasks like deep research and complex decision-making. Key issues include: 1) difficulty capturing intent from ambiguous queries; 2) poor logical coherence in multi-hop reasoning; 3) efficiency limits of traditional retrieval in open domains; and 4) degraded generation quality from noisy retrieved data.

Models like DeepSeek-R1, with strong reasoning capabilities, inspire new directions for RAG systems. As shown in Figure¬†[1](https://arxiv.org/html/2504.15909v2#S0.F1 "Figure 1 ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), recent research explores integrating formal reasoning frameworks with knowledge retrieval. This approach optimizes retrieval through logic-driven query reformulation and uses reasoning to analyze and validate retrieved knowledge, creating cognitive synergy between retrieval and generation. This paradigm aims to overcome conventional limitations, enabling intelligent systems with rigorous logic and reliable knowledge use. From a trend perspective, an increasing number of methods combine reasoning and retrieval abilities through reinforcement learning (RL), marking a new direction in the LRM era. Meanwhile, prompt-based approaches continue to rapidly evolve, with researchers aiming to achieve results through workflow design while keeping model parameters frozen. Notably, sole reliance on tuning methods is steadily decreasing, suggesting limited improvements from additional fine-tuning at this stage.

Traditional RAG is limited by its unidirectional flow (retrieval ‚Üí generation). Integrating reasoning capabilities grants the system greater autonomy, unlocking new possibilities. As shown in Figure¬†[2](https://arxiv.org/html/2504.15909v2#S1.F2 "Figure 2 ‚Ä£ 1. Introduction ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), this integration is poised to drive major breakthroughs, enabling practical use in complex real-world scenarios.

1) From Ambiguous Semantic Matching to Logic-Driven Targeted Retrieval. Traditional RAG relies on semantic similarity for retrieval; however, it is sensitive to phrasing variations. Advanced reasoning allows deep logical analysis of queries (e.g., causal links, conditional constraints) to dynamically refine retrieval strategies¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)). For example, to answer ‚ÄùHow to reduce postoperative infection risks in diabetes patients?‚Äù, the system prioritizes retrieving ‚Äùblood glucose control thresholds‚Äù and ‚Äùantibiotic usage guidelines‚Äù over simply matching ‚Äùdiabetes postoperative care‚Äù. This approach supports multi-hop retrieval by breaking down complex queries into sequential sub-queries while preserving cross-document coherence through reasoning chains.

![Refer to caption](extracted/6386523/Images/advantage.png)

Figure 2. Advantages of Combining RAG with Reasoning

2) From Simple Information Aggregation to Logically Coherent Context Construction. Current RAG systems input all retrieved document chunks into context directly, often causing fragmented or contradictory information that confuses LLMs. Reasoning-enhanced systems integrate evidence chains by logically verifying and inferring causality in retrieved content, filtering conflicts and forming coherent explanations¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)). They also use dynamic knowledge completion to detect missing logical links, prompting iterative retrieval or inference to fill gaps¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)).

3) From Simple and Single-Turn QA to Systemic Decision Support. Traditional RAG performs well in factual QA¬†(Petroni et¬†al., [2020](https://arxiv.org/html/2504.15909v2#bib.bib66)) but struggles with multi-step and complex decision-making. Reasoning-integrated systems produce structured reasoning output, enhancing multi-objective optimization to balance retrieval breadth and solution feasibility under various constraints. For example, multiple constraints under different conditions in engineering construction plans¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)), and the formulation of diagnosis and treatment plans for various diseases in the medical field¬†(Zhao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib106)).

4) From Indiscriminate Retrieval to Intelligent Resource Allocation. Traditional RAG retrieves documents for all queries, regardless of complexity. Reasoning-enhanced systems use on-demand retrieval, handling simple queries with direct generation and complex ones with multi-round retrieval to reduce latency¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)). Dynamic retrieval pruning uses pre-reasoning predictions to target key information, minimizing unnecessary document and graph traversal¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)).

5) From Passive Knowledge Tool to Proactive Cognitive Assistant. Advancing beyond reactive knowledge retrieval, reasoning-enhanced systems can proactively serve users by asking clarifying questions and anticipating implicit needs. This shift enables human-like assistants that integrate memory, reasoning, and decision-making, proving especially valuable for complex tasks such as deep research¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44)), business analytics¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)), personal assistant¬†(Zhong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib108)) and urban planning¬†(Wang et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib86)).

However, the synergistic pathway between RAG and reasoning requires more than simply replacing conventional generative LLMs with LRM modules. It necessitates deep integration of technological evolution insights from LRM - achieved through reconstructing knowledge retrieval mechanisms and strengthening reasoning-generation collaborative linkages - to enable system-level enhancement of cognitive capabilities within the RAG architecture.

Therefore, this paper aims to address the pivotal and forward-looking research question of ‚Äùhow RAG systems can synergize with reasoning capabilities‚Äù. We systematically review current studies after 2024 while establishing explicit definitions for reasoning within RAG contexts. Building on this foundation, we provide an in-depth taxonomy and analysis of the objectives, typical patterns, and implementations underlying RAG-reasoning integration, clarifying key technological trajectories and critical breakthroughs.

As RAG technology enters its next developmental phase, downstream task complexity has escalated significantly - particularly evident in emerging challenges like Deep Research¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107)). These advanced applications not only demand enhanced reasoning capacities but also drive RAG‚Äôs expansion into multimodal, cross-domain, and dynamic environments. However, while the integration of reasoning capabilities demonstrably improves complex task performance, existing research frequently overlooks associated computational overheads and potential risks. Through systematic examination of these operational constraints and analysis of industry applications, we propose practical guidelines for multiple real-world scenarios with diverse requirements.

Finally, we outline future research directions grounded in current technological evolution, including: 1) RAG-graph architecture integration, 2) coordinated multimodal reasoning frameworks, 3) hybrid model collaboration, and 4) RL optimization specifically designed for RAG systems. This work establishes both theoretical foundations and practical roadmaps for subsequent research in this evolving field.

The contributions of this paper can be summarized as follows:

* ‚Ä¢

  Pioneering Review. This work represents the first comprehensive survey focusing on the integration of RAG with reasoning, offering novel insights and forward-looking guidance for advancing this emerging research frontier.
* ‚Ä¢

  Systematic Taxonomy. We present a multi-dimensional framework to systematically examine the objectives, paradigms, and methodologies for combining RAG with reasoning capabilities, establishing clear classification criteria across technical dimensions.
* ‚Ä¢

  Practical Guidance. Beyond theoretical exploration, we critically discuss the additional cost and potential risks associated with the introduction of reasoning, accompanied by an actionable Practical Guide for real-world scenarios.
* ‚Ä¢

  Open Resource Platform111<https://openrag.notion.site/open-rag-base?pvs=4> Through the OpenRAG platform, we provide a rich, multi-dimensional review of related work, which allows readers to quickly search and compare different methods.

## 2. Overview

This chapter establishes a conceptual framework for the paper along two key dimensions. First, it formally defines ‚Äùreasoning‚Äù and distinguishes it from ‚Äùinference.‚Äù Second, it organizes a taxonomy of synergy mechanisms between ‚ÄùRAG and Reasoning.‚Äù To construct a clear cognitive pathway, we address three progressive research questions:

* ‚Ä¢

  Why synergize RAG and reasoning?
* ‚Ä¢

  What are their typical collaboration paradigms?
* ‚Ä¢

  How can this integration be realized?

### 2.1. Definition

The definition of reasoning in modern AI systems remains an evolving construct, particularly within the context of LRMs exemplified by DeepSeek R1 and OpenAI O1. Here, under the scope of LLMs, we formalize reasoning as a structured, multi-step process that dynamically decomposes complex problems, generates intermediate hypotheses, and iteratively refines solutions through logical and evidence-based transformations. Mathematically, let a reasoning process ‚Ñõ‚Ñõ\mathcal{R}caligraphic\_R be defined as a tuple ‚ü®ùí¶p,ùí¶r,ùíÆt,Œ¶‚ü©

subscriptùí¶ùëùsubscriptùí¶ùëüsubscriptùíÆùë°Œ¶\langle\mathcal{K}\_{p},\mathcal{K}\_{r},\mathcal{S}\_{t},\Phi\rangle‚ü® caligraphic\_K start\_POSTSUBSCRIPT italic\_p end\_POSTSUBSCRIPT , caligraphic\_K start\_POSTSUBSCRIPT italic\_r end\_POSTSUBSCRIPT , caligraphic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , roman\_Œ¶ ‚ü©, where ùí¶psubscriptùí¶ùëù\mathcal{K}\_{p}caligraphic\_K start\_POSTSUBSCRIPT italic\_p end\_POSTSUBSCRIPT denotes parametric knowledge embeddings, ùí¶rsubscriptùí¶ùëü\mathcal{K}\_{r}caligraphic\_K start\_POSTSUBSCRIPT italic\_r end\_POSTSUBSCRIPT represents retrieved contextual knowledge, ùíÆt={s0,s1,‚Ä¶,sn}subscriptùíÆùë°subscriptùë†0subscriptùë†1‚Ä¶subscriptùë†ùëõ\mathcal{S}\_{t}=\{s\_{0},s\_{1},\ldots,s\_{n}\}caligraphic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = { italic\_s start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT , italic\_s start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , ‚Ä¶ , italic\_s start\_POSTSUBSCRIPT italic\_n end\_POSTSUBSCRIPT } constitutes the evolving state sequence with s0subscriptùë†0s\_{0}italic\_s start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT as the initial query and snsubscriptùë†ùëõs\_{n}italic\_s start\_POSTSUBSCRIPT italic\_n end\_POSTSUBSCRIPT as the final response, and Œ¶:ùíÆi√óùí¶p√óùí¶r‚ÜíùíÆi+1:Œ¶‚ÜísubscriptùíÆùëñsubscriptùí¶ùëùsubscriptùí¶ùëüsubscriptùíÆùëñ1\Phi:\mathcal{S}\_{i}\times\mathcal{K}\_{p}\times\mathcal{K}\_{r}\rightarrow%
\mathcal{S}\_{i+1}roman\_Œ¶ : caligraphic\_S start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT √ó caligraphic\_K start\_POSTSUBSCRIPT italic\_p end\_POSTSUBSCRIPT √ó caligraphic\_K start\_POSTSUBSCRIPT italic\_r end\_POSTSUBSCRIPT ‚Üí caligraphic\_S start\_POSTSUBSCRIPT italic\_i + 1 end\_POSTSUBSCRIPT defines the state transition function.

The reasoning process exhibits three defining characteristics. First, it is inherently multi-step, systematically decomposing complex problems into intermediate cognitive states (e.g., sub-question generation or temporary conclusions) rather than pursuing direct input-output mapping. Second, it generates novel knowledge or facts ‚Äî synthesizing implicit relationships, deriving latent constraints, or reformulating problems in ways not explicitly present in the initial input or parametric memory (e.g., transforming ‚ÄùIs A greater than B?‚Äù into comparative subquestions about A and B‚Äôs attributes). Crucially, these representations are not merely retrieved but dynamically constructed through the reasoning trajectory. Third, the process is teleological ‚Äî its architecture and termination conditions are explicitly optimized for complex problem resolution, where complexity is measured by the necessity of state transitions or the insufficiency of direct retrieval from either parametric (ùí¶psubscriptùí¶ùëù\mathcal{K}\_{p}caligraphic\_K start\_POSTSUBSCRIPT italic\_p end\_POSTSUBSCRIPT) or external (ùí¶rsubscriptùí¶ùëü\mathcal{K}\_{r}caligraphic\_K start\_POSTSUBSCRIPT italic\_r end\_POSTSUBSCRIPT) knowledge sources. This stands in stark contrast to atomic inference, which lacks such deliberate state construction and goal-aware iteration.

The distinction between reasoning and inference manifests most saliently in their computational signatures. While inference ‚Ñê‚Ñê\mathcal{I}caligraphic\_I constitutes a single-step conditional probability computation P‚Å¢(y|x)=‚àèt=1TP‚Å¢(yt|x,y<t)ùëÉconditionalùë¶ùë•superscriptsubscriptproductùë°1ùëáùëÉconditionalsubscriptùë¶ùë°

ùë•subscriptùë¶absentùë°P(y|x)=\prod\_{t=1}^{T}P(y\_{t}|x,y\_{<t})italic\_P ( italic\_y | italic\_x ) = ‚àè start\_POSTSUBSCRIPT italic\_t = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_T end\_POSTSUPERSCRIPT italic\_P ( italic\_y start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | italic\_x , italic\_y start\_POSTSUBSCRIPT < italic\_t end\_POSTSUBSCRIPT ), reasoning ‚Ñõ‚Ñõ\mathcal{R}caligraphic\_R implements a meta-process coordinating multiple inference calls through explicit state management ‚Ñõ‚Å¢(x)=Œ¶1‚àòŒ¶2‚àò‚ãØ‚àòŒ¶n‚Å¢(x)‚Ñõùë•subscriptŒ¶1subscriptŒ¶2‚ãØsubscriptŒ¶ùëõùë•\mathcal{R}(x)=\Phi\_{1}\circ\Phi\_{2}\circ\cdots\circ\Phi\_{n}(x)caligraphic\_R ( italic\_x ) = roman\_Œ¶ start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT ‚àò roman\_Œ¶ start\_POSTSUBSCRIPT 2 end\_POSTSUBSCRIPT ‚àò ‚ãØ ‚àò roman\_Œ¶ start\_POSTSUBSCRIPT italic\_n end\_POSTSUBSCRIPT ( italic\_x ). This multi-phase architecture enables systematic error correction through backtracking mechanisms and dynamic retrieval refinement ‚Äî features fundamentally absent in conventional inference pipelines. The operational boundary emerges when state transitions involve explicit symbolic manipulation (equation restructuring in mathematical reasoning) or knowledge graph traversal (temporal reasoning over retrieved events), distinguishing true reasoning from mere multi-step inference.

{forest}

for tree=
forked edges,
grow‚Äô=0,
draw,
rounded corners,
node options=align=center,
calign=edge midpoint,
font=,
[The Synergy of RAG and Reasoning, fill=black!10,rotate=90,text width=6cm,font=[Purpose ¬ß[3](https://arxiv.org/html/2504.15909v2#S3 "3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.5cm, for tree=fill=red!20,font=[ Reasoning-Augmented Retrieval

(Better Retrieval) ¬ß[3.1](https://arxiv.org/html/2504.15909v2#S3.SS1 "3.1. Reasoning-Augmented Retrieval ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=3.5cm
[ ARM¬†(Chen et¬†al., [2025f](https://arxiv.org/html/2504.15909v2#bib.bib8)); AdaptiveRAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42));
FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)); LevelRAG¬†(Zhang et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib104)); OmniThink¬†(Xi et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib95)); PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)); SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)); UAR¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)); O1-Embedeer¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)); ITER-RETGEN¬†(Shao et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib69));
HiRAG¬†(Zhang et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib103));
MetaRAG¬†(Zhou et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib109));
MMOA-RAG¬†(Chen et¬†al., [2025e](https://arxiv.org/html/2504.15909v2#bib.bib13));
ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17));
DeepResearcher¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107));
ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50));
FRAG¬†(Gao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib24));
PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74));
Insight-RAG¬†(Pezeshkpour and Hruschka, [2025](https://arxiv.org/html/2504.15909v2#bib.bib67));
ChainRAG¬†(Zhu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib111));
FG-RAG¬†(Hong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib33));
MCTS-RAG¬†(Hu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib37));
REAPER¬†(Joshi et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib47));
DeepNote¬†(Wang et¬†al., [2024e](https://arxiv.org/html/2504.15909v2#bib.bib85)),
text width=10.0cm, node options=align=left
]
]
[ Retrieval-Augmented Reasoning

(Better Reasoning) ¬ß[3.2](https://arxiv.org/html/2504.15909v2#S3.SS2 "3.2. Retrieval-Augmented Reasoning ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=3.5cm
[ ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)); AgenticReasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93));
CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84)); CR-planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)); DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)); Deepsolution¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)); KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59)); OpenRAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39)); PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83)); R1-Seacher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)); RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97)); ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76));
ReSearch¬†(Chen et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib7));
MedRAG¬†(Zhao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib106));
RARE¬†(Tran et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib78));
RARE(Wang et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib91));
RetroRAG¬†(Xiao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib96));
KG-RAR¬†(Wu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib94));
RetrievalPRM¬†(Zhu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib110));
MRD-RAG¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12));
Search-O1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52));
StePO-Rec¬†(Bi et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib6)),
text width=10.0cm, node options=align=left
]
]
]
[Paradigms ¬ß[4](https://arxiv.org/html/2504.15909v2#S4 "4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.5cm, for tree=fill=orange!20,font=[Pre-defined Workflow ¬ß¬†[4.1](https://arxiv.org/html/2504.15909v2#S4.SS1 "4.1. Pre-defined workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.8cm
[Reasoning in Pre-Retrieval,text width=2.1cm
[
LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35)); O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)); planRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)); UAR¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15));
MMOA-RAG¬†(Chen et¬†al., [2025e](https://arxiv.org/html/2504.15909v2#bib.bib13));
MedRAG¬†(Zhao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib106));
FRAG¬†(Gao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib24));
Insight-RAG¬†(Pezeshkpour and Hruschka, [2025](https://arxiv.org/html/2504.15909v2#bib.bib67));
ChainRAG¬†(Zhu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib111));
RetrievalPRM¬†(Zhu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib110));
REAPER¬†(Joshi et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib47));
AdaptiveRAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)),
text width=8.2cm, node options=align=left
]
]
[Reasoning in Post-Retrieval,text width=2.1cm
[
ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)); ARM¬†(Chen et¬†al., [2025f](https://arxiv.org/html/2504.15909v2#bib.bib8));
MRD-RAG¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12));
FG-RAG¬†(Hong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib33));
ToG2¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61)),
text width=8.2cm, node options=align=left
]
]
[Hybrid Reasoning,text width=2.1cm
[
IR-COT¬†(Trivedi et¬†al., [2022a](https://arxiv.org/html/2504.15909v2#bib.bib79));
FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51));
ITER-RETGEN¬†(Shao et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib69));
LevelRAG¬†(Zhang et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib104));
HiRAG¬†(Zhang et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib103));
MetaRAG¬†(Zhou et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib109));
RetroRAG¬†(Xiao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib96));
KG-RAR¬†(Wu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib94));
DeepNote¬†(Wang et¬†al., [2024e](https://arxiv.org/html/2504.15909v2#bib.bib85)),
text width=8.2cm, node options=align=left
]
]
]
[Dynamic Workflow ¬ß[4.2](https://arxiv.org/html/2504.15909v2#S4.SS2 "4.2. Dynamic RAG Workflow ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.8cm
[Proactivity-Driven Reasoning,text width=2.2cm
[
AgenticReasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93));
DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25));
CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84));
Co-STORM¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44));
PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83));
Search-O1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52));
R1-Searcher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)),
text width=8.1cm, node options=align=left
]
]
[Reflection-Driven Reasoning,text width=2.2cm
[
Flare¬†(Jiang et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib46));
OpenRAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39));
WriteHere¬†(Xiong et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib99));
ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50));
Self-RAG¬†(Asai et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib4)),
text width=8.1cm, node options=align=left
]
]
[Feedback-Driven Reasoning,text width=2.2cm
[
SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21));
CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53));
MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98));
DeepSolution¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55));
RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97));
ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17));
ReSearch¬†(Chen et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib7));
RARE¬†(Tran et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib78));
DeepResearcher¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107));
PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74));
MCTS-RAG¬†(Hu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib37));
KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59)),
text width=8.1cm, node options=align=left
]
]
]
]
[Implementation ¬ß[5](https://arxiv.org/html/2504.15909v2#S5 "5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.5cm, for tree=fill=blue!20,font=[Resoning Method ¬ß[5.1](https://arxiv.org/html/2504.15909v2#S5.SS1 "5.1. Reasoning Process ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.8cm,
[LLM/CoT, text width=2.0cm
[
ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101));
AdaptiveRAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42));
O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102));
DeepNote¬†(Wang et¬†al., [2024e](https://arxiv.org/html/2504.15909v2#bib.bib85));
HiRAG¬†(Zhang et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib103));
MetaRAG¬†(Zhou et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib109));
MMOA-RAG¬†(Chen et¬†al., [2025e](https://arxiv.org/html/2504.15909v2#bib.bib13));
RetroRAG¬†(Xiao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib96));
PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74));
KG-RAR¬†(Wu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib94));
MRD-RAG¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12));
PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)),
text width=8.2cm, node options=align=left
]
]
[Special Token Prediction, text width=2.0cm
[
Self-RAG¬†(Asai et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib4));
SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21));
OpenRAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39));
R1-Searcher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73));
ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17));
ReSearch¬†(Chen et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib7));
ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50));
Search-O1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)),
text width=8.2cm, node options=align=left
]
]
[Search-Driven Reasoning, text width=2.0cm
[
OminiThink¬†(Xi et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib95));
DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25));
CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84));
DeepSolution¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55));
ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76));
KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59));
WriteHere¬†(Xiong et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib99));
RARE¬†(Tran et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib78));
MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98));
StePO-Rec¬†(Bi et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib6)),
text width=8.2cm, node options=align=left
]
]
[Reasoning on Graph, text width=2.0cm
[
FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51));
ToG2¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61));
LighRAG¬†(Guo et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib28));
FRAG¬†(Gao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib24));
FG-RAG¬†(Hong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib33));
MedRAG¬†(Zhao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib106)),
text width=8.2cm, node options=align=left
]
]
[External Solver,text width=2.0cm
[
ARM¬†(Chen et¬†al., [2025f](https://arxiv.org/html/2504.15909v2#bib.bib8)),
text width=8.2cm, node options=align=left
]
]
]
[Optimization ¬ß[5.2](https://arxiv.org/html/2504.15909v2#S5.SS2 "5.2. Reasoning Optimization ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), text width=2.8cm, for tree=fill=blue!20
[Prompt-Based, text width=2.0cm
[
Co-STORM¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44));
Agentic Reasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93));
FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51));
PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49));
HiRAG¬†(Zhang et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib103));
MetaRAG¬†(Zhou et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib109));
MedRAG¬†(Zhao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib106));
RARE¬†(Tran et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib78));
ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50));
RetroRAG¬†(Xiao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib96));
FRAG¬†(Gao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib24));
KG-RAR¬†(Wu et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib94));
MRD-RAG¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12));
FG-RAG¬†(Hong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib33));
MCTS-RAG¬†(Hu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib37));
DeepSolution¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55));
StePO-Rec¬†(Bi et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib6)),
text width=8.2cm, node options=align=left
]
]
[Tuning-Based, text width=2.0cm
[
KBQA-Q1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59));
O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102));
DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25));
CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84));
MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98));
RetrievalPRM¬†(Zhu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib110));
REAPER¬†(Joshi et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib47));
RARE(Wang et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib91));
UAR¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)),
text width=8.2cm, node options=align=left
]
]
[RL-Based, text width=2.0cm
[PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83));
LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35));
RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97));
ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76));
SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21));
CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53));
DeepRetrieval¬†(Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43));
DeepNote¬†(Wang et¬†al., [2024e](https://arxiv.org/html/2504.15909v2#bib.bib85));
MMOA-RAG¬†(Chen et¬†al., [2025e](https://arxiv.org/html/2504.15909v2#bib.bib13));
ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17));
ReSearch¬†(Chen et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib7));
DeepResearcher¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107));
PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74));
R1-Search¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)),
text width=8.2cm, node options=align=left
]
]
]
]
]

Figure 3. A structured taxonomy of synthesizing RAG and Reasoning.

### 2.2. Taxonomy

Integrating RAG with reasoning marks a paradigm shift in tackling complex knowledge-intensive tasks. This work develops a hierarchical taxonomy (Figure¬†[3](https://arxiv.org/html/2504.15909v2#S2.F3 "Figure 3 ‚Ä£ 2.1. Definition ‚Ä£ 2. Overview ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")) based on three key questions: why reasoning is needed with RAG (Purpose), how they structurally interact (Paradigm), and what methods enable effective integration (Implementation). This framework guides readers through the technical innovations in later chapters, providing a clear conceptual path without premature technical details, and highlighting the field‚Äôs evolutionary logic, avoiding delving prematurely into specific technical details.

#### 2.2.1. Synergy Purpose

Integrating reasoning with RAG addresses the limitations of traditional RAG systems, which struggle with multi-step logic, contextual adaptation, and implicit knowledge synthesis due to reliance on superficial semantic matching and fixed knowledge limits. Adding reasoning enables dynamic retrieval planning, logical verification of evidence, and insight generation beyond retrieved data through abductive or counterfactual reasoning. At the same time, the introduction of external knowledge retrieval also helps alleviate reasoning interruptions caused by the knowledge limitations of LRM and reduces the likelihood of hallucinations. This integration occurs in two main ways: Reasoning-Augmented Retrieval, where inference drives context-aware information gathering; Retrieval-Augmented Reasoning, where external knowledge supports and expands the model‚Äôs deductive abilities.

#### 2.2.2. Synergy Paradigms

Building upon the above necessity, our taxonomy categorizes RAG+Reasoning systems along the axis of procedural dynamism. Pre-defined workflows employ fixed templates that systematically alternate between retrieval and reasoning phases, with intervention points predetermined at *pre-retrieval reasoning* (e.g., query decomposition), *post-retrieval reasoning* (e.g., evidence synthesis), or *hybrid stages*. While offering operational transparency, these architectures exhibit limited adaptability to emergent task complexities. In contrast, dynamic workflows implement state-contingent reasoning processes where retrieval actions are conditionally triggered through continuous system introspection. This paradigm further branches into *Proactivity-Driven* strategies (self-initiated knowledge requests), *Reflection-driven* mechanisms (error-corrective retrieval based on intermediate result analysis), and *Feedback-driven* approaches (environmental reward signals or external model evaluations). The progression from static to dynamic architectures reflects the field‚Äôs maturation toward human-like contextual adaptation in open-world problem-solving.

#### 2.2.3. Synergy Implementation

Operationalizing these synergies requires innovations across reasoning and retrieval strategies. Foundational reasoning architectures span LLM-Based like COT, search-based hypothesis generation (tree search, Monte Carlo methods), symbolic solver integration, and graph-structured multi-hop inference. These capabilities are further enhanced through three principal augmentation strategies: prompt-based techniques that utilize natural language templates and special token (e.g., ¬°Plan¬ø, ¬°Verify¬ø) to steer model behavior, tuning-based methods that inject domain-specific knowledge or distill reasoning capability, and RL-based frameworks that optimize retrieval-reasoning policies through outcome reward models (ORM) or process reward models (PRM). The alignment between these methodologies and the proposed taxonomy is critical‚Äîstatic workflows predominantly rely on predictable prompt-guided reasoning chains, whereas dynamic systems increasingly integrate search-based exploration or solver-augmented strategies to navigate evolving state spaces.

Overall, this tripartite taxonomy‚Äîmotivational drivers, architectural paradigms, and implementation methodologies‚Äîestablishes a unified lens for analyzing RAG+Reasoning systems. Subsequent chapters will elaborate on each stratum, progressively revealing how these conceptual distinctions translate into technical innovations that push the boundaries of machine intelligence.

## 3. The purpose of the synergy

![Refer to caption](extracted/6386523/Images/purpose.png)

Figure 4. The purpose of the synergy between RAG and reasoning

The integration of RAG and reasoning marks a crucial advancement in enhancing LLMs‚Äô problem-solving abilities. Their true potential lies not in isolated use but in their synergy, which overcomes key limitations in retrieval and reasoning. This section explains the main motivations for combining RAG with reasoning, emphasizing two primary benefits: (1) enhancing retrieval accuracy and flexibility through reasoning, and (2) reinforcing complex reasoning by using context-rich retrieved knowledge. Figure¬†[4](https://arxiv.org/html/2504.15909v2#S3.F4 "Figure 4 ‚Ä£ 3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review") illustrates these collaborative aims and the limitations they address.

The first key benefit is Reasoning-Augmented Retrieval, where reasoning improves the retrieval process. Traditional RAG systems struggle with query formulation, relevance assessment, and iterative refinement‚Äîtasks needing logical and contextual analysis. Reasoning enables adaptive retrieval through dynamic query expansion, ambiguity resolution, and multi-hop evidence aggregation, overcoming the limits of keyword- or embedding-based methods and aligning retrieval with the task‚Äôs reasoning demands.

The second benefit is Retrieval-Augmented Reasoning, where external knowledge supplements the limitations of purely parametric LLM reasoning. Even advanced models face hallucination, knowledge gaps, and compositional challenges alone. Retrieval grounds reasoning in up-to-date, domain-specific, or rare information absent from model weights, crucial for explainability, multi-step deduction, and integrating diverse sources.

Together, combining RAG and reasoning fills fundamental gaps in both techniques. By enhancing retrieval via reasoning and strengthening reasoning through retrieval, it broadens LLMs‚Äô capacity to address complex real-world problems.

### 3.1. Reasoning-Augmented Retrieval

Reasoning-Augmented Retrieval (RAR) represents a significant advancement in information retrieval by integrating multi-step reasoning to dynamically enhance retrieval quality. Unlike traditional methods that depend on static semantic matching, RAR creates a cognitive feedback loop mimicking human iterative reasoning, surpassing the limitations of simple ‚Äùquery-document‚Äù interactions.

RAR‚Äôs effectiveness stems from several key features. It often uses on-demand retrieval, where reasoning‚Äîevaluating intent clarity, knowledge state, and temporal factors‚Äîguides adaptive search initiation, reducing redundancies present in fixed triggers (e.g., UAR‚Äôs classifier¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15))). It improves semantic alignment by inferring implicit query logic such as business rules or entity relationships to generate precise retrieval requests aligned with data schemas (e.g., PlanRAG‚Äôs plan-retrieval loops¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49))). RAR also applies multi-step iterative refinement, using intermediate reasoning outputs (e.g., chain-of-thought, partial answers¬†(Trivedi et¬†al., [2022a](https://arxiv.org/html/2504.15909v2#bib.bib79))) to recursively reformulate queries in a closed-loop system essential for resolving multi-hop dependencies¬†(Shao et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib69)). Furthermore, it adapts to specific domains by tailoring retrieval to vertical contexts (e.g., financial or medical) and balances efficiency and precision through lightweight reasoning strategies (e.g., AdaptiveRAG‚Äôs complexity-based selection¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42))).

Traditional retrieval systems, effective for simple queries, struggle with complex information needs due to rigid designs favoring static matching over dynamic reasoning, limiting their adaptability to changing contexts and diverse data. RAR primarily addresses five core challenges inherent in these conventional methods.

#### 3.1.1. Semantic Disparities Between Queries and Documents

A key challenge lies in the mismatch between user queries and documents‚Äîwhether due to differing expression styles (professional jargon vs. casual language) or implicit contextual gaps‚Äîmaking direct semantic matching unreliable. Importantly, high similarity does not guarantee true relevance, as documents may share keywords or surface features without addressing the underlying intent or logic of the query. Retrieval models must therefore understand deeper semantics beyond superficial similarity.Domain adaptation further complicates this issue. To overcome these gaps, approaches such as reasoning-augmented embeddings (O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)) enriches queries with inferred ‚Äúthinking‚Äù text), feedback-driven rewriting (SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)) dynamically refines queries based on retrieved results), and pre-planning (PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) extracts business rules to generate SQL queries aligned with database schemas) help better capture domain-specific semantics and ensure relevance beyond mere similarity.

#### 3.1.2. Inflexible Intent Disambiguation

Traditional RAG methods rely on fixed embedding similarity strategies , which fail to dynamically interpret the implicit intent behind complex queries (e.g., multi-hop reasoning or domain-specific requirements). User queries often exhibit semantic complexity that far exceeds their surface text‚Äîfor instance, a request to ‚Äùoptimize supply chain costs‚Äù may require correlating disparate database fields not explicitly mentioned.
Static retrieval methods lack the adaptability to capture such dynamically evolving information needs. A critical limitation lies in intent dynamicity: as contextual understanding expands, traditional systems generate fixed retrieval results based solely on the initial query. Furthermore, semantic representation limitations of dense retrieval models (e.g., BERT-based models) hinder their ability to encode intricate semantic relationships (e.g., irony, metaphors), leading to misaligned results. Current approaches attempt to mitigate these issues through multi-step intent decomposition (e.g., LevelRAG‚Äôs high-level searcher breaks complex queries into multi-hop sub-queries¬†(Zhang et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib104))) and dynamic query reformulation (e.g., LeReT‚Äôs reinforcement learning generates diversified query candidates¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35))), iteratively refining retrieval strategies to align with document content.

#### 3.1.3. Inefficient Coordination of Multi-Source Heterogeneous Data

Retrieval from diverse sources‚Äîtext, tables, graphs, web, and APIs‚Äîoften produces fragmented results due to a lack of global reasoning. The key challenge is modal heterogeneity: different retrieval techniques (dense retrieval for text, SQL for tables, GQL for graphs) operate independently without unified coordination. For example, experiments show standard RAG methods (like dense retrieval with query decomposition) yield only 32.7% perfect recall and 40.9% F1 on the OTT-QA dataset. These outcomes reveal the limitations of traditional approaches in aligning textual queries with structured tables‚Äîsuch as failing to link concepts like ‚ÄùK-12 student free rates‚Äù in text to related ‚Äùeducation expenditure‚Äù columns when not explicitly mentioned. Additionally, disconnected entity matching (e.g., relating ‚Äùcompany revenue‚Äù in text to financial tables) worsens inefficiencies, as conventional methods depend on semantic similarity and overlook domain-specific relationships and exact-value matches. Advanced techniques‚Äîsuch as reasoning-driven alignment (ARM‚Äôs N-gram constraints for cross-modal entity decoding¬†(Chen et¬†al., [2025f](https://arxiv.org/html/2504.15909v2#bib.bib8))) and unified semantic spaces (LevelRAG‚Äôs shared multi-modal representations¬†(Zhang et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib104)))‚Äîenable more effective, integrated retrieval.

#### 3.1.4. Incompleteness and Incoherence in Complex Retrieval Tasks

Single-step retrieval systems fall short in complex multi-hop reasoning tasks, such as deducing entity chains or conducting decision analysis. Traditional static retrieval conflicts with multi-step cognitive needs, resulting in three main issues: 1) Path dependency, where later retrievals rely on information from earlier steps (e.g., finding ‚Äùthe most populous county in California‚Äù before its education policies), but conventional systems lack state management; 2) Error propagation,early retrieval errors cause mistakes in intermediate results, which then affect the next round of retrieval; 3) Semantic inflexibility of fixed queries, which cannot adapt to dynamic concepts like entity aliases or relational predicates.

Advanced methods address these flaws through integrated strategies. PlanRAG uses iterative ‚Äùplan-retrospect-replan‚Äù cycles to trigger sub-queries when gaps arise. Reinforcement learning in LeReT improves query generation via reward-driven path selection. Likewise, ITER-RETGEN rebuilds follow-up queries using intermediate answers (e.g., ‚Äùaward recipient‚Äôs height‚Äù) to resolve multi-hop dependencies.

#### 3.1.5. Trade-offs Between Retrieval Efficiency and Precision

Complex scenarios face a tension between exhaustive retrieval, which is computationally costly, and restricted retrieval, which risks information loss. Expanding retrieval blindly inflates costs (e.g., LLM API calls) without ensuring relevance. Simple queries suffer from unnecessary multi-step retrieval, wasting resources, while complex queries face quality risks if retrieval is too limited. Adaptive approaches like complexity-aware routing (Adaptive-RAG‚Äôs lightweight classifier allocates retrieval budgets¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42))) and cost-sensitive training (SmartRAG‚Äôs reinforcement learning balances quality and steps¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21))) dynamically manage this trade-off.

In summary, Reasoning-Augmented Retrieval overcomes traditional RAG‚Äôs limitations in dynamic triggering, semantic alignment, multi-hop support, domain adaptation, and efficiency trade-offs by deeply integrating reasoning into the retrieval process. Its key innovation is a bidirectional enhancement between reasoning and retrieval‚Äîreasoning refines retrieval strategies, while retrieval supports iterative reasoning‚Äîjointly boosting accuracy and efficiency in complex information tasks.

### 3.2. Retrieval-Augmented Reasoning

Retrieval-Augmented Reasoning (ReAR) combines external knowledge retrieval with inherent model reasoning to overcome failures from knowledge gaps or logical discontinuities in complex tasks. Unlike traditional RAG methods that retrieve information once, ReAR uses an iterative, context-sensitive retrieval that continuously provides relevant data to support multi-step reasoning. This approach is crucial for tasks needing strict logic, such as mathematical proofs, where intermediate steps require specific theorems or lemmas. By making retrieval an adaptive, ongoing process rather than a one-time step, ReAR strengthens each reasoning stage with accurate, current information, improving the overall inference‚Äôs reliability and robustness.

ReAR‚Äôs core feature is dynamic knowledge supplementation, generating retrieval queries in real-time based on the evolving reasoning context. This overcomes the limits of single-round retrieval by enabling knowledge refinement at each step, as seen in process supervision frameworks like RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97)). ReAR also improves reasoning paths using methods like search space compression‚Äîfor example, MCTS-guided heuristics in KBQA‚Äîand structured feedback from diverse sources like knowledge graphs¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98)). These techniques maintain logical consistency while reducing irrelevant or conflicting information. Importantly, ReAR adapts well across domains, supporting precise knowledge retrieval and tool use for specialized tasks such as industrial problem-solving in PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83)) or scientific reasoning¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107)).

By integrating retrieval as an active part of the reasoning loop, ReAR addresses LLMs‚Äô temporal and depth constraints, ensuring adherence to domain-specific and time-sensitive requirements. This close coupling turns external knowledge into an on-demand resource, creating a closed-loop system that enhances the model‚Äôs ability to handle complex, knowledge-intensive problems. Specifically, ReAR seeks to address the following limitations and challenges:

#### 3.2.1. Knowledge Gap in Multi-step Reasoning

In long-range reasoning, missing intermediate knowledge often breaks logical chains, especially in industrial and scientific contexts requiring multi-source data integration (e.g., text, tables, time-series). Static retrieval methods worsen this by not adapting to the reasoning process‚Äôs changing needs. ReAR techniques address this with chained retrieval, as in CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84)), which breaks multi-hop questions into sequential sub-queries (e.g., retrieving ‚Äùevent causes‚Äù then their ‚Äùimpacts‚Äù), systematically linking knowledge. Reasoning-state-aware retrieval, used in FLARE¬†(Jiang et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib46)), predicts future information needs by generating interim prompts (e.g., ‚Äùthe next step requires discussion of ‚Ä¶‚Äù), enabling dynamic query construction that preserves coherence. Together, these approaches resolve the conflict between discrete retrieval and continuous reasoning.

#### 3.2.2. Reasoning Discontinuity Caused by Domain Knowledge Boundaries

Reasoning discontinuity arises from LLMs‚Äô limited knowledge, struggling with specialized domains (e.g., semiconductor design in PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83))) and real-time data (e.g., medical parameters in Agentic Reasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93))). End-to-end models often produce factual errors, while traditional RAG methods fail to retrieve deep professional knowledge due to coarse retrieval, especially with complex data like tables,charts and images.

ReAR addresses this with two complementary solutions: knowledge atomization and structural organization, as in PIKE‚Äôs decomposition of documents into fine-grained units and multi-layer knowledge graphs for semantic and logical retrieval; and dynamic tool integration, as in Agentic Reasoning‚Äôs real-time data acquisition via code execution and API calls to compute critical indicators (e.g., medical FiO2). These innovations overcome the challenges of specialized knowledge depth and timely information relevance that limit conventional methods.

#### 3.2.3. Search Space Explosion and Local Optima Traps

The main challenge in multi-step reasoning is the exponential growth of the search space, where methods like Chain-of-Thought (CoT) often yield suboptimal or inconsistent results due to unconstrained hypotheses. Traditional approaches like CoT and Tree-of-Thought (ToT) lack external knowledge constraints, causing invalid assumptions, while purely symbolic reasoning falls short in open-domain tasks. To address this, two strategies are used: knowledge base-anchored heuristic search (KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59))), which limits reasoning actions to subgraphs in knowledge graphs, and a retrieval-verification mechanism (Search-o1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52))) that prunes unsupported reasoning paths using evidence from the knowledge base. Together, these reduce the search space and preserve reasoning coherence.

#### 3.2.4. Dynamic Knowledge Requirements in Multi-Step Reasoning

Complex multi-step reasoning tasks face the challenge of continuously changing knowledge requirements. This is evident in cases like multi-hop reasoning and engineering planning, where each stage generates new sub-problems (e.g., moving from ‚Äùarchitectural design‚Äù to ‚Äùmaterial cost estimation‚Äù). Static knowledge bases or one-time retrieval methods cannot meet this evolving demand. This manifests in two ways: initial knowledge may miss later needs, causing gaps; and fixed knowledge sets may include irrelevant information, reducing reasoning accuracy. To address this, new retrieval-augmented reasoning approaches introduce dynamic solutions: process supervision (e.g., reward models in RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97))) detects knowledge gaps in real time, atomic decision-making (e.g., step decomposition in DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25))) triggers retrieval as needed, and tree-like expansions (e.g., multi-path retrieval in DeepSolution¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55))) enable parallel exploration. By integrating knowledge retrieval within reasoning, these methods let the system identify, supplement, and verify knowledge dynamically‚Äîmuch like a human expert‚Äîgreatly enhancing the reliability and completeness of complex reasoning.

#### 3.2.5. Insufficient Depth and Breadth of Reasoning

This issue is prominent in expert tasks like medical diagnosis, legal analysis, and research report generation. LLMs‚Äô static knowledge often fails to capture the evolving scope of domain knowledge, resulting in shallow reasoning that misses multi-level, cross-domain connections. For example, when assessing ‚ÄùCompany A is affected by economic recession,‚Äù traditional methods rely on superficial statistical patterns and cannot systematically follow the deeper logical chain from ‚ÄùCompany A ‚Üí industry supply chain ‚Üí macroeconomic policy ‚Üí international political landscape,‚Äù leading to reasoning that lacks causal depth.

To overcome this, recent advances use structured, retrieval-enhanced frameworks. ToG2.0¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61)) models Knowledge Graph relational paths as retrieval guidance vectors, enabling targeted queries along entity paths, surpassing the limits of keyword-based retrieval. This approach complements CR-Planner‚Äôs¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) iterative expansion, which triggers retrieval of specialized knowledge (e.g., textbook proofs of algorithm complexity) at critical reasoning points, ensuring accurate domain knowledge integration via multi-round validation. Addressing cross-domain knowledge linkage, CO-STORM¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44)) employs a multi-agent system whose host module generates cross-modal retrieval commands by analyzing potential semantics in uncited documents.

## 4. Patterns of synergy

![Refer to caption](extracted/6386523/Images/pattern.png)

Figure 5. Patterns of Synergy between RAG and Reasoning

Section¬†[3](https://arxiv.org/html/2504.15909v2#S3 "3. The purpose of the synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review") detailed the need and motivation for integrating RAG with reasoning. Building on this, this section presents two core implementation patterns for RAG-reasoning synergy (Figure¬†[5](https://arxiv.org/html/2504.15909v2#S4.F5 "Figure 5 ‚Ä£ 4. Patterns of synergy ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")): (1) the Pre-defined Workflow, which uses logical architectures with preset rules for coordination, and (2) Dynamic Workflow, which relies on context-aware, adaptive coordination via real-time decision engines. These patterns illustrate current frameworks combining knowledge retrieval and multi-step reasoning from deterministic and flexible perspectives.

### 4.1. Pre-defined workflow

Pre-defined workflow is a multi-step reasoning approach with a fixed architecture and sequential execution, emphasizing process clarity and operational determinism. It consists of predefined iterative stages, each with strict input-output rules and no dynamic changes based on intermediate results. This modular design ensures controllability and structured reasoning for complex tasks. All steps are executed regardless of intermediate outcomes, guaranteeing repeatability and stability while avoiding uncertainties from dynamic decisions. Although it sacrifices adaptability, this approach offers procedural predictability and is well-suited for scenarios demanding clear reasoning paths, albeit with possible computational redundancy due to lack of real-time adjustments.

Mathematically, the pre-defined RAG workflow can be formalized as a deterministic multi-step operational chain. Given an input query QùëÑQitalic\_Q and a predefined sequence of NùëÅNitalic\_N reasoning steps and the final decision output Dùê∑Ditalic\_D, the complete workflow is expressed as:

|  |  |  |  |
| --- | --- | --- | --- |
| (1) |  | D=fN‚àò‚ãØ‚àòf2‚àòf1‚Å¢(Q)ùê∑subscriptùëìùëÅ‚ãØsubscriptùëì2subscriptùëì1ùëÑD=f\_{N}\circ\cdots\circ f\_{2}\circ f\_{1}(Q)italic\_D = italic\_f start\_POSTSUBSCRIPT italic\_N end\_POSTSUBSCRIPT ‚àò ‚ãØ ‚àò italic\_f start\_POSTSUBSCRIPT 2 end\_POSTSUBSCRIPT ‚àò italic\_f start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT ( italic\_Q ) |  |

where each fi‚àà{Œ®,R,Œì}subscriptùëìùëñŒ®ùëÖŒìf\_{i}\in\{\Psi,R,\Gamma\}italic\_f start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT ‚àà { roman\_Œ® , italic\_R , roman\_Œì } denotes strictly defined functions for reasoning (Œ®Œ®\Psiroman\_Œ®), retrieval (RùëÖRitalic\_R), or decision-making (ŒìŒì\Gammaroman\_Œì), with ‚àò\circ‚àò representing function composition. This formulation adheres to the fixed mapping sequence Q‚Ü¶Œ®‚Å¢(Q)‚Ü¶R‚Å¢(Œ®‚Å¢(Q))‚Ü¶Œì‚Å¢(R‚Å¢(Œ®‚Å¢(Q)))maps-toùëÑŒ®ùëÑmaps-toùëÖŒ®ùëÑmaps-toŒìùëÖŒ®ùëÑQ\mapsto\Psi(Q)\mapsto R(\Psi(Q))\mapsto\Gamma(R(\Psi(Q)))italic\_Q ‚Ü¶ roman\_Œ® ( italic\_Q ) ‚Ü¶ italic\_R ( roman\_Œ® ( italic\_Q ) ) ‚Ü¶ roman\_Œì ( italic\_R ( roman\_Œ® ( italic\_Q ) ) ), exhibiting Markovian properties where ft+1subscriptùëìùë°1f\_{t+1}italic\_f start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT depends solely on ftsubscriptùëìùë°f\_{t}italic\_f start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT‚Äôs output while remaining independent of historical states {f<t}subscriptùëìabsentùë°\{f\_{<t}\}{ italic\_f start\_POSTSUBSCRIPT < italic\_t end\_POSTSUBSCRIPT }. The chained composition guarantees process closure and reproducibility, though constrained by the static combinatorial nature of {fi}i=1Nsuperscriptsubscriptsubscriptùëìùëñùëñ1ùëÅ\{f\_{i}\}\_{i=1}^{N}{ italic\_f start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT } start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_N end\_POSTSUPERSCRIPT.

In the pre-defined pipeline, based on the position where reasoning is introduced, it can be further divided into Pre-Retrieval, Post-Retrieval, and Hybrid.

#### 4.1.1. Pre-Retrieval Reasoning

For pre-retrieval methods, the sequence is explicitly defined as

|  |  |  |  |
| --- | --- | --- | --- |
| (2) |  | D=Œì‚àò‚Ñõ‚àòŒ®‚Å¢(Q)ùê∑Œì‚ÑõŒ®ùëÑD=\Gamma\circ\mathcal{R}\circ\Psi(Q)italic\_D = roman\_Œì ‚àò caligraphic\_R ‚àò roman\_Œ® ( italic\_Q ) |  |

where Œ®Œ®\Psiroman\_Œ® denotes a reasoning operator that systematically transforms or enriches the query prior to retrieval.
This paradigm enhances retrieval precision by resolving ambiguities, inferring implicit intents, or optimizing query representations. Current research identifies four principal methodological categories for designing Œ®Œ®\Psiroman\_Œ®:

Query Optimization focuses on generating and selecting query variants to maximize retrieval relevance. Mathematically, this is formalized as Candidates=Generate‚Å¢(Q,C)CandidatesGenerateùëÑùê∂\text{Candidates}=\text{Generate}(Q,C)Candidates = Generate ( italic\_Q , italic\_C ), Œ®Optimize‚Å¢(Q,C)=arg‚Å°maxcandidate‚ààCandidates‚Å°Score‚Å¢(candidate)subscriptŒ®OptimizeùëÑùê∂subscriptcandidateCandidatesScorecandidate\quad\Psi\_{\text{Optimize}}(Q,C)=\arg\max\_{\text{candidate}\in\text{Candidates%
}}\text{Score}(\text{candidate})roman\_Œ® start\_POSTSUBSCRIPT Optimize end\_POSTSUBSCRIPT ( italic\_Q , italic\_C ) = roman\_arg roman\_max start\_POSTSUBSCRIPT candidate ‚àà Candidates end\_POSTSUBSCRIPT Score ( candidate ), where (Generate) produces candidate queries and (arg‚Å°max\arg\maxroman\_arg roman\_max) selects optimal variants based on contrastive training or reinforcement learning. Representative implementations, such as LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35)), leverage iterative sampling and optimization to balance query diversity and specificity.

Attribute Judgment employs classification mechanisms to dynamically regulate retrieval triggers. This is modeled as Œ®Classify‚Å¢(Q)=Classify‚Å¢(Q)subscriptŒ®ClassifyùëÑClassifyùëÑ\Psi\_{\text{Classify}}(Q)=\text{Classify}(Q)roman\_Œ® start\_POSTSUBSCRIPT Classify end\_POSTSUBSCRIPT ( italic\_Q ) = Classify ( italic\_Q ), where Classify evaluates query attributes (e.g., temporal sensitivity, intent complexity) against predefined criteria. Frameworks like UAR¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)) and AdaptiveRAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)) exemplify this approach by integrating multi-stage classifiers to minimize unnecessary retrievals.

Plan Generation decomposes complex queries into structured sub-task sequences to guide retrieval direction. Formulated as Œ®Plan‚Å¢(Q)=Plan‚Å¢(Q)subscriptŒ®PlanùëÑPlanùëÑ\Psi\_{\text{Plan}}(Q)=\text{Plan}(Q)roman\_Œ® start\_POSTSUBSCRIPT Plan end\_POSTSUBSCRIPT ( italic\_Q ) = Plan ( italic\_Q ), the operator Plan generates hierarchical task decompositions, as seen in PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) , which utilizes chain-of-thought reasoning to align retrieval targets with multi-step problem-solving requirements.

Semantic Enhancement enriches query representations using domain-specific or task-aware embeddings. Expressed as Œ®Enhance‚Å¢(Q)=Encode‚Å¢(Q,ùí¶)subscriptŒ®EnhanceùëÑEncodeùëÑùí¶\Psi\_{\text{Enhance}}(Q)=\text{Encode}(Q,\mathcal{K})roman\_Œ® start\_POSTSUBSCRIPT Enhance end\_POSTSUBSCRIPT ( italic\_Q ) = Encode ( italic\_Q , caligraphic\_K ), where ùí¶ùí¶\mathcal{K}caligraphic\_K denotes auxiliary knowledge (e.g., reasoning trajectories), methods like O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)) integrate latent reasoning patterns into query embeddings to improve retrieval robustness.

Collectively, these methodologies demonstrate that pre-retrieval reasoning serves as a systematic interface to mitigate semantic gaps between raw queries and knowledge bases, establishing a critical component for precision-driven RAG architectures.

#### 4.1.2. Post-Retrieval Reasoning

In pre-defined RAG systems with multi-step reasoning pipelines, the post-retrieval reasoning paradigm represents a critical advancement where cognitive processing occurs after information retrieval from external sources. This approach addresses inherent limitations in conventional RAG, particularly in managing knowledge conflicts, mitigating information insufficiency, and enhancing logical consistency across complex reasoning tasks. Mathematically, this process can be formalized as a deterministic function composition:

|  |  |  |  |
| --- | --- | --- | --- |
| (3) |  | D=Œì‚àòŒ®‚àò‚Ñõ‚Å¢(Q)ùê∑ŒìŒ®‚ÑõùëÑD=\Gamma\circ\Psi\circ\mathcal{R}(Q)italic\_D = roman\_Œì ‚àò roman\_Œ® ‚àò caligraphic\_R ( italic\_Q ) |  |

‚Ñõ‚Ñõ\mathcal{R}caligraphic\_R denotes the retrieval operator, Œ®Œ®\Psiroman\_Œ® implements the reasoning transformation, and ŒìŒì\Gammaroman\_Œì represents the final decision function.

The core characteristic of Post-Retrieval Reasoning lies in its execution of the reasoning process after retrieval, with the reasoning target being the retrieved content. ToG2.0¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61)) proposes an iterative multi-step reasoning framework that alternates between graph retrieval and context retrieval, integrating the reasoning judgment of LLMs to progressively expand entities and prune irrelevant information, ultimately generating accurate answers. This approach dynamically addresses the issue of insufficient information through iterative refinement while establishing a dual-evidence verification mechanism via knowledge graph relation pruning and entity-guided context retrieval. Its graph-structured reasoning module transforms the connectivity validation of triple paths into a constraint satisfaction problem, effectively mitigating logical inconsistencies between text fragments and thereby significantly improving the quality of complex question answering.

ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)), on the other hand, employs a predefined three-stage process (Self-Inquiry ‚Üí Knowledge Assimilation ‚Üí Thought Accommodation) to structurally comprehend and calibrate retrieved knowledge, resolving conflicts between parametric memory and external knowledge. During the Knowledge Assimilation stage, ActiveRAG enhances the corrective effect of external knowledge on the internal representations of LLMs through multi-instruction fine-tuning strategies (e.g., counterfactual comparison and anchor association), substantially reducing the likelihood of hallucination generation. ARM‚Äôs¬†(Chen et¬†al., [2025f](https://arxiv.org/html/2504.15909v2#bib.bib8)) structural alignment and self-verification stages also demonstrate optimization for post-retrieval reasoning. By incorporating domain knowledge via mixed-integer programming (MIP) solvers, ARM ensures the rationality and coverage of retrieval results, providing a scalable optimization framework for multi-source data compatibility and thereby enabling globally optimal cross-modal retrieval.

#### 4.1.3. Hybrid Reasoning

The Hybrid pattern of pre-defined process forms a composite processing paradigm by integrating pre-retrieval reasoning with post-retrieval reasoning. The essence is formalized as a multi-round recursive iterative process, where each iteration cycle strictly comprises three phases: Retrieval, Generation, and Reasoning, executed as structured composite operations. Let the total number of iterations be TùëáTitalic\_T; the workflow is defined as:

|  |  |  |  |
| --- | --- | --- | --- |
| (4) |  | QT=(‚óãt=1T‚Ñõùìâ‚àòŒìt‚àòŒ®t)(Q0)Q\_{T}=\left(\bigcirc\_{t=1}^{T}\mathcal{R\_{t}}\circ\Gamma\_{t}\circ\Psi\_{t}% \right)(Q\_{0})italic\_Q start\_POSTSUBSCRIPT italic\_T end\_POSTSUBSCRIPT = ( ‚óã start\_POSTSUBSCRIPT italic\_t = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_T end\_POSTSUPERSCRIPT caligraphic\_R start\_POSTSUBSCRIPT caligraphic\_t end\_POSTSUBSCRIPT ‚àò roman\_Œì start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚àò roman\_Œ® start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ( italic\_Q start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT ) |  |

Here, each iterative unit is indexed by tùë°titalic\_t. The process terminates when a predefined condition ùíØ‚Å¢(Qt,Dt,Ct)ùíØsubscriptùëÑùë°subscriptùê∑ùë°subscriptùê∂ùë°\mathcal{T}(Q\_{t},D\_{t},C\_{t})caligraphic\_T ( italic\_Q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_D start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) is met, yielding the final response Œìfinal‚Å¢(CT)subscriptŒìfinalsubscriptùê∂ùëá\Gamma\_{\text{final}}(C\_{T})roman\_Œì start\_POSTSUBSCRIPT final end\_POSTSUBSCRIPT ( italic\_C start\_POSTSUBSCRIPT italic\_T end\_POSTSUBSCRIPT ). This recursive mechanism enables dynamic synergy between knowledge acquisition and semantic inference, overcoming the linear limitations of single-cycle retrieval-generation frameworks.

IR-CoT¬†(Trivedi et¬†al., [2022a](https://arxiv.org/html/2504.15909v2#bib.bib79)) leverages chain-of-thought reasoning to iteratively construct intermediate logic chains, enabling multi-hop retrieval guided by progressively refined contextual cues. FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)) introduces a dual-phase architecture that first generates structured search graphs to model temporal and entity dependencies, followed by dynamic query rewriting to optimize financial data retrieval. LevelRAG employs hierarchical validation mechanisms, aggregating multi-granular retrieval results and triggering supplementary retrievals based on context completeness assessments. ITER-RETGEN¬†(Shao et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib69)) utilizes generation-enhanced feedback loops to iteratively refine query representations, enhancing semantic alignment between retrieval and generation phases.

These approaches share a common foundation in structured recursion while diverging in operational mechanisms. By enforcing deterministic iteration cycles, they balance controlled workflow execution with adaptive semantic exploration, addressing challenges such as multi-step reasoning, temporal coherence, and cross-domain knowledge synthesis. The hybrid paradigm‚Äôs strength lies in its capacity to decompose complex queries into iterative retrieval-generation units, systematically bridging knowledge gaps while maintaining interpretability and robustness in open-domain problem-solving scenarios.

### 4.2. Dynamic RAG Workflow

The RAG with dynamic workflow represents an autonomous reasoning architecture centered around LLMs, characterized by the integration of non-deterministic operational workflows and real-time decision-making capabilities. Unlike pre-defined pipelines, this architecture enables continuous monitoring of reasoning states to dynamically trigger retrieval, generation, or verification operations. The LLM actively evaluates contextual demands during reasoning processes, autonomously determining optimal moments for invoking external tools or resources through a hybrid feedback coordination mechanism. By eliminating fixed iterative units and pre-determined tool-calling sequences, the framework achieves dynamic evolution of execution pathways, demonstrating superior adaptability in complex cognitive tasks through real-time adjustment of computational workflows based on intermediate reasoning outcomes.

This dynamic architecture manifests three principal characteristics: 1) Operator invocation is governed by the LLM‚Äôs contextual state analysis, exemplified through special token prediction (e.g., ‚Äò[Web-Search]‚Äò or ‚Äò¬°begin\_of\_query¬ø‚Äò) to initiate external operations; 2) Reasoning trajectories exhibit high flexibility, allowing dynamic query reformulation and sub-problem generation to overcome limitations of static workflows; 3) Context-driven decision mechanisms prioritize real-time reasoning states over predefined rules, enhancing systemic responsiveness to emergent task complexities while improving precision.

Defining the reasoning state at time tùë°titalic\_t as St=(Ht,Ct)subscriptùëÜùë°subscriptùêªùë°subscriptùê∂ùë°S\_{t}=(H\_{t},C\_{t})italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = ( italic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ), where Htsubscriptùêªùë°H\_{t}italic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT denotes historical information aggregation and Ctsubscriptùê∂ùë°C\_{t}italic\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT represents contextual embedding vectors, the decision process is modeled as a stochastic system:

|  |  |  |  |
| --- | --- | --- | --- |
| (5) |  | at+1‚àºœÄ‚Å¢(St;Œò)similar-tosubscriptùëéùë°1ùúã  subscriptùëÜùë°Œòa\_{t+1}\sim\pi(S\_{t};\Theta)italic\_a start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ‚àº italic\_œÄ ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ; roman\_Œò ) |  |

|  |  |  |  |
| --- | --- | --- | --- |
| (6) |  | St+1=Œ¥‚Å¢(St,ùíØat+1‚Å¢(St))subscriptùëÜùë°1ùõøsubscriptùëÜùë°subscriptùíØsubscriptùëéùë°1subscriptùëÜùë°S\_{t+1}=\delta(S\_{t},\mathcal{T}\_{a\_{t+1}}(S\_{t}))italic\_S start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = italic\_Œ¥ ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , caligraphic\_T start\_POSTSUBSCRIPT italic\_a start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ) |  |

Here, œÄ:ùíÆ‚ÜíŒî‚Å¢(ùíú):ùúã‚ÜíùíÆŒîùíú\pi:\mathcal{S}\to\Delta(\mathcal{A})italic\_œÄ : caligraphic\_S ‚Üí roman\_Œî ( caligraphic\_A ) constitutes the policy function mapping states to probability distributions over action space ùíúùíú\mathcal{A}caligraphic\_A (retrieval, generation, verification, etc.), while ùíØasubscriptùíØùëé\mathcal{T}\_{a}caligraphic\_T start\_POSTSUBSCRIPT italic\_a end\_POSTSUBSCRIPT denotes state transition functions corresponding to action aùëéaitalic\_a. The non-Markovian nature of the system emerges from St+1subscriptùëÜùë°1S\_{t+1}italic\_S start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT‚Äôs dependence on complete historical trajectories {S‚â§t}subscriptùëÜabsentùë°\{S\_{\leq t}\}{ italic\_S start\_POSTSUBSCRIPT ‚â§ italic\_t end\_POSTSUBSCRIPT }, with dynamic adaptability ensured through extensible action spaces ùíúùíú\mathcal{A}caligraphic\_A and online optimization of policy parameters ŒòŒò\Thetaroman\_Œò. This formulation enables context-sensitive state updates via Œ¥:ùíÆ√óùí™‚ÜíùíÆ:ùõø‚ÜíùíÆùí™ùíÆ\delta:\mathcal{S}\times\mathcal{O}\to\mathcal{S}italic\_Œ¥ : caligraphic\_S √ó caligraphic\_O ‚Üí caligraphic\_S, establishing a theoretical foundation for open-ended reasoning processes in complex problem domains.

Based on the mode of reasoning initiation, agentic RAG with dynamic workflows can be further categorized into three distinct types: Proactivity-driven, Reflection-driven, and Feedback-driven mechanisms.
The LLM proactivity-driven approach is characterized by the model‚Äôs autonomous triggering of actions based on internal assessments, executing operations without external intervention through mechanisms analogous to human intuitive decision-making‚Äîfor instance, when the model independently identifies insufficient evidentiary support in the current reasoning process, it proactively generates retrieval requests to supplement information. The reflection-driven mode emphasizes self-examination of the reasoning process, dynamically initiating subsequent operations through quantitative evaluation of intermediate result quality (e.g., triggering actions when the calculated reasoning support score of 0.7 exceeds a predefined threshold of 0.6), which simulates the self-optimization logic of expert systems, enabling the model to adjust reasoning pathways through introspection. The feedback-driven mechanism incorporates external intervention, employing independent models or rule-based systems to perform real-time scoring of intermediate states (e.g., an external reward model assigning a 2.5/5 score to reasoning steps) while providing corrective suggestions, operating similarly to a mentor-guided mode that continuously calibrates the reasoning workflow through external feedback signals.

#### 4.2.1. Proactivity-Driven Reasoning

The core innovation of Proactivity-driven Reasoning lies in enabling LLMs to fully govern the reasoning process through self-triggered prediction mechanisms. This active control manifests through three key mechanisms: (1) direct tool invocation via model-generated special tokens (e.g., [Web-Search]), without external intervention, (2) context-aware decision making based on real-time knowledge gaps or hypothesis verification requirements, and (3) Markov Decision Process (MDP)-based dynamic path optimization.

Formally, the reasoning process can be modeled as a state sequence S={s0,s1,‚Ä¶,st}ùëÜsubscriptùë†0subscriptùë†1‚Ä¶subscriptùë†ùë°S=\{s\_{0},s\_{1},\dots,s\_{t}\}italic\_S = { italic\_s start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT , italic\_s start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , ‚Ä¶ , italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT }, where each state stsubscriptùë†ùë°s\_{t}italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT encapsulates the current reasoning context. At each step tùë°titalic\_t, the LLM selects an action at‚àà{retrieve,generate,terminate}subscriptùëéùë°retrievegenerateterminatea\_{t}\in\{\text{retrieve},\text{generate},\text{terminate}\}italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚àà { retrieve , generate , terminate } based on stsubscriptùë†ùë°s\_{t}italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT, executes the corresponding operation (e.g., document retrieval or answer generation), and updates its state through transition function st+1=Œ¥‚Å¢(st,at,ot)subscriptùë†ùë°1ùõøsubscriptùë†ùë°subscriptùëéùë°subscriptùëúùë°s\_{t+1}=\delta(s\_{t},a\_{t},o\_{t})italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = italic\_Œ¥ ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_o start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) where otsubscriptùëúùë°o\_{t}italic\_o start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT represents action outcomes. This MDP framework enables dynamic path adjustment through real-time feedback until termination (aT=terminatesubscriptùëéùëáterminatea\_{T}=\text{terminate}italic\_a start\_POSTSUBSCRIPT italic\_T end\_POSTSUBSCRIPT = terminate) and final answer generation.

Recent advancements demonstrate significant improvements over conventional RAG approaches. The Agentic Reasoning framework achieves granular control through dynamic tool invocation, eliminating predefined execution sequences. DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)) optimizes cost-accuracy tradeoffs via MDP-based imitation learning, addressing the retrieval-generation disconnection in traditional systems. CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84)) introduces hybrid-driven mechanisms combining LLM-initiated subqueries with external policy control, enhancing error tolerance for complex queries. Collectively, these approaches establish a paradigm shift from fixed pipelines to context-sensitive, self-optimizing reasoning architectures.

#### 4.2.2. Reflection-Driven Reasoning

The reflection-driven mechanism represents a dynamic reasoning framework that enables iterative self-evaluation and revision of intermediate outputs through model introspection. Common methods include: (1) a evaluation system combining explicit token prediction and implicit confidence scoring, (2) self-monitoring capabilities through grounding tokens for content-document consistency verification and utility tokens for answer effectiveness assessment, and (3) adaptive routing mechanisms that automatically select single-hop or multi-hop reasoning paths based on contextual complexity. The mathematical formalism of this process can be expressed as:

|  |  |  |  |
| --- | --- | --- | --- |
| (7) |  | ùí´=‚ãÉt=1T[G‚Å¢(ùêÇt)‚ÜíE‚Å¢(ùêát,ùíü)‚Üíœà‚Å¢(œï‚Å¢(ùêût),œÑ)]ùí´superscriptsubscriptùë°1ùëádelimited-[]‚Üíùê∫subscriptùêÇùë°ùê∏subscriptùêáùë°ùíü‚Üíùúìitalic-œïsubscriptùêûùë°ùúè\mathcal{P}=\bigcup\_{t=1}^{T}\left[G(\mathbf{C}\_{t})\rightarrow E(\mathbf{H}\_{% t},\mathcal{D})\rightarrow\psi(\phi(\mathbf{e}\_{t}),\tau)\right]caligraphic\_P = ‚ãÉ start\_POSTSUBSCRIPT italic\_t = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_T end\_POSTSUPERSCRIPT [ italic\_G ( bold\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ‚Üí italic\_E ( bold\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , caligraphic\_D ) ‚Üí italic\_œà ( italic\_œï ( bold\_e start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) , italic\_œÑ ) ] |  |

where Gùê∫Gitalic\_G denotes the generation function operating on current context ùêútsubscriptùêúùë°\mathbf{c}\_{t}bold\_c start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT, Eùê∏Eitalic\_E represents the evaluation function that assesses hidden states ùê°tsubscriptùê°ùë°\mathbf{h}\_{t}bold\_h start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT against external knowledge base ùíüùíü\mathcal{D}caligraphic\_D, œïitalic-œï\phiitalic\_œï serves as the confidence mapping function, œÑùúè\tauitalic\_œÑ is the decision threshold, and œàùúì\psiitalic\_œà functions as the branch selector.

In practical implementations like Self-RAG¬†(Asai et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib4)), this framework generates candidate responses alongside reflection tokens, computes passage relevance scores (ISREL‚àà[0,1]ISREL01\text{ISREL}\in[0,1]ISREL ‚àà [ 0 , 1 ]) and factual support metrics (ISSUP), and employs weighted aggregation of token probabilities in œïitalic-œï\phiitalic\_œï to determine retrieval activation or generation revision through threshold-based Œ¥ùõø\deltaitalic\_Œ¥ operations. Meanwhile, Open-RAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39)) incorporates hybrid threshold mechanisms and Mixture-of-Experts architecture to enforce counterfactual verification through non-retrieval confidence scoring (PrNoRTsubscriptPrNoRT\text{Pr}\_{\text{NoRT}}Pr start\_POSTSUBSCRIPT NoRT end\_POSTSUBSCRIPT), enabling dynamic expansion of complex reasoning capabilities while preserving base model efficiency. ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50)) utilizes knowledge-guided reasoning chains combined with external knowledge sources to perform reflection-driven reasoning. In each iteration, it adjusts the reasoning path through the ‚ÄùThought-Action-Observation‚Äù paradigm, effectively preventing error propagation and improving answer accuracy.

The paradigm‚Äôs innovation lies in reconstructing traditional sequential processes into conditional Markov decision processes, where state transition probabilities P‚Å¢(st+1|st)ùëÉconditionalsubscriptùë†ùë°1subscriptùë†ùë°P(s\_{t+1}|s\_{t})italic\_P ( italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT | italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) are dynamically determined by model self-evaluation outcomes. Compared to proactive LLM-driven methods (e.g., Toolformer‚Äôs direct API invocation), the reflection-driven approach establishes closed-loop control through explicit evaluation stages (function Eùê∏Eitalic\_E), effectively mitigating hallucination risks while maintaining computational efficiency.

#### 4.2.3. Feedback-Driven Reasoning

The feedback-driven dynamic RAG system establishes closed-loop control over reasoning processes through external signals, formally modeled as a Partially Observable Markov Decision Process. The system state st=(qt,ùí¶t,Ht)subscriptùë†ùë°subscriptùëûùë°subscriptùí¶ùë°subscriptùêªùë°s\_{t}=(q\_{t},\mathcal{K}\_{t},H\_{t})italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = ( italic\_q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) evolves through iterative interactions, comprising the current query representation qtsubscriptùëûùë°q\_{t}italic\_q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT, dynamic knowledge base ùí¶tsubscriptùí¶ùë°\mathcal{K}\_{t}caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT, and historical trajectory ‚Ñãtsubscript‚Ñãùë°\mathcal{H}\_{t}caligraphic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT. Initialized with q0subscriptùëû0q\_{0}italic\_q start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT and ùí¶0=‚àÖsubscriptùí¶0\mathcal{K}\_{0}=\emptysetcaligraphic\_K start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT = ‚àÖ, the policy function œÄ‚Å¢(at|st)ùúãconditionalsubscriptùëéùë°subscriptùë†ùë°\pi(a\_{t}|s\_{t})italic\_œÄ ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) generates actions from the operational space ùíú={Retrieve,Reason,Verify,Answer,‚àÖ}ùíúRetrieveReasonVerifyAnswer\mathcal{A}=\{\text{Retrieve},\text{Reason},\text{Verify},\text{Answer},\emptyset\}caligraphic\_A = { Retrieve , Reason , Verify , Answer , ‚àÖ }. State transitions follow st+1=Œ¥‚Å¢(st,at)subscriptùë†ùë°1ùõøsubscriptùë†ùë°subscriptùëéùë°s\_{t+1}=\delta(s\_{t},a\_{t})italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = italic\_Œ¥ ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) with knowledge base updates

|  |  |  |  |
| --- | --- | --- | --- |
| (8) |  | ùí¶t+1=ùí¶t‚äïRetrieve‚Å¢(qt)‚ãÖùïÄ‚Å¢(at=Retrieve)subscriptùí¶ùë°1direct-sumsubscriptùí¶ùë°‚ãÖRetrievesubscriptùëûùë°ùïÄsubscriptùëéùë°Retrieve\mathcal{K}\_{t+1}=\mathcal{K}\_{t}\oplus\text{Retrieve}(q\_{t})\cdot\mathbb{I}(a% \_{t}=\text{Retrieve})caligraphic\_K start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚äï Retrieve ( italic\_q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ‚ãÖ blackboard\_I ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = Retrieve ) |  |

where ‚äïdirect-sum\oplus‚äï denotes incremental updates and ùïÄùïÄ\mathbb{I}blackboard\_I represents an indicator function. The reward function R‚Å¢(st,at,st+1)‚Üírt‚ÜíùëÖsubscriptùë†ùë°subscriptùëéùë°subscriptùë†ùë°1subscriptùëüùë°R(s\_{t},a\_{t},s\_{t+1})\rightarrow r\_{t}italic\_R ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ) ‚Üí italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT drives policy optimization through

|  |  |  |  |
| --- | --- | --- | --- |
| (9) |  | œÄt+1=Œ©‚Å¢(œÄt,‚àáŒ∏ùîºa‚àºœÄt‚Å¢[R‚Å¢(st,a,st+1)])subscriptùúãùë°1Œ©subscriptùúãùë°subscript‚àáùúÉsubscriptùîºsimilar-toùëésubscriptùúãùë°delimited-[]ùëÖsubscriptùë†ùë°ùëésubscriptùë†ùë°1\pi\_{t+1}=\Omega(\pi\_{t},\nabla\_{\theta}\mathbb{E}\_{a\sim\pi\_{t}}[R(s\_{t},a,s\_% {t+1})])italic\_œÄ start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = roman\_Œ© ( italic\_œÄ start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , ‚àá start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT blackboard\_E start\_POSTSUBSCRIPT italic\_a ‚àº italic\_œÄ start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT [ italic\_R ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a , italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ) ] ) |  |

forming an adaptive control loop. Three distinct feedback mechanisms emerge within this framework.

Explicit reward feedback employs specialized models œÄrewardsubscriptùúãreward\pi\_{\text{reward}}italic\_œÄ start\_POSTSUBSCRIPT reward end\_POSTSUBSCRIPT for quantitative evaluation, exemplified by RAG-Gym‚Äôs process rewards¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97)). The reward function combines immediate and terminal rewards:

|  |  |  |  |
| --- | --- | --- | --- |
| (10) |  | rt=Œª1‚Å¢œÄreward‚Å¢(st)+Œª2‚Å¢ùîºst+k‚Å¢[Œ≥k‚Å¢Rterminal]subscriptùëüùë°subscriptùúÜ1subscriptùúãrewardsubscriptùë†ùë°subscriptùúÜ2subscriptùîºsubscriptùë†ùë°ùëòdelimited-[]superscriptùõæùëòsubscriptùëÖterminalr\_{t}=\lambda\_{1}\pi\_{\text{reward}}(s\_{t})+\lambda\_{2}\mathbb{E}\_{s\_{t+k}}[% \gamma^{k}R\_{\text{terminal}}]italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = italic\_Œª start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT italic\_œÄ start\_POSTSUBSCRIPT reward end\_POSTSUBSCRIPT ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) + italic\_Œª start\_POSTSUBSCRIPT 2 end\_POSTSUBSCRIPT blackboard\_E start\_POSTSUBSCRIPT italic\_s start\_POSTSUBSCRIPT italic\_t + italic\_k end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT [ italic\_Œ≥ start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT italic\_R start\_POSTSUBSCRIPT terminal end\_POSTSUBSCRIPT ] |  |

with discount factor Œ≥ùõæ\gammaitalic\_Œ≥. SmartRAG extends this through policy gradient optimization

|  |  |  |  |
| --- | --- | --- | --- |
| (11) |  | ‚àáŒ∏J‚Å¢(Œ∏)=ùîºœÑ‚àºœÄŒ∏‚Å¢[‚àët=0T‚àáŒ∏log‚Å°œÄŒ∏‚Å¢(at|st)‚Å¢A^t]subscript‚àáùúÉùêΩùúÉsubscriptùîºsimilar-toùúèsubscriptùúãùúÉdelimited-[]superscriptsubscriptùë°0ùëásubscript‚àáùúÉsubscriptùúãùúÉconditionalsubscriptùëéùë°subscriptùë†ùë°subscript^ùê¥ùë°\nabla\_{\theta}J(\theta)=\mathbb{E}\_{\tau\sim\pi\_{\theta}}[\sum\_{t=0}^{T}% \nabla\_{\theta}\log\pi\_{\theta}(a\_{t}|s\_{t})\hat{A}\_{t}]‚àá start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT italic\_J ( italic\_Œ∏ ) = blackboard\_E start\_POSTSUBSCRIPT italic\_œÑ ‚àº italic\_œÄ start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT [ ‚àë start\_POSTSUBSCRIPT italic\_t = 0 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_T end\_POSTSUPERSCRIPT ‚àá start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT roman\_log italic\_œÄ start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) over^ start\_ARG italic\_A end\_ARG start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ] |  |

where the advantage function A^tsubscript^ùê¥ùë°\hat{A}\_{t}over^ start\_ARG italic\_A end\_ARG start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT integrates temporal feedback.

Implicit environmental feedback derives from knowledge base validation, as implemented in KBQA-o1‚Äôs SPARQL verification and SolutionRAG‚Äôs pruning mechanisms¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59)). This feedback is formalized as rt=ùïÄ(ùí¶t‚äßq0)‚ãÖcvalid‚àíùïÄ(‚ä•‚ààùí¶t)‚ãÖcinvalidr\_{t}=\mathbb{I}(\mathcal{K}\_{t}\models q\_{0})\cdot c\_{\text{valid}}-\mathbb{I%
}(\bot\in\mathcal{K}\_{t})\cdot c\_{\text{invalid}}italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = blackboard\_I ( caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚äß italic\_q start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT ) ‚ãÖ italic\_c start\_POSTSUBSCRIPT valid end\_POSTSUBSCRIPT - blackboard\_I ( ‚ä• ‚àà caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ‚ãÖ italic\_c start\_POSTSUBSCRIPT invalid end\_POSTSUBSCRIPT with validation function ùïÄ‚Å¢(‚ãÖ)ùïÄ‚ãÖ\mathbb{I}(\cdot)blackboard\_I ( ‚ãÖ ) and penalty coefficients cùëêcitalic\_c. ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76)) introduces threshold-triggered correction: when rt<œÑsubscriptùëüùë°ùúèr\_{t}<\tauitalic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT < italic\_œÑ, it activates refinement loops ùí¶t+1=PEM‚Å¢(ùí¶t,q0)‚äïRetrieve‚Å¢(PRM‚Å¢(st))subscriptùí¶ùë°1direct-sumPEMsubscriptùí¶ùë°subscriptùëû0RetrievePRMsubscriptùë†ùë°\mathcal{K}\_{t+1}=\text{PEM}(\mathcal{K}\_{t},q\_{0})\oplus\text{Retrieve}(\text%
{PRM}(s\_{t}))caligraphic\_K start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = PEM ( caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_q start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT ) ‚äï Retrieve ( PRM ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) ).

Structured rule feedback encodes domain knowledge through differentiable scoring functions. MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98)) implements depth-attenuated rewards

|  |  |  |  |
| --- | --- | --- | --- |
| (12) |  | rt=11+Œ±‚Å¢dt‚Å¢‚àëi=1nLLMscore‚Å¢(at(i))subscriptùëüùë°11ùõºsubscriptùëëùë°superscriptsubscriptùëñ1ùëõsubscriptLLMscoresuperscriptsubscriptùëéùë°ùëñr\_{t}=\frac{1}{1+\alpha d\_{t}}\sum\_{i=1}^{n}\text{LLM}\_{\text{score}}(a\_{t}^{(% i)})italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = divide start\_ARG 1 end\_ARG start\_ARG 1 + italic\_Œ± italic\_d start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT end\_ARG ‚àë start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_n end\_POSTSUPERSCRIPT LLM start\_POSTSUBSCRIPT score end\_POSTSUBSCRIPT ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT ( italic\_i ) end\_POSTSUPERSCRIPT ) |  |

with search depth dtsubscriptùëëùë°d\_{t}italic\_d start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPTand decay coefficient Œ±ùõº\alphaitalic\_Œ±. CR-Planner‚Äôs hierarchical critique combines subgoal and execution scores: rttotal=Œ≤1‚Å¢œÄsub‚Å¢(st)+Œ≤2‚Å¢œÄexec‚Å¢(at|st)superscriptsubscriptùëüùë°totalsubscriptùõΩ1subscriptùúãsubsubscriptùë†ùë°subscriptùõΩ2subscriptùúãexecconditionalsubscriptùëéùë°subscriptùë†ùë°r\_{t}^{\text{total}}=\beta\_{1}\pi\_{\text{sub}}(s\_{t})+\beta\_{2}\pi\_{\text{exec%
}}(a\_{t}|s\_{t})italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT total end\_POSTSUPERSCRIPT = italic\_Œ≤ start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT italic\_œÄ start\_POSTSUBSCRIPT sub end\_POSTSUBSCRIPT ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) + italic\_Œ≤ start\_POSTSUBSCRIPT 2 end\_POSTSUBSCRIPT italic\_œÄ start\_POSTSUBSCRIPT exec end\_POSTSUBSCRIPT ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) through weighted fusion.

These feedback mechanisms interact through a unified strategy update framework, where external feedback-driven approaches achieve controllable optimization of the reasoning process through interpretable feedback signals while maintaining the generative capabilities of LLMs. Overall, the dynamic process of RAG, by endowing the model with autonomy in the reasoning process, not only enhances adaptability to complex tasks but also provides a new solution for efficient reasoning in resource-constrained environments.

## 5. Implementation and Optimization

Building upon preceding sections, this section systematically analyzes the concrete implementation and optimization strategies for reasoning within the RAG paradigm. In contrast to existing surveys that predominantly focus on post-training methodologies or isolated LLM reasoning mechanisms, our analysis maintains a dedicated focus on the synergistic integration of RAG with reasoning examining their co-adaptive implementations through a structural lens.

![Refer to caption](extracted/6386523/Images/implementation.png)

Figure 6. Implementation and optimization of the synergy between RAG and Reasoning

### 5.1. Reasoning Process

#### 5.1.1. LLM CoT

Integrating Chain-of-Thought (CoT) reasoning with LLMs is key to combining RAG with complex reasoning tasks. Research shows CoT enhances RAG systems by explicitly guiding multi-step reasoning and dynamically incorporating external knowledge. For example, ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)) uses a ‚ÄùSelf-Inquiry ‚Üí Knowledge Assimilation ‚Üí Thought Accommodation‚Äù chain to align knowledge and reasoning: a knowledge assimilation agent merges external documents with LLM memory via operations like association and reflection, creating structured knowledge. Meanwhile, a reasoning adaptation agent refines inference chains from Self-Inquiry to ensure answers align with retrieved knowledge and address reasoning gaps. Similarly, Adaptive-RAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)) alternates between CoT and retrieval, breaking down multi-hop reasoning into steps such as entity localization and document correlation, refining retrieval and generation based on prior results.

At the knowledge and reasoning level, O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)) drives RAG through open-ended long-text reasoning, extending CoT beyond fixed triggers via coherent thought processes like problem decomposition. PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) explicitly uses CoT to produce executable multi-step plans, adjusting operations dynamically through a closed-loop ‚Äùplan-execute-feedback‚Äù cycle. Despite different implementations, these methods share two CoT strengths: breaking down complex problems into clear intermediate steps and guiding external knowledge selection through reasoning states. Studies show these approaches outperform traditional RAG in multi-hop QA and knowledge-intensive tasks by enhancing both LLMs‚Äô reasoning and adaptability to external knowledge.

#### 5.1.2. Special Token Prediction

Recent advances active RAG also highlight special token prediction as a key method for dynamically linking external knowledge retrieval with multi-step reasoning¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17)). By embedding domain- or action-specific tokens (e.g., ‚Äò[Web-search]‚Äò, ‚Äò[Retrieve=Yes]‚Äò, ‚Äò¬°begin\_of\_query¬ø‚Äò) into LLM vocabularies, models can autonomously trigger tools or self-reflect during text generation. Frameworks like Self-RAG¬†(Asai et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib4)) and SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)) use dedicated tokens (‚ÄòRetrieve‚Äò, ‚ÄòISREL‚Äò, ‚Äò[RETRIEVE]‚Äò) to manage retrieval activation, relevance checks, and output verification, turning static reasoning chains into conditional workflows. The innovation lies in predicting these tokens within generated sequences, segmenting tasks into retrieval initiation, document evaluation, and knowledge grounding phases.

Hybrid models such as Open-RAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39)) combine token control with mixture-of-experts (MoE) routing, sparsely activating experts aligned with token-predicted reasoning. Unlike traditional chain-of-thought or search tree methods, special token prediction offers finer control and interpretability by encoding decision logic explicitly in token sequences while maintaining end-to-end training. This approach also overcomes latency and inflexibility of preset retrieval schedules by enabling context-aware, on-demand tool use. For example, R1-Searcher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)) and Search-o1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)) use token boundaries like ‚Äò¬°end\_of\_query¬ø‚Äò to coordinate retrieval pauses and resume generation after knowledge integration.

Together, these systems show that token-level prediction not only bridges reasoning and retrieval but also creates a scalable framework for tool-enhanced language agents, preserving generative fluency while enabling systematic external knowledge integration and procedural reasoning.

#### 5.1.3. Search-Driven Reasoning

Recent advancements in search-driven reasoning have significantly improved RAG frameworks by employing structured search strategies for dynamic information exploration and multi-step reasoning with external knowledge. Current approaches mainly follow three paradigms: tree-based search, MCTS, and reinforcement learning-optimized policy networks.

Tree-based methods organize reasoning hierarchically through structured path exploration. For example,StePO-Rec¬†(Bi et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib6)) uses a multi-step tree-structured reasoning method that iteratively retrieves different outfit matching knowledge and user preferences at each node, ultimately achieving generative recommendations for complementary items. OmniThink¬†(Xi et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib95)) uses an information tree to expand topic analysis by generating subqueries that guide breadth-first or depth-first retrievals. DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)) applies a binary tree search within a Markov decision process to explore parametric knowledge and retrieval paths in parallel, selecting optimal branches. DeepSolution‚Äôs¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)) bidirectional thinking tree alternates expanding solution and critique nodes with scoring for path pruning, aligning naturally with MCTS evaluation. These methods balance exploration efficiency with solution coverage through explicit tree structures.

MCTS enhances robustness by optimizing long-term decisions via simulation, evaluation, and backpropagation. CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) integrates MCTS with the UCB strategy to balance exploration and exploitation while estimating optimal subgoals through multi-step simulations. KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59)) and MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98)) generate candidate actions using policy models and combine reward models to globally assess logical forms, reducing local optima. ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76)) innovatively merges MCTS with procedural reward models (PRMs), interleaving retrieval and reasoning steps, and filtering high-reward paths to form a closed-loop ‚Äùreason-retrieve-reason‚Äù cycle. These methods probabilistically explore paths and use reinforcement learning feedback to improve global reasoning for complex tasks.

Reinforcement learning-optimized policy networks adaptively refine search strategies. LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35)) replaces fixed search algorithms with reinforcement learning (e.g., IPO) to dynamically optimize query generation based on rewards like retrieval accuracy, implicitly learning optimal search patterns without explicit tree or graph structures, thus offering greater flexibility and scalability.

In summary, search-driven reasoning unites inference and retrieval through structured strategies, combining multi-path exploration, dynamic evaluation, and adaptive optimization to deliver interpretable, efficient solutions for knowledge-intensive tasks. Future work may focus on hybrid paradigms (e.g., integrating MCTS and reinforcement learning) and lightweight algorithms to balance performance with computational efficiency.

#### 5.1.4. Reasoning on Graph

Graph-structured reasoning offers a novel approach for multi-hop inference in RAG systems by explicitly modeling knowledge interaction paths through topology. Current methods fall into two categories: query-flow-oriented search graphs (e.g. FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51))) and knowledge-association-based expansion graphs (ToG-2.0¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61))). FinSearch builds a directed acyclic graph (DAG) where nodes are atomic subqueries (e.g., stock prices, financial reports) and edges capture logical and temporal dependencies. A pre-planner breaks down queries into subquery sequences, using graph traversal to control information flow and dynamically adjust paths, such as backtracking when conflicts arise‚Äîsubstantially surpassing linear chain-of-thought methods in handling complex logic.

#### 5.1.5. External Solver

The integration of RAG and reasoning is also can be achieved by incorporating external solvers, where specialized solvers, such as the Alignment-Oriented LLM-based Retrieval Method (ARM), are employed to handle the reasoning component. The retrieval process for complex problems is formulated as a global optimization task, leveraging external solvers like mixed-integer programming (MIP) to achieve structural alignment and joint optimization of data objects. Specifically, ARM first decomposes user queries into keywords that match N-grams in the dataset through an information alignment module, generating an initial set of retrieval candidates via constrained decoding. Subsequently, in the structural alignment phase, the MIP solver performs global filtering on candidate objects based on a predefined objective function that maximizes both the relevance of retrieved objects to the query and their mutual compatibility. This ensures that the selected objects not only cover the requirements of the query but also form a coherent information chain through entity or inter-table linkages. Finally, the self-verification mechanism of the LLM, combined with a beam search-based aggregation strategy, dynamically refines and consolidates multiple candidate sets, ultimately producing a retrieval collection that satisfies both semantic matching and the structural organization of the data.

ToG-2.0 achieves multi-hop expansion by integrating knowledge graphs with documents, starting from an initial entity and iteratively extending relevant entities and relations (such as corporate ownership chains and technology dependency networks) via the Edge function. This process constructs structured triple paths while simultaneously retrieving and verifying document content. By tuning the width and depth parameters, the method emulates human reasoning: broadly exploring potential associations before deeply verifying high-confidence paths. FRAG¬†(Gao et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib24)) dynamically adjusts retrieval strategies by predicting the hop range of reasoning paths based solely on the query text, thereby enhancing retrieval quality without requiring additional fine-tuning or invocation of large language models, enabling flexible and efficient retrieval optimization. FG-RAG¬†(Hong et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib33)) further expands entity coverage in graph retrieval through context-aware entity expansion, providing richer background information. Combined with query-level fine-grained summary generation, FG-RAG transforms coarse-grained graph information into highly relevant detailed content, effectively improving the performance of query-focused summarization tasks.

Although differing in design from workflow-based methods, ToG-2.0 shares key advantages with other graph-structured approaches: explicitly modeling reasoning state dependencies, supporting dynamic path generation and optimization, and enabling closed-loop interaction between retrieval and reasoning. This effectively overcomes the limitations of traditional RAG in implicit relation inference and counterfactual analysis, thereby establishing an interpretable theoretical and practical framework for knowledge reasoning.

### 5.2. Reasoning Optimization

In the previous chapter, we focused on introducing several approaches to integrate reasoning with RAG. This chapter shifts attention to how to augment the reasoning capabilities, specifically including Prompt-Based, Tuning-Based, and RL-Based strategies.

#### 5.2.1. Prompt-Based

Prompt-Based optimization is a key approach to improving RAG and reasoning system performance by using carefully designed natural language prompts. These prompts break down complex reasoning tasks into manageable steps and guide LLMs to follow specific logical structures during generation. The main advantage is that control over reasoning flow is achieved solely through prompt design, without parameter fine-tuning or reinforcement learning, preserving the model‚Äôs generalization while enhancing task-specific results.

This approach has three main features. First, task structuring: prompts explicitly decompose and control reasoning chains via zero-shot or templated designs. Techniques like Co-STORM¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44)) and WriteHere¬†(Xiong et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib99)) use role assignments, stage divisions, and operation-specific instructions to guide multi-step reasoning‚Äîsuch as proposal generation, knowledge retrieval, refinement, and validation‚Äîimproving interpretability by representing intermediate steps clearly.

Second, result reliability is improved by standardizing outputs and reducing hallucinations. Strategies include requiring citation of retrieval results, enforcing specific output formats, and integrating reflection and calibration based on retrieved knowledge. Systems like FinSearch¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)) and ActiveRAG¬†(Xu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib101)) incorporate temporal weighting, deduplication, and domain rules through prompts, enhancing consistency and logical coherence, especially in complex domains.

Third, interactive adaptability allows dynamic prompt adjustments. Special tokens (e.g., `<Search>`, `[Web-search]`) enable models to trigger tools or revise queries in real time based on intermediate results. Methods such as Agentic Reasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) and PlanRAG¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) use context-sensitive prompts and feedback loops to refine reasoning paths dynamically, maintaining coherence and accuracy in multi-hop tasks and outperforming traditional RAG methods in complex, evolving scenarios.

In summary, prompt-based optimization offers an efficient, flexible, and reliable approach to enhancing RAG+Reasoning by emphasizing task structuring, result standardization, and interactive adaptability. Its non-intrusive and broadly applicable design has established it as a mainstream strategy for optimizing LLM reasoning and serves as a foundation for future hybrid methods integrating fine-tuning and reinforcement learning. By systematically optimizing reasoning without altering model parameters through semantic structures, dynamic feedback, and symbolic constraints, this paradigm effectively manages macro-level controls like task decomposition and knowledge integration while addressing key challenges such as generation consistency, logical coherence, and external knowledge alignment. This makes prompt-based optimization a lightweight yet powerful solution for complex reasoning tasks.

Table 1. Comparison of RL-based RAG with Reasoning Methods

| Method | Base Model | RL | Parameter | Supervision | Reward Function | Policy Strategy |
| --- | --- | --- | --- | --- | --- | --- |
| PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74)) | Qwen2.5/Llama3.2 | GRPO | QLoRA | ORM | |  | | --- | | Dual rewards: | | 1. Retrieval fidelity (RfidsubscriptùëÖfidR\_{\text{fid}}italic\_R start\_POSTSUBSCRIPT fid end\_POSTSUBSCRIPT) | | 2. Response quality (RqualsubscriptùëÖqualR\_{\text{qual}}italic\_R start\_POSTSUBSCRIPT qual end\_POSTSUBSCRIPT) | | Combined: R=Œ±‚Å¢Rfid+Œ≤‚Å¢RqualùëÖùõºsubscriptùëÖfidùõΩsubscriptùëÖqualR=\alpha R\_{\text{fid}}+\beta R\_{\text{qual}}italic\_R = italic\_Œ± italic\_R start\_POSTSUBSCRIPT fid end\_POSTSUBSCRIPT + italic\_Œ≤ italic\_R start\_POSTSUBSCRIPT qual end\_POSTSUBSCRIPT | | |  | | --- | | ‚Ä¢ Group-based advantage normalization | | ‚Ä¢ PPO-style clipped objective | | ‚Ä¢ KL regularization | |
| DeepResearcher¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107)) | Qwen2.5-7B | GRPO | Full | ORM | |  | | --- | | Format compliance penalty (-1) | | + Answer F1 score | | |  | | --- | | ‚Ä¢ Reference policy constraints | | ‚Ä¢ KL divergence penalty | |
| ReSearch¬†(Chen et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib7)) | Qwen2.5-7B | GRPO | Full | ORM | |  | | --- | | Hybrid rewards: | | ‚Ä¢ Answer F1 (vs ground truth) | | ‚Ä¢ Format compliance check | | |  | | --- | | ‚Ä¢ GRPO with clip ratio 0.2 | | ‚Ä¢ Group advantage normalization (G=5) | | ‚Ä¢ Œ≤=0.001ùõΩ0.001\beta=0.001italic\_Œ≤ = 0.001 KL penalty | |
| ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17)) | Llama3.2-3B | GRPO | Full | ORM+PRM | |  | | --- | | ‚Ä¢ Answer correctness | | ‚Ä¢ Format compliance | | ‚Ä¢ Search diversity | | ‚Ä¢ Chunk matching | | ‚Ä¢ Retry behavior | | ‚Ä¢ Strategy compliance | | |  | | --- | | ‚Ä¢ Intra-group reward comparison | | ‚Ä¢ Noise-injected robustness training | | ‚Ä¢ KL constraints | |
| MMOA-RAG¬†(Chen et¬†al., [2025e](https://arxiv.org/html/2504.15909v2#bib.bib13)) | Llama-3-8B | MAPPO | Full | ORM | |  | | --- | | Shared F1 reward + penalties: | | ‚Ä¢ Excessive sub-questions | | ‚Ä¢ Document ID errors | | ‚Ä¢ Answer verbosity | | |  | | --- | | ‚Ä¢ MAPPO actor-critic updates | | ‚Ä¢ Cosine learning rate scheduling | |
| DeepNote¬†(Wang et¬†al., [2024e](https://arxiv.org/html/2504.15909v2#bib.bib85)) | Qwen2.5/Llama3.1 | DPO | Full | ORM | |  | | --- | | Implicit preference modeling | | via likelihood contrast | | |  | | --- | | ‚Ä¢ Direct Preference Optimization | | ‚Ä¢ Preference gap maximization | |
| R1-Searcher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)) | Qwen2.5/Llama3.1 | Reinforce++ | Full | ORM | |  | | --- | | Two-stage rewards: | | 1. Retrieval count + format | | 2. F1 score + format penalty | | |  | | --- | | ‚Ä¢ RAG-based rollout | | ‚Ä¢ Retrieval-masked loss | |
| KBQA-O1¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59)) | Llama3/Qwen2.5/Gemma2 | MCTS | DoRA | ORM+PRM | |  | | --- | | Composite reward: | | ‚Ä¢ Stepwise policy model score | | ‚Ä¢ Final reward model score | | |  | | --- | | ‚Ä¢ MCTS trajectory optimization | | ‚Ä¢ Q-value backpropagation | |
| DeepRetrieval¬†(Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43)) | Qwen2.5-3B | PPO | Full | ORM | |  | | --- | | Task metrics: | | ‚Ä¢ Recall@k/NDCG | | ‚Ä¢ Syntax validity | | |  | | --- | | ‚Ä¢ GAE advantage estimation | | ‚Ä¢ Distributed HybridFlow | |
| LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35)) | Llama3-8B/Gemma-9B | IPO | Full | PRM | |  | | --- | | Average Precision (AP) | | of retrieved documents | | |  | | --- | | ‚Ä¢ Identity Policy Optimization | | ‚Ä¢ Context distillation | |
| SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)) | Flan-T5-L/Llama2-7B | PPO | Full/LoRA | ORM | |  | | --- | | Action-specific: | | ‚Ä¢ EM+F1 for answers | | ‚Ä¢ Cost penalty for retrievals | | |  | | --- | | ‚Ä¢ On-policy sampling | | ‚Ä¢ PPO updates | |
| ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76)) | LLaMA3.1-8B | MCTS | LoRA | ORM+PRM | |  | | --- | | Monte Carlo step scoring | | + TD look-ahead | | |  | | --- | | ‚Ä¢ Iterative preference optimization | | ‚Ä¢ KTO loss | |
| DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)) | Qwen2.5-7B/Llama3.1-8B | Hybrid | Full | ORM+PRM | |  | | --- | | Cost-aware accuracy: | | R=‚àíC‚Å¢(o)√óT‚Å¢(st)ùëÖùê∂ùëúùëásubscriptùë†ùë°R=-C(o)\times T(s\_{t})italic\_R = - italic\_C ( italic\_o ) √ó italic\_T ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) | | C‚Å¢(o)ùê∂ùëúC(o)italic\_C ( italic\_o ): Answer correctness | | T‚Å¢(st)ùëásubscriptùë†ùë°T(s\_{t})italic\_T ( italic\_s start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ): Total retrieval cost | | |  | | --- | | ‚Ä¢ Imitation + contrastive learning | | ‚Ä¢ PPO-like calibration | |
| RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97)) | LLaMA3.1-8B | Hybrid | LoRA | PRM | |  | | --- | | Triple criteria: | | ‚Ä¢ Sufficiency | | ‚Ä¢ Utility | | ‚Ä¢ Redundancy | | |  | | --- | | ‚Ä¢ SFT + DPO | | ‚Ä¢ PRM-guided selection | |
| CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) | Skywork-Llama3.1-8B | MCTS | LoRA | PRM | |  | | --- | | Critic-estimated rewards: | | ‚Ä¢ Stepwise correctness | | ‚Ä¢ Global impact | | |  | | --- | | ‚Ä¢ MCTS simulation | | ‚Ä¢ Pairwise ranking loss | |

1ORM: Outcome-based Reward Model; PRM: Process-based Reward Model.
2Full: Full parameter tuning.

#### 5.2.2. Tuning-Based

The tuning-based approach improves the integration of RAG and reasoning by optimizing model parameters to internalize the retrieval-augmented chain-of-thought mechanism within LLMs. Current research mainly targets three goals: *retrieval pathway optimization*, *structured generation enhancement*, and *collaborative training with external modules*.

For retrieval pathway optimization, methods like CoRAG¬†(Wang et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib84)) and DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)) build end-to-end multistep reasoning frameworks through full parameter fine-tuning and multitask learning. CoRAG expands single-step QA datasets into retrieval-reasoning chains and jointly trains tasks such as sub-query generation, intermediate answer prediction, and final composition. This boosts the model‚Äôs ability to break down complex problems (e.g., multi-entity relational reasoning) and adapt retrieval strategies dynamically (e.g., query rewriting, error correction). DeepRAG combines imitation and contrastive learning with binary tree search to create efficient retrieval paths, using a DPO-style contrastive loss to reduce redundant retrieval while maintaining accuracy.

To improve structured generation, MCTS-KBQA¬†(Xiong et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib98))and Self-RAG¬†(Asai et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib4)) fine-tune models for precise special token generation. MCTS-KBQA uses supervised fine-tuning to make large language models output instructions that comply with knowledge graph protocols (e.g., SPARQL), modeling reasoning as executable tool-call sequences. Self-RAG enhances self-supervised generation control by expanding vocabulary and training the model to generate reflection tokens like retrieval triggers and relevance markers, preserving fluency and reducing factual errors. Additionally, O1-Embedder¬†(Yan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib102)) and Open-RAG¬†(Islam et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib39)) align semantic spaces via mixed fine-tuning: O1-Embedder combines generative and contrastive training with special tokens to separate generation from embedding tasks, enhancing multihop semantic understanding; Open-RAG uses QLoRA¬†(Dettmers et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib18)) quantized fine-tuning and Mixture of Experts (MoE) modules to specialize networks for single/multi-hop reasoning.

In collaborative optimization with external modules, AdaptiveRAG¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)) and CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) apply parameter isolation to balance generality and adaptability. AdaptiveRAG fine-tunes a lightweight classifier to select retrieval strategies dynamically. CR-Planner introduces a Critic model trained with contrastive loss on MCTS trajectory data to assess the long-term value of reasoning actions, prioritizing efficient solutions in tasks like mathematical reasoning.

Together, these tuning strategies restructure the parameter space to internalize retrieval-reasoning interactions effectively, enhancing the model‚Äôs ability to solve complex problems while ensuring computational efficiency and broad applicability across domains.

#### 5.2.3. RL-Based

As shown in Table¬†[1](https://arxiv.org/html/2504.15909v2#S5.T1 "Table 1 ‚Ä£ 5.2.1. Prompt-Based ‚Ä£ 5.2. Reasoning Optimization ‚Ä£ 5. Implementation and Optimization ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), Reinforcement learning (RL) has recently become pivotal for tackling long-chain reasoning in modern inference models and optimizing RAG combined with reasoning tasks. Central to these advances is the use of dynamic reward mechanisms that guide LLMs to balance knowledge retrieval and logical reasoning adaptively. RL optimization objectives generally fall into two categories: outcome-based reward modeling (ORM) and process-based reward modeling (PRM), with some hybrid approaches blending both to balance global goals and local optimizations.

The ORM paradigm focuses solely on the quality of the final output and its adherence to standards. For example, R1-Searcher¬†(Song et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib73)) employs a two-stage Reinforce++¬†(Hu, [2025](https://arxiv.org/html/2504.15909v2#bib.bib36)) training where rewards in the first stage depend on correct retrieval calls and special token generation, while the second stage directly optimizes the F1 score of answers. This encourages the model to develop strategies maximizing knowledge integration, reducing hallucinations, and enhancing accuracy in multi-hop QA beyond traditional RAG methods. Similarly, KBQA-O1 ¬†(Luo et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib59))uses MCTS with a policy network for candidate reasoning paths and a reward model evaluating logical consistency, effectively balancing exploration and exploitation in knowledge base QA.

Conversely, PRM emphasizes detailed supervision of intermediate reasoning steps. LeReT¬†(Hsu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib35)) uses the Identity Policy Optimization (IPO) algorithm, optimizing query quality by rewarding average precision (AP) of retrieved documents, boosting retrieval recall and overall multi-hop task performance. ReARTeR¬†(Sun et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib76)) extends this with a step-level binary reward model, combining Monte Carlo scoring and temporal difference (TD) methods to evaluate reasoning paths proactively, reducing logical errors and redundant retrievals, and improving accuracy on benchmarks like HotpotQA.

Moreover, influenced by DeepSeek-R1, GRPO¬†(Shao et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib70)) is also gradually being applied in scenarios combining RAG and Reasoning. GRPO is a variant of the Proximal Policy Optimization (PPO) reinforcement learning algorithm that abandons the critic model and instead estimates the baseline from group scores, significantly reducing training resources. For example, ReZero¬†(Dao and Le, [2025](https://arxiv.org/html/2504.15909v2#bib.bib17)) uses GRPO to introduce a ‚Äùretry‚Äù mechanism for LLMs, incentivizing LLMs to keep trying after an initial search failure by rewarding retry search queries. This mechanism simulates the human strategy of ‚Äùif at first you don‚Äôt succeed, try again‚Äù in information retrieval. PORAG¬†(Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74)), based on GRPO, directly optimizes retrieval quality, contextual relevance, and generation coherence through a dual reward mechanism (retrieval fidelity and response quality).

Hybrid methods merge ORM and PRM to optimize both final outcomes and intermediate steps via composite rewards. SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)) applies Proximal Policy Optimization (PPO), combining answer-level F1 rewards with penalties for excessive retrievals, balancing knowledge completeness and efficiency. RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97))advances this with multidimensional process rewards (sufficiency, utility, redundancy) and techniques like contrastive loss and Best-of-N sampling to promote efficient search decisions, even zero-shot. These hybrid strategies markedly lower retrieval costs while sustaining accuracy in complex tasks.

In addition, we can also observe that in current RL-based methods, academia focuses more on exploration with small-scale LLMs (¬°8B), among which the Qwen and Llama series are the most widely used. Overall, RL provides a flexible, scalable framework for integrating RAG and reasoning. ORM guides the discovery of globally optimal strategies, PRM enhances reasoning robustness via local refinements, and their combination addresses modular system limits. Future work may explore collaborative rewards in multi-agent settings, offline RL based on world models, and hierarchical reward decomposition for open-domain applications.

## 6. Downstream Tasks and Evaluation

While previous chapters focused on methodologies and advances in RAG combined with reasoning, this chapter shifts to tasks and evaluation. It provides a comprehensive overview and analysis of existing tasks, datasets, their current status, and emerging trends. By reviewing these resources, we highlight the landscape‚Äôs gaps and limitations in current evaluation methods. The chapter also explores key challenges in assessment frameworks, identifying shortcomings and suggesting potential improvements.

![Refer to caption](extracted/6386523/Images/sankey_diagram.png)

Figure 7. The current downstream tasks and datasets related to the combination of RAG and Reasoning show that multi-hop question answering tasks still dominate. Correspondingly, HotpotQA, 2WikiMultihopQA, and MuSiQue remain the most commonly used evaluation datasets.

### 6.1. Knowledge-Intensive Tasks

In the evaluation for RAG systems, knowledge-intensive question answering (QA) remains the primary focus (Figure¬†[7](https://arxiv.org/html/2504.15909v2#S6.F7 "Figure 7 ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")). As LLMs improve in semantic understanding and reasoning, benchmarks have expanded to cover tasks from simple fact retrieval to complex multi-step reasoning. However, evaluation methods specifically designed for RAG lag behind due to the dual challenge of assessing both retrieval-generation coherence and adaptability to dynamic knowledge bases. For example, multi-hop QA requires integrating dispersed knowledge through multi-stage retrieval while verifying logical consistency between answers and retrieval paths. This complexity increases dataset construction costs compared to purely generative tasks, keeping research centered on knowledge-intensive QA subcategories such as open-domain QA, knowledge-base QA, and multi-hop QA.

Commonly used datasets include Natural Questions (NQ)¬†(Kwiatkowski et¬†al., [2019](https://arxiv.org/html/2504.15909v2#bib.bib48)) for single-hop factual queries, HotpotQA, 2WikiMultiHopQA¬†(Ho et¬†al., [2020](https://arxiv.org/html/2504.15909v2#bib.bib32)) and Musique¬†(Trivedi et¬†al., [2022b](https://arxiv.org/html/2504.15909v2#bib.bib80)) for multi-hop QA. These benchmarks are mostly based on Wikipedia and fail to reflect the RAG demands and corresponding complexity in real-world scenarios. Some efforts have pushed evaluation boundaries, like CRUD-RAG‚Äôs¬†(Lyu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib60)) operational metrics and DomainRAG‚Äôs¬†(Wang et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib87)) domain-specific evaluations, but high costs and metric-task interdependencies limit progress. As a result, knowledge-intensive QA remains central for testing RAG robustness and practicality, highlighting a critical bottleneck: the need for innovative frameworks that balance retrieval flexibility and controlled generation to support new developments like Agentic RAG .Overall, many evaluation benchmarks are lagging behind rapid RAG+Reasoning advances, especially as LLMs grow more powerful. Specifically, the current evaluation of RAG faces the following challenges.

##### Limited Challenge

With improving LLM capabilities, many knowledge-based questions are no longer difficult, as they can be answered without external retrieval. Current multi-hop reasoning datasets, often built from artificial templates, offer limited challenge. There is an urgent need for more complex datasets reflecting real-world scenarios and practical use.

##### Lack of Specificity

Existing evaluation tasks are still predominantly focused on factual assessment and knowledge retrieval, lacking evaluations that probe deeper analytical thinking. This constraint limits the ability to measure a model‚Äôs capacity for profound reasoning and cognitive depth.

##### Task Uniformity

The majority of benchmarks are overly dependent on QA tasks, focusing on reactive, question-and-answer-based interactions. There is a pressing need to introduce tasks aligned with real-world applications, such as active information retrieval tasks based on personal knowledge or proactive knowledge discovery.

##### Insufficient Dimensions

Evaluations are primarily end-to-end, focusing solely on final outcomes. However, with the introduction of reasoning processes, RAG+Reasoning systems have become iterative, multi-step frameworks. Current evaluations are unable to assess intermediate reasoning steps or retrieval chains effectively. The absence of step-by-step supervision data limits both research and training of related methods. Furthermore, current evaluation methodologies lack comprehensive assessments of system performance trade-offs, such as computational cost and efficiency, which are critical for practical deployment.

This emergent landscape necessitates the creation of a new generation of evaluation frameworks that can address these shortcomings. Such frameworks must not only ensure the adaptability of retrieval and the controllability of generation but also integrate intermediate reasoning evaluation and efficiency metrics, paving the way for the development of more robust and efficient RAG systems suited to diverse real-world applications.

### 6.2. New Tasks on RAG+Reasoning

Recently, combining RAG with reasoning has significantly improved models‚Äô ability to tackle more realistic and challenging tasks, raising the standards for evaluation methods. This subsection examines emerging tasks that assess their combined strengths, related tasks and datasets are shown in Table¬†[2](https://arxiv.org/html/2504.15909v2#S6.T2 "Table 2 ‚Ä£ 6.2. New Tasks on RAG+Reasoning ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"). Here, ‚Äùemerging‚Äù refers not to entirely new tasks but to those with unprecedented complexity and demands. These include Deep Research tasks requiring multi-layered information integration and reasoning; PhD (Expert)-Level Complex Reasoning tasks targeting advanced scenario reasoning; and critical; domain-specific decision support tasks like medical diagnosis and legal analysis. Such tasks demand not only external knowledge retrieval but also logical consistency, coherence, and depth in reasoning.

Table 2. Tasks and Datasets under the New Trend of RAG Combined with Reasoning

|  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Task Type | Sub-Task | Dataset | Description | Scale | Construction By | Evaluation | Paper |
| Deep Research | Deep Research | Agentic Reasoning Deep Research¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) | PHD-level dataset covering finance, medicine, and law. | 15-30 domains | PhD Experts | Expert pass rate | (Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) |
| Report Generation | WildSeek¬†(Jiang et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib45)) | Info-seeking task‚Äìgoal pairs for document generation. | 100 samples | Rules/LLM/Manual | LLM | (Xiong et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib99)) |
| Report Generation | TELL ME A STORY¬†(Huot et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib38)) | fiction writing evaluation dataset: detailed prompts and long-form narratives. | 230 samples | Manual | LLM | (Xiong et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib99)) |
| Peer Review | Review-5k¬†(Weng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib92)) | ICLR 2024 peer review dataset: paper metadata and structured reviewer feedback. | 4,991 papers | OpenReview/arXiv | MSE/MAE/Acc | (Weng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib92)) |
| Report Generation | Research-14k¬†(Weng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib92)) | 2022‚Äì2024 Accepted ML papers: outlines, full texts, and cited abstracts. | 14,911 papers | Semantic Scholar + arXiv | Simulated review scores | (Weng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib92)) |
| Report Generation | SolutionBench¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)) | Engineering benchmark: constrained solutions across 8 real-world domains. | 1,050 datapoints | Manual/LLM extraction | Analytical/ Technical scores | (Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)) |
| Mathematics &  Reasoning | Math Reasoning | GPQA¬†(Rein et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib68)) | PHD-level MCQs in physics, chemistry, and biology. | 744 sets | PhD Experts | Accuracy | (Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) |
| Math Reasoning | MATH500¬†(Lightman et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib56)) | 500 math problems from the MATH test set. | 500 problems | Public repos | Pass@K | (Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)) |
| Programming | LiveCodeBench¬†(Jain et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib41)) | Programming benchmark with easy, medium, and hard problems. | 1,055 problems | Competition platforms | Pass@K | (Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)) |
| Programming | USACO¬†(Shi et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib71)) | USA Computing Olympiad problems, testing algorithms and coding. | 307 problems | USA Computing Olympiad | Pass@K | (Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) |
| Math Reasoning | TheoremQA-Math¬†(Hongjin et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib34)) | BRIGHT subset: theorem-based math problems. | 206 problems | STEM datasets | Accuracy | (Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) |
| Programming | Gorilla¬†(Patil et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib65)) | API-aware code generation from HuggingFace, Torch Hub, TensorFlow Hub docs. | 1,600 APIs | Manual | AST matching | (Srinivas and Runkana, [2025](https://arxiv.org/html/2504.15909v2#bib.bib74)) |
| Math Reasoning | OlympiadBench¬†(He et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib30)) | Olympiad-level math competition problems. | 1,000 problems | Competitions | Accuracy/F1 | (Zhu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib110)) |
| Complex Reasoning | ComplexWebQA¬†(Talmor and Berant, [2018](https://arxiv.org/html/2504.15909v2#bib.bib77)) | Multi-step reasoning over web queries with cross-document integration. | 34,689 queries | Web snippets | Accuracy | (Hu et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib37)) |
| Demanding  Retrieval | Domain Retrieval | StackEcon & StackBio¬†(Hongjin et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib34)) | Biology and economics StackExchange questions for complex retrieval. | 206 queries | StackExchange | nDCG@K | (Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) |
| Active Retrieval | AR-Bench¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)) | Active retrieval benchmark with four sub-tasks. | 8k/sub-task | Synthetic | Accuracy | (Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)) |
| Real-time | TAQA¬†(Zhao et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib105)) | QA dataset with time-evolving answers. | 10K-100K rows | Human-curated | LLM | (Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)) |
| Real-time | FreshQA¬†(Vu et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib81)) | Dynamic fact QA benchmark with evolving answers | 600 samples | Mixed sources | LLM | (Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15)) |
| Domain Retrieval | PubMed¬†(Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43)) | PICO-based medical search dataset linking reviews to PubMed. | 21k+ samples | Systematic reviews | Recall@K | (Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43)) |
| Domain Retrieval | Trial search¬†(Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43)) | PICO-based clinical trial search linked to ClinicalTrials.gov. | 7k+ samples | Manually | Recall@K | (Jiang, [2025](https://arxiv.org/html/2504.15909v2#bib.bib43)) |
| Domain Retrieval | FinSearchBench-24¬†(Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)) | Financial retrieval benchmark covering stocks, rates, policy, trends. | 1,500 queries | Manually | Accuracy | (Li et¬†al., [2024c](https://arxiv.org/html/2504.15909v2#bib.bib51)) |
| Decision &  QA | Business | DQA¬†(Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) | Decision QA benchmark with business scenarios in enterprise settings. | 301 pairs | video games | Accuracy | (Lee et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib49)) |
| Medical | CMB-Clin¬†(Wang et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib88)) | CMB subset for clinical diagnosis reasoning in Chinese medical cases. | 74 cases | Textbooks/diagnostic materials | LLM/Expert | (Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)) |
| Medical | MM-Cases¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)) | Medicine cases generated by GPT-4o-mini, verified by doctors. | 609 cases | LLM/doctor-reviewed | LLM/Expert | (Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)) |
| Medical | TCM-Cases¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)) | TCM patient cases generated by GPT-4o-mini, verified by doctors. | 130 cases | LLM/doctor-reviewed | LLM/Expert | (Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)) |

#### 6.2.1. Deep Research

From the perspective of integrating RAG and reasoning, Deep Research tasks exemplify complex downstream applications. They require models to handle open-ended retrieval, produce long-form, structured text, and synthesize multi-source information through deep reasoning. This section analyzes their key features, evaluation datasets, and metrics.

At the core of Deep Research tasks lies the mission of addressing complex informational queries. These tasks are distinguished by several key attributes:

First, dynamic interactivity is essential. Models engage in iterative dialogue to uncover latent user needs or ‚Äùunknown unknowns‚Äù. For example, the Co-Storm¬†(Jiang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib44)) framework enables collaboration with multiple language model agents to explore information gradually, easing user cognitive load and capturing unmet needs more accurately.

Second, integrating information from multiple sources is crucial. Models must consolidate diverse data to provide comprehensive coverage. For instance, uses dynamic mind maps to structure knowledge and produce cohesive reports, ensuring accuracy and completeness.

Third, expert-level accuracy is required. Many tasks demand domain expertise, expecting models to perform like human specialists. The Agentic Reasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) framework illustrates this with high-stakes scenarios like medical treatment design or legal analysis, where outputs are judged on correctness, depth, and coherence.

Fourth, multi-modal reasoning is often necessary. Deep Research tasks involve varied data types‚Äîtext, code, knowledge graphs‚Äîand dynamic tool use such as web searches or code execution to enhance reasoning.

Finally, handling multiple real-world constraints is vital. Tasks may require generating practical solutions under specific conditions, like designing hospitals in challenging environments with factors like heavy rainfall and seismic activity, as seen in the DeepSolution framework. This ensures outputs are feasible and relevant.

To ensure the diversity and complexity of Deep Research tasks, their evaluation relies on datasets drawn from multiple domains. A few notable examples include:

WildSeek Dataset¬†(Jiang et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib45)): This dataset is constructed from real-world user information-seeking scenarios and comprises 100 data points covering 24 fields, including economics, computer science, and law. Each data point is characterized by a topic, user goal, and domain label. For example: ‚ÄùDomain: Economics; Topic: Development of a Shared Trading Currency; Goal: Investigate how a new shared currency could eliminate transaction costs‚Äù. WildSeek effectively evaluates models‚Äô competence in dynamic interaction and multi-source information integration.

GAIA¬†(Mialon et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib63)). The GAIA Benchmark, developed jointly by Meta AI, Hugging Face, and others, is a comprehensive evaluation framework designed to assess general AI assistants‚Äô ability to handle real-world problems. It features 466 carefully crafted tasks spanning language reasoning, visual perception, multi-agent collaboration, and adaptability, focusing on key skills like reasoning, multimodal processing, web browsing, and tool use. GAIA measures performance across dimensions such as task execution, adaptability, collaboration, generalization, and real-world reasoning with metrics like completion rate, response quality, efficiency, and robustness. Unlike traditional benchmarks, it emphasizes robustness and reliability in everyday scenarios, supports zero-shot evaluation, prevents data contamination, and is widely used in research and industry to guide AI development.

SolutionBench¬†(Li et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib55)): This dataset spans eight engineering domains, including environmental, mining, and transportation engineering. Each instance presents a complex engineering problem with specific constraints. For example: ‚ÄùDesign a safe and efficient hospital construction plan in a region with 3000mm annual rainfall, expansive soils, and frequent seismic activity.‚Äù\* SolutionBench evaluates models‚Äô ability to address multi-constraint problems and integrate specialized knowledge effectively.

The current evaluation system for DeepResearch faces the dual challenges of scarce specialized testing tasks and the difficulty of assessing complex, lengthy reports: On one hand, existing benchmark tests only cover basic capabilities and lack systematic evaluation standards in specialized scenarios like business analysis and policy assessment; on the other hand, the multimodal integration, logical chain verification, and domain adaptability testing of long reports pose technical bottlenecks for traditional assessment methods, necessitating the development of new evaluation tools that integrate logic graphs, dynamic scenario simulation, and domain knowledge bases.

In the future, the evaluation system will evolve into a multidimensional framework, including the construction of a three-level indicator matrix covering basic capabilities, reasoning levels, and application value. Overcoming these evaluation bottlenecks requires both technological innovation and joint standard-building efforts. This concerns not only the reliability validation of intelligent research tools but also the reshaping of research evaluation paradigms and industrial application boundaries.

#### 6.2.2. PhD (Expert)-Level Complex Reasoning

The integration of RAG with advanced reasoning has become essential for tackling expert-level, complex cognitive tasks, particularly at the PhD level. These tasks, including competitive programming, theorem-driven proof reasoning, and cross-disciplinary knowledge retrieval, require multi-layered logical inference and precise coordination between dynamic retrieval and domain-specific knowledge. PhD-level reasoning differs from standard evaluations across three dimensions: knowledge intensity, procedural rigor, and domain specificity. Knowledge intensity demands dynamic access to deep, specialized knowledge, such as analyzing dynamic programming time complexity or applying algebraic topology theorems‚Äîneeds that surpass general corpora and call for domain-specific knowledge graphs and retrieval methods. Procedural rigor involves mathematical precision in multi-step proofs, requiring logical consistency in symbolic manipulation, theorem use, and counterexample refutation, as seen in international math competitions. Domain specificity reflects tailored reasoning methods, e.g., handling synchronization in concurrent programming or employing tensor calculus in quantum field theory.

Evaluation systems for such tasks are inherently multi-layered and multimodal. The USACO Benchmark¬†(Shi et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib72)) offers a graduated difficulty scale for programming reasoning, testing both correctness and algorithmic constraints like time complexity. TheoremQA-Math¬†(Chen et¬†al., [2023](https://arxiv.org/html/2504.15909v2#bib.bib10)) links formalized math problems to theorem libraries, demanding verifiable mappings between theorem applications and calculations. Cross-disciplinary datasets like StackBio and StackEcon¬†(Li et¬†al., [2024b](https://arxiv.org/html/2504.15909v2#bib.bib54)) assess models‚Äô ability to extract critical knowledge from dense, domain-rich documents, serving as strong tests for domain-oriented retrieval accuracy.

Modern evaluation surpasses traditional end-to-end tests by combining process and outcome validation. Frameworks like CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) use dual models‚Äîa Sub-Goal Critic to score reasoning chains and an Execution Critic to evaluate retrieval‚Äîallowing fine-grained step monitoring. For example, in dynamic programming, key steps like formulating state transitions and retrieving boundary conditions receive targeted feedback. Similarly, Search-O1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)) quantifies knowledge completeness by tracking uncertainty indicators (e.g., tentative language), measuring confidence and accuracy. Outcome validation maintains strict correctness benchmarks in programming and combines metrics like F1 scores with expert review in open-domain scientific QA to ensure precise understanding of domain-specific terms.

### 6.3. Challenges and Future Directions

#### 6.3.1. Complex Domain Tasks

Recent advances in RAG have provided novel solutions for more complex tasks in professional domains. These downstream tasks transcend the limitations of traditional question-answering models that rely solely on simple retrieval-generation patterns, involving challenges such as real-time information acquisition, integration of domain expertise, and dynamic decision-making support. The nature of these tasks can be characterized along three interrelated dimensions: (1) temporal dynamics, emphasizing the rapid changes in data and reasoning environment; (2) domain specificity, focusing on deep integration of industry knowledge and structured data; and (3) reasoning chain complexity, reflecting requirements for multi-stage reasoning and fine-grained decomposition of queries.

To rigorously evaluate such systems, innovative benchmarking approaches have been proposed. The FinSearchBench-24 dataset, for example, encompasses five months of market data variations, integrating multi-variable interactions across stock, policy, and industrial sectors, and includes over 1,500 multiple-choice questions, thereby surpassing the constraints of traditional static benchmarks. The evaluation adopts a hierarchical and quantitative methodology: the foundational level measures model accuracy and response latency; the intermediate layer assesses the temporal sensitivity of information relevance and the contribution of retrieval mechanisms to reasoning outcomes; and the advanced layer employs ablation studies to highlight performance variances under dynamic temporal decay. This multifaceted evaluation not only differentiates surface-level retrieval capabilities but also rigorously measures the synergy between reasoning quality and temporal context, furnishing theoretical and practical foundations for long-term stability and predictive accuracy in complex domain systems.

Experimental findings further reveal that establishing long-term evaluation protocols with temporal weighting functions is indispensable for adapting to realistic dynamic environments. Nonlinear declines in decision accuracy, observed when extending relevance windows from 72 to 168 hours, emphasize the importance of factoring temporal decay into assessment frameworks. Future work should extend these evaluation protocols to high-stakes domains such as medical diagnostics and legal consultation, where the standardization of interpretability metrics will critically support the evolution of RAG+ reasoning systems toward robust and trustworthy decision-assistance platforms.

![Refer to caption](extracted/6386523/Images/cost.png)

Figure 8. From LLM to RAG and then to RAG+Reasoning, performance improvement comes with additional cost.

#### 6.3.2. Decision Support and Active Retrieval

The expansion of RAG+Reasoning frameworks into specialized tasks has fostered two complementary research paradigms: decision optimization and active retrieval. In the decision optimization category, systems must leverage heterogeneous structured data, rule bases, and objective functions to formulate optimal strategies. Representative systems like PlanRAG formalize Decision Question Answering (Decision QA) tasks targeting enterprise-level scenarios including supply chain optimization, industrial resource allocation, and market price regulation. These tasks require planning multimodal reasoning paths where models iteratively retrieve data from relational and graph databases, integrate intricate business rules, and iteratively refine decision-making paths through replanning mechanisms. To evaluate such capabilities, the Decision QA (DQA) benchmark creates dual database versions (MySQL and Neo4j) derived from economic systems in strategy games, assessing cross-structured generalization. The evaluation consists of a three-tier framework: the core tier measures answer accuracy; the intermediate layer diagnoses error types to identify system bottlenecks; and the foundational tier focuses on retrieval efficiency and the impact of replanning frequency. This structured evaluation framework not only tracks performance but also offers actionable insights for system refinement.

Conversely, the active retrieval evaluation addresses the challenge of dynamically determining when and how to invoke retrieval under complex multimodal contexts. Unlike rigid traditional RAG systems, UAR applies lightweight classifiers for fast, accurate triggers, improving performance in time-sensitive or creative tasks. Tested on AR-Bench, it combines binary trigger accuracy with GPT assessments, exact matches, and human reviews, boosting adaptability across diverse contexts.

Emerging trends in these evaluation paradigms indicate a shift from static, rule-based frameworks to dynamic system simulations, as exemplified by DQA‚Äôs use of game engine-generated datasets to simulate realistic environments. Similarly, active retrieval tasks progress from simple retrieval trigger decisions toward collaborative multi-criteria decision-making. Evaluation methodologies are concurrently evolving from singular performance metrics to multidimensional matrices comprising core effectiveness, diagnostic error distributions, and economic cost measures.

## 7. Cost and Risk

Integrating reasoning into RAG systems is neither effortless nor purely beneficial. Recent trends have exaggerated its advantages while downplaying the costs and risks. This trade-off between performance and cost is crucial. This section examines the expenses and misuse risks linked to adding reasoning to RAG systems. As shown in Figure¬†[8](https://arxiv.org/html/2504.15909v2#S6.F8 "Figure 8 ‚Ä£ 6.3.1. Complex Domain Tasks ‚Ä£ 6.3. Challenges and Future Directions ‚Ä£ 6. Downstream Tasks and Evaluation ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), the cost of moving from LLM to RAG, then to RAG + Reasoning, incurs an inevitable ‚Äùinvisible tax‚Äù. Though often hidden by performance gains, this cost is vital in assessing these methods‚Äô overall practicality and efficiency.

The shift from LLM to RAG moves from simplicity to enhanced knowledge handling by incorporating external information. A basic LLM provides direct, efficient answers with low latency and token use but is limited to pre-trained knowledge, restricting complex or up-to-date queries. RAG overcomes this by adding a vector database for external retrieval, vastly expanding response scope and reliability. However, this requires substantial data processing, storage, and introduces higher latency and token costs due to data chunking, encoding, indexing, and retrieval overhead.

Advancing from RAG to RAG + Reasoning adds multi-step reasoning capabilities, enabling complex task handling, autonomous decisions, and more context-aware responses through intricate reasoning. This comes at the expense of increased delays, token consumption, processing demands, and greater complexity in system integration and maintenance. The reasoning layer‚Äôs autonomy also brings opaqueness, unpredictability, and heightened security and reliability risks. These challenges highlight the necessity of carefully balancing effectiveness against costs when adopting RAG + Reasoning in real-world applications.

![Refer to caption](extracted/6386523/Images/cost_diagram.png)

Figure 9. Cost quadrant diagram of retrieval and reasoning requirements

### 7.1. Cost Trade-off in RAG+Reasoning

Figure¬†[9](https://arxiv.org/html/2504.15909v2#S7.F9 "Figure 9 ‚Ä£ 7. Cost and Risk ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review") illustrates typical works combining RAG and Reasoning, showing retrieval and reasoning demands alongside token consumption. While integrating dynamic knowledge retrieval with multi-step reasoning greatly improves accuracy in more complex tasks, the resulting systemic costs are often underestimated in research and practice. These costs grow non-linearly, causing serious efficiency bottlenecks in real-world use. The tradeoff between effectiveness and efficiency stems from RAG+Reasoning‚Äôs architecture: multi-stage task decoupling, dynamic path planning, and intermediate state preservation. These features improve reasoning quality but trigger cascading increases in computational resources, token usage, and reduced retrieval efficiency. This section explores these implicit tradeoffs from the angles of resource use, token consumption, and retrieval efficiency.

#### 7.1.1. Non-Linear Growth of Computational Resources

The RAG+Reasoning framework separates retrieval and reasoning into multiple stages, causing computational demands to grow non-linearly. Dynamic chain-of-reasoning methods execute multiple LLM generations and retrievals per inference, resulting in complexity far exceeding baseline models. Fixed-length reasoning chains trigger repeated retrieval and generation calls, increasing resource needs with task complexity. More advanced techniques like MCTS-guided methods add rounds of candidate path generation and evaluation, further multiplying runtime and memory usage on GPUs compared to linear methods. Even simpler multi-step planning tasks incur much higher overhead than single-stage retrieval models due to extra graph construction and analysis. While this resource intensity improves inference accuracy, it poses serious scalability challenges under limited resources as computational costs grow superlinearly with model size, retrieval chain length, and task complexity.

#### 7.1.2. Implicit Token Inflation

Multi-step reasoning frameworks inherently cause significant token inflation through iterative intermediate processes like thought chains, retrieved documents, and verification feedback. Active learning setups consolidate multiple intermediate results‚Äîretrieved documents, counterfactuals, multi-round validations‚Äîleading to token usage well beyond typical limits. Chain-based retrieval also generates token bloat due to exhaustive candidate path exploration. Iterative reasoning path selection, expansion, and evaluation add heavy token overhead in tasks needing deep reasoning chains involving extensive sequence generation and evaluation. Token usage grows exponentially with task complexity and increases further when intermediate reasoning favors depth or breadth. This inflation raises API costs and memory demands, especially in long-text generation like Deep Research ¬†(Zheng et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib107)).

#### 7.1.3. Marginal Decline in Retrieval Efficiency

Dynamic retrieval improves knowledge precision but suffers diminishing efficiency as task complexity increases. Adaptive methods reduce retrievals for simple tasks but still require multiple iterations for complex ones, adding significant overhead compared to standard RAG. The tradeoff between retrieval quality and frequency further limits efficiency. High-accuracy retrieval methods incur heavy computational and time costs, negating their efficiency benefits. Even advanced retrieval-trigger optimizations can‚Äôt fully remove this overhead due to extra training and deployment costs¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)). This natural efficiency ceiling highlights ongoing challenges in balancing retrieval accuracy and resource use, especially in large, complex tasks.

#### 7.1.4. Toward a Cost Model Framework

Against this backdrop, the development of fine-grained cost models becomes a necessary precondition for balancing effectiveness and efficiency. Existing evaluation metrics, which often rely on single-task performance indicators (such as Exact Match or F1) or coarse-grained runtime statistics, lack the comprehensiveness to jointly model computational resources, token flow, and retrieval overhead. Consequently, they fail to quantify the true tradeoffs in reasoning mechanisms. For instance, while multi-hop reasoning may improve task accuracy, these improvements are frequently offset by exponential growth in token consumption and latency relative to baseline methods. A fine-grained cost model would enable researchers and practitioners to more accurately evaluate the real benefits of reasoning-centric frameworks while addressing the underexplored interplay between computational cost and task performance.

### 7.2. Potential Risk of Over-Thinking

In the process of developing deep thinking models, ‚Äùoverthinking‚Äù poses a key risk to system efficiency and reliability¬†(Fan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib20); Sui et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib75); Chen et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib11); He et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib31); Wang et¬†al., [2025c](https://arxiv.org/html/2504.15909v2#bib.bib82); Cuadron et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib16)), and this issue is further amplified after combining with RAG. It appears as redundant reasoning steps, excessive validation of known conclusions, or unnecessarily broad retrieval scopes, wasting computational resources, increasing error propagation, and degrading performance. For example, in financial risk assessment, an LLM with RAG might retrieve multiple similar market reports and repeatedly verify the same economic indicators rather than focusing on core risks, leading to delayed decisions. This stems from an imbalance between reasoning and retrieval: after accessing external knowledge, the model can enter a ‚Äùself-validation loop,‚Äù repeatedly parsing overlapping or contradictory documents. The generation module, seeking reliability, may trigger further retrievals, creating a feedback loop that worsens inefficiency. This issue is critical in real-time systems like medical diagnosis, where over-retrieval of irrelevant literature can delay urgent decisions.

Case studies show the impact of overthinking¬†(Sui et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib75)). In legal document interpretation, early reasoning errors can amplify through the retrieval-generation loop, causing retrieval along incorrect paths and yielding illogical conclusions. This error propagation is evident in systems like the Search-o1¬†(Li et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib52)), where flawed information extraction misguides subsequent reasoning. In industrial equipment manual interpretation, overextended reasoning with highly similar documents risks obscuring critical parameter differences, increasing procedural errors. These examples illustrate that overthinking not only hampers knowledge integration but also creates safety hazards in practical applications.

To mitigate these risks, researchers propose multiple optimization frameworks. ReaRAG¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50)) limits reasoning chain length and incorporates self-reflection to prune invalid branches. A simple and effective way is to use a two-stage filtering process, first narrowing documents by metadata, then validating fragment relevance, reducing redundant information‚Äîfor instance, retrieving only relevant legal clauses rather than entire regulatory texts. The DeepSeek R1¬†(Guo et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib27)) applies reinforcement learning with distillation to penalize redundant steps, cutting repeated formula validation in math proofs by over 40%. These approaches transform open-ended reasoning into controlled, goal-directed processes, using methods like attention weight analysis to measure information gain or confidence functions to evaluate reasoning paths.

Current research balances constraints with model creativity. Knowledge graph-guided reasoning is tested in clinical trials to prioritize key medical features over exhaustive literature retrieval¬†(Chen et¬†al., [2025d](https://arxiv.org/html/2504.15909v2#bib.bib12)). Causal reasoning models aim to break error chains; for example, in financial forecasting, causal graphs restrict reasoning to logically relevant macroeconomic links. Adaptive stopping strategies adjust reasoning depth in customer service‚Äîsimple queries use preset templates, complex issues activate multi-hop reasoning. These advances reshape retrieval-augmented reasoning, with the core challenge being to develop evaluation frameworks that avoid both ‚Äùcognitive stagnation‚Äù from excessive constraints and ‚Äùcognitive overload‚Äù from insufficient control.

Future progress will integrate cognitive science with computational modeling. By mimicking human ‚Äùintuition-verification‚Äù decision-making, LLMs could switch seamlessly between rapid response and deep reasoning. In high-risk fields like industrial fault diagnosis, such hybrid models can quickly propose contingency plans after initial retrieval while verifying their validity through deeper analysis. This layered approach reduces overthinking risks and offers a safe, controllable path for applying LLMs in critical industries.

## 8. Practical Guide

![Refer to caption](extracted/6386523/Images/practical_guide.png)

Figure 10. Practical guide to synergizing RAG and Reasoning

The combination of RAG and Reasoning is not a one-size-fits-all solution; it requires careful evaluation of each scenario‚Äôs unique needs. As a rapidly evolving and relatively new field, practical applications are still limited, making best practices hard to define. This chapter abstracts and summarizes the key traits of typical RAG+Reasoning application domains and offers practical guidelines for system design based on these features. It provides recommendations on leveraging RAG‚Äôs strengths with Reasoning, highlighting priorities, pitfalls to avoid, and current opportunities (Figure¬†[10](https://arxiv.org/html/2504.15909v2#S8.F10 "Figure 10 ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review")). The goal is to promote wider adoption and effective use of this technology in diverse, complex real-world settings.

### 8.1. Domain characteristics

As illustrated in the left part of Figure¬†[10](https://arxiv.org/html/2504.15909v2#S8.F10 "Figure 10 ‚Ä£ 8. Practical Guide ‚Ä£ Synergizing RAG and Reasoning: A Systematic Review"), we develop a seven-dimensional feature system based on the three core stages of RAG‚Äîquery, retrieval, and generation‚Äîto systematically analyze challenges and adaptation needs across various industries. The query stage emphasizes the complexity of intent understanding and the demand for advanced reasoning, recognizing that industries differ in query abstraction and specificity; some require quickly capturing implicit, deep intentions, while others need complex reasoning. Effective preservation of original semantic meaning during understanding and reasoning is key to improving RAG performance. Retrieval focuses on the system‚Äôs adaptability to diverse and dynamic knowledge sources, which vary from rich multi-domain data to rapidly updating information; frequent updates and fragmented knowledge present challenges that demand effective integration to ensure consistent support for generation. The generation stage requires high-quality outputs, with strict control over hallucinations‚Äîespecially critical in sensitive fields like healthcare and law‚Äîalong with varying latency requirements for real-time or delayed responses. Explainability and traceability at this stage are essential for system credibility and serve as key evaluation metrics. This comprehensive framework reveals technical bottlenecks and guides improvements, and is applied to analyze four representative domains: finance, healthcare, law, and personal assistants.

#### 8.1.1. Finance

In the finance domain, user queries typically focus on structured needs like investment decisions and risk forecasting. While intent understanding is moderately complex, the system must perform advanced reasoning amid rapidly changing market conditions, relying heavily on external knowledge and frequent updates. For example, portfolio return forecasting integrates time series analysis, policy interpretation, and cross-market reasoning. Retrieval demands handling diverse data sources‚Äîreal-time market data, annual reports, and regulatory filings‚Äîwith update cycles often measured in minutes. During generation, strict latency and hallucination control are crucial, as outputs must include decision-making suggestions with full data traceability. Investment research reports, for instance, require annotated key indicators, their data sources, and computation logic to ensure transparency and regulatory compliance. High latency control and robust traceability are essential to maintain transparency and adherence to financial regulations.

#### 8.1.2. Healthcare

Healthcare queries involve complex medical semantic parsing, often with ambiguous terms or incomplete symptoms. For example, ‚Äùpersistent chest pain with shortness of breath‚Äù requires multi-hop reasoning across cardiology, pulmonology, and emergency medicine. Retrieval must integrate electronic health records, medical imaging, and up-to-date clinical guidelines. In generation, hallucination tolerance is minimal‚Äîerrors in drug dosages or protocols risk malpractice. Therefore, accuracy, timeliness, and explainability are paramount, with every decision step traceable and verifiable.

#### 8.1.3. Legal Services

Legal consultations often require interpreting statutes and citing cases, balancing precise legal terms with natural language nuances. Retrieval depends on structured, infrequently updated sources like case law databases and local regulations. Generation demands accuracy‚Äîfor instance, drafting contract clauses must precisely cite specific statutes (e.g., Article 472 of the Civil Code) down to the paragraph level for traceability. Explainability is essential, with traceability usually above 95%, and probabilistic language avoided to comply with strict judicial documentation standards.

#### 8.1.4. Personal Assistants

This domain features diverse, dynamic user needs, including schedule management, real-time navigation, and open-domain conversations. Accurate intent disambiguation through contextual awareness is crucial. Retrieval integrates fragmented sources like user behavior logs, geolocation, and social media. Generation latency varies: weather updates require sub-second responses, while travel planning can tolerate 5+ seconds. Hallucination tolerance depends on context‚Äîcreative outputs are acceptable for recipes but not for flight information, which demands full accuracy. This necessitates adaptive verification in the RAG system. Though intent complexity is lower than in healthcare or legal fields, the domain‚Äôs interaction diversity requires heavy reliance on external knowledge and dynamic balancing of latency and accuracy.

### 8.2. Do‚Äôs and Don‚Äôts

Building on aforementioned domain characteristics, we further identify six common scenarios, and derive technical adaptation principles for each. This section outlines key optimization strategies (Do‚Äôs) and prohibitions (Don‚Äôts) , to guide the co-design of RAG and reasoning.

#### 8.2.1. Structured Reasoning Scenarios

For scenarios requiring multi-step logical decomposition and structured knowledge dependency, such as *portfolio return prediction*, Chain-of-Thought (CoT) task decomposition and knowledge graph (KG)-driven graph reasoning approaches should be employed. Complex problems should be broken into verifiable sub-tasks, such as coupling market trend analysis with policy impact assessment, while leveraging knowledge graph constraints to ensure logical completeness and auditability. It is essential to incorporate a temporal validation layer to cross-check the consistency of timestamp-sensitive information (e.g., real-time market data or emergent regulatory policies) within a dynamic knowledge base. Approaches that exclude retrieval-based verification of salient features must be avoided, as they may lead to reasoning biases arising from the absence of structured knowledge anchors (e.g., critical indicators from financial statements). Furthermore, the reasoning space of LLMs should be constrained within domain-specific knowledge frameworks to prevent irrelevant or invalid deductions.

#### 8.2.2. Dynamic Demand-Responsive Scenarios

For scenarios characterized by rapidly shifting demands and user preference variability, such as *itinerary planning and multimodal interaction in personal assistant services*, a dynamic adaptation mechanism based on prompt engineering is recommended. By dynamically associating fragmented knowledge units (e.g., user behavior history and real-time traffic updates) with semantic templates and employing heuristic rules for search-space pruning (e.g., prioritizing locally updated information within the past 24 hours), the system can balance contextual adaptability with response speed. Model fine-tuning or reinforcement learning (RLHF/DPO)-based strategy updates should be avoided due to their lengthy iterative cycles and computational overhead, which cannot meet real-time responsiveness requirements, such as millisecond-grade reaction times for last-minute destination changes. Lightweight caching architectures should be implemented within the retrieval system, prioritizing frequently accessed knowledge fragments, such as operating hours of popular tourist attractions, to achieve an equilibrium between dynamism and stability.

#### 8.2.3. Deterministic Decision-Making Scenarios

In scenarios requiring a single, reliable conclusion, such as *clinical diagnosis generation in the healthcare domain*, a multi-level deterministic assurance system should be established. Time-validation layers can filter outdated knowledge (e.g., therapies no longer approved), while field-sensitive retrieval modules trigger predefined decision rules conforming to up-to-date clinical guidelines (e.g., those codified within the latest version of the International Classification of Diseases [ICD]). Knowledge graph path constraints should restrict the reasoning process to validated causal links within medical logic (e.g., linking symptom patterns to laboratory test results within corroborated diagnostic pathways), thereby minimizing the likelihood of deviations from standard protocols. Probabilistic exploration strategies that generate alternative hypotheses (e.g., speculative differential diagnoses for atypical pneumonia) should be strictly disallowed to avoid clinical misjudgments. Additionally, delegating decision-making authority to external classification models must be avoided to maintain end-to-end explainability and a clear causal link in the decision-making pipeline.

#### 8.2.4. Time-Sensitive Scenarios

In tasks highly sensitive to response delays, such as *real-time risk warnings and trading decisions in the financial sector*, heuristic rules should be employed to prioritize indexing of frequently queried knowledge units (e.g., volatility indices and liquidity indicators) at the top of the search hierarchy. Directed retrieval expansion strategies that preload potentially associated information (e.g., contractual clauses of derivative instruments tied to underlying assets) can further reduce latency in multi-turn interactions. Monte Carlo Tree Search (MCTS) and other sample-based algorithms are ill-suited for such scenarios due to the excessive computational complexity caused by branch expansion, rendering them infeasible within tight time constraints (e.g., milliseconds). Similarly, the invocation of complex mathematical solvers (e.g., numerical solutions for stochastic differential equations) can introduce uncontrollable delays and should be replaced with lightweight rule-based mechanisms (e.g., threshold-triggering mechanisms based on historical volatility ranges).

#### 8.2.5. Risk-Sensitive Scenarios

For scenarios with minimal tolerance for errors, such as *contract clause generation and citation of judicial interpretations in the legal sector*, a dual-layer defensive mechanism must be employed. A pre-action review layer should validate the compliance of generated content with statutory standards (e.g., ensuring consistency between liability clauses and Article 577 of the Civil Code), while a reliability validation layer performs cross-referencing validation across multiple sources (e.g., aligning Supreme Court precedents with regional court guidelines) to resolve potential conflicts. Retrieval systems must include version control modules to track and update legal references (e.g., automatically flagging repealed local statutes). Unconstrained reinforcement learning-based text generation methods must be avoided, as their exploratory nature risks violating the normative requirements of legal documents (e.g., generating presumptive liability terms unsupported by judicial interpretations). All decision-making actions must pass through deterministic rule engines to filter inadmissible outputs, and the system should never execute decision actions autonomously, such as generating legally binding arbitration notices without oversight.

#### 8.2.6. Complex Path Exploration Scenarios

In exploration tasks involving multiple possible trajectories, such as *differential diagnosis and therapeutic pathway optimization in medicine*, weighted ranking search algorithms should balance search depth and breadth. Knowledge graph topology can guide prioritization (e.g., standard treatment procedures for acute coronary syndrome), while Monte Carlo Tree Search can extend exploration into uncommon differential paths (e.g., rare genetic metabolic disorders). Dynamic pruning threshold functions should be designed (e.g., adjusting the scope of differential diagnosis based on patient history) to eliminate low-confidence hypotheses in real time, thereby controlling computational scale. Brute-force searching of all potential paths (e.g., concurrently testing hundreds of pathogens for nonspecific symptoms) should be avoided to prevent exponential computational scaling. Careful handling of specific token triggers during retrieval (e.g., avoiding spurious associations between ‚Äùfever‚Äù and unrelated oncological hyperthermia research) is critical to maintaining logical coherence in diagnostic reasoning.

### 8.3. Opportunity Points

Based on the Do‚Äôs and Don‚Äôts of current technologies analyzed in the previous section, there remain numerous directions with substantial academic value and application potential that have yet to be fully explored. This section systematically discusses several promising opportunity points across three dimensions: *data and indexing*, *models and methodologies*, and *application services*.

#### 8.3.1. Data and Indexing

##### Cold-Hot Tiered Indexing and Dynamic Context Management

The challenge of managing massive and highly heterogeneous data resources lies in devising an effective *cold-hot tiered indexing* mechanism that prioritizes data according to their frequency of use and importance. Such a mechanism not only demands classification of data based on timeliness and access frequency but also requires integration with dynamic context management. This allows the system to intelligently retrieve the most relevant data according to the immediate context.

Moreover, a dynamically updated indexing mechanism can mitigate the loss of data timeliness, which often leads to deteriorated inference accuracy. By ensuring access to the most recent and task-appropriate data, this approach reduces redundancy and incorrect retrievals associated with static indexing. When combined with automated task scheduling and resource allocation strategies, fine-grained real-time inference support can be achieved, significantly enhancing the system‚Äôs overall efficiency.

##### Cross-Institution Knowledge Base Construction

The construction of cross-institution or cross-domain knowledge bases offers new opportunities for advancing RAG+Reasoning research. At the core of large-scale cross-institutional knowledge bases lies the optimization of data integration and sharing mechanisms. This entails addressing challenges such as data security and privacy while adopting standardized data interfaces or leveraging federated learning paradigms to enable multidimensional data integration.

Through semantic alignment across multiple sources, entity resolution, and concept abstraction, cross-institutional knowledge can be transformed into authoritative and richly contextualized knowledge bases. These enhanced repositories provide robust contextual support for reasoning tasks and can deliver deeper insights in areas such as healthcare, finance, and urban management.

##### Fine-Grained Layering and Confidence Grading

In scenarios where retrieval and reasoning operate synchronously, the *interpretability* and *reliability* of generated outcomes are paramount. Fine-grained layering of data and indices, along with confidence grading of retrieval results, enables the system to selectively use the most trustworthy and relevant subsets of data during different stages of reasoning. This approach fosters transparency and traceability in final decisions or generative outputs.

For instance, in medical diagnosis scenarios, confidence grading can initiate additional verification or expert review in high-risk cases. In the legal domain, confidence layering systematically presents key evidence and identifies sources of uncertainty, reducing reasoning vulnerabilities and minimizing the risk of erroneous conclusions caused by information ambiguity.

#### 8.3.2. Models and Methodologies

##### Event-Driven Active Retrieval

Traditional retrieval mechanisms are predominantly passive. However, *event-driven active retrieval* presents a promising exploration avenue. By monitoring critical events, such as the injection of new data, user interactions, or changes in external sensors, event-triggered retrieval and reasoning processes can be initiated to capture and respond to potential risks and opportunities in real time. Integrating methodologies such as sequence-based event detection or multitask-learning-based intent recognition can facilitate automatic determination of *when* and *how* to trigger retrieval actions. Iteratively optimizing these processes contributes to a more efficient and continuous reasoning loop.

##### Spatiotemporal-Aware Retrieval and Association

Many applications, such as natural disaster monitoring, traffic flow prediction, and inventory management in retail, exhibit strong dependencies on temporal and spatial dimensions. By incorporating spatiotemporal-aware algorithms, retrieval processes can prioritize or emphasize crucial documents according to constraints tied to time and space. This not only enhances timeliness but also improves the purposefulness and accuracy of reasoning.

Furthermore, modeling the evolution of events within spatiotemporal dimensions‚Äîwhen combined with semantic indexing and vector-based retrieval mechanisms in RAG‚Äîcan enable more precise characterization and utilization of complex spatiotemporal dynamics during reasoning.

##### Multimodal Fusion in Retrieval and Reasoning

Multimodal data (e.g., text, images, audio, video, and sensor data) collectively constitute a richer contextual environment, offering critical cues for reasoning tasks. However, existing studies are often limited to the retrieval of single or a few data modalities. Advancing research on multimodal fusion and reasoning mechanisms under the RAG+Reasoning framework has the potential to greatly enhance the system‚Äôs capacity for addressing complex queries.

The research focus lies in constructing cross-modal representation learning and alignment methods, enabling unified representations of the same entities or events across different modalities. During retrieval, confidence scores for each modality can be integrated into a comprehensive ranking process, culminating in multimodal-informed joint decision-making during reasoning. This approach not only improves contextual understanding in complex tasks but also broadens the application scope of RAG technologies in scenarios such as expert systems and autonomous driving, where sensory integration and interpretation are critical.

##### Dynamic Risk Propagation Modeling and Management

The tight coupling of retrieval and reasoning with multi-stage decision-making inevitably introduces risk propagation issues. Misjudgments of high-risk or low-confidence documents during upstream retrieval are often inherited by downstream reasoning processes, amplifying uncertainties and increasing error margins. To address this, dynamic risk modeling should be embedded within retrieval workflows, enabling risk quantification, tracking, and management at multiple stages. When necessary, risk mitigation mechanisms or process rollbacks can be triggered, creating a closed-loop correction framework.

Incorporating strategies for analyzing and managing risk propagation is not only a technical challenge but also a matter of system deployment and standardization. In high-stakes domains such as healthcare and financial risk management, establishing comprehensive safety standards and compliance protocols will be crucial. These protocols should treat dynamic risk propagation management as a critical component of evaluating and iterating knowledge retrieval and reasoning systems.

#### 8.3.3. Application Services

##### Validation of Logical Chain Completeness

While RAG with Reasoning can provide partially interpretable reasoning outputs, verifying the completeness of logical chains remains a challenge. Future research could integrate formal verification or symbolic reasoning techniques to ensure consistency and completeness across key reasoning nodes and intermediate conclusions. This would prevent logical gaps or illogical leaps in reasoning, offering robust regulatory support for high-stakes industries such as law and finance.

##### Intervenable Generation During Reasoning

Contemporary Agentic RAG often operate as ‚Äùblack boxes,‚Äù rendering external interventions nearly impossible during generative reasoning tasks. However, providing mechanisms for human intervention‚Äîsuch as through visualization or interactive interfaces‚Äîcould enable experts or users to perform manual corrections, initialize prior knowledge, or modify interim assumptions during the reasoning process. This would substantially enhance the system‚Äôs flexibility and safety.

Specifically, intervenable generation allows not only post hoc error corrections but also proactive identification and rectification of potential risks or biases at earlier stages. Interactive interpretable reasoning platforms or visualization tools grounded in knowledge graphs could empower users to scrutinize and influence reasoning workflows, thereby enhancing confidence and control in decision-making processes across diverse domains.

##### Risk Decision Interception Firewalls

In closed-loop automated tasks such as algorithmic trading or medical diagnostic decision-making, erroneous reasoning outputs can lead to catastrophic outcomes. To mitigate such risks, the system architecture should incorporate *risk decision interception firewalls*, which perform multidimensional validations at critical reasoning nodes or prior to outputting decisions. When confidence levels or high-risk indicators breach thresholds, these firewalls can block decision outputs or escalate them for stricter human review.

This mechanism serves as a ‚Äúfinal line of defense‚Äù for RAG+Reasoning systems, ensuring decision security in large-scale automated information networks. It also provides a robust foundation for compliance and regulatory auditing, enabling safer deployment in critical applications.

##### Edge-Cloud Collaborative Retrieval and Reasoning

With the rapid development of IoT and 5G technologies, many scenarios demand on-site data collection and preliminary processing on edge devices, followed by high-level retrieval and reasoning tasks on cloud platforms. Efficiently partitioning tasks, allocating resources, and maintaining consistency between indexes and models across the edge-cloud continuum represent critical research directions.

Leveraging techniques such as lightweight model compression, distributed index synchronization, and communication optimization can ensure fast reasoning while maximizing resource utilization. Edge-cloud collaborative solutions are particularly impactful for real-time industrial monitoring and smart city applications, reducing network latency and bandwidth bottlenecks while ensuring accurate and timely inference outputs.

In summary, RAG+Reasoning systems present many untapped opportunities across various dimensions. Further research and practical validation could greatly improve their use in complex, high-risk scenarios while fueling new growth in GenAI.

## 9. Future Trends

In this chapter, we summarize four major trends in technological advancements based on current research, aiming to elucidate and guide the potential future directions of RAG.

### 9.1. The Integration of RAG and Graph

Recent developments have witnessed a growing synergy between RAG systems and graph-based approaches. The intrinsic benefits of graph structures, such as explicit logical relationships and knowledge indexing, have enabled new paradigms for addressing challenges in global reasoning, dynamic data management, and personalized services within RAG systems.

Knowledge Organization.

Graph-structured knowledge organization frameworks offer a powerful alternative to traditional vector-based retrieval methods, excelling in modeling complex relationships and supporting global reasoning. For example, GraphRAG¬†(Edge et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib19)) combines hierarchical graph indexing with community detection to extract entity relationship networks from text corpora, enabling large-scale thematic analysis through hierarchical summaries. Building on this, PIKE¬†(Wang et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib83)) introduces a multi-level heterogeneous knowledge graph that organizes documents, semantic segments, and refined knowledge units into a three-layer hierarchy, improving extraction accuracy and multi-hop reasoning via atomized knowledge construction and task decomposition. For dynamic personalization, EMG-RAG¬†(Wang et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib90)) features a three-layer Editable Memory Graph architecture that structures memory data by ontology classification, subclass, and entity relationships, using reinforcement learning to enable real-time updates and multidimensional queries. Together, these advances leverage graph topologies to address the limitations of conventional RAG systems‚Äîsuch as one-dimensional representation and weak contextual links‚Äîenabling multilevel reasoning from local fact retrieval to global thematic summarization and forming a foundation for interpretable, adaptive RAG systems.

Symbolic Reasoning.
Graph-structured symbolic reasoning methods leverage the multi-hop reasoning power of Knowledge Graphs (KG) to better manage complex semantic and logical relationships. Frameworks like HippoRAG2 and the Think-on-Graph (ToG)¬†(Ma et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib61)) series exemplify this. HippoRAG2¬†(Guti√©rrez et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib29)) builds open knowledge graphs and uses personalized PageRank with a dense-sparse coding approach inspired by brain memory, boosting performance in factual memory, semantic understanding, and multi-hop reasoning. Likewise, ToG-2 combines iterative retrieval of knowledge graphs and documents, using relationship discovery, entity pruning, and context-driven graph searches to integrate fine-grained information from unstructured text, enhancing implicit relationship detection.

Task Planning.
Graph-based task planning in RAG systems enhances complex problem-solving by overcoming the limitations of traditional linear workflows, which struggle with multi-step or multimodal reasoning. These approaches build dynamic knowledge graphs, like Mind Maps, to explicitly model logical dependencies and context. For instance, the Agentic Reasoning¬†(Wu et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib93)) transforms reasoning chains into graph structures for entity extraction, relation identification, and community clustering, enabling dynamic path tracking and optimized retrieval, excelling in tasks like doctoral-level GPQA¬†(Rein et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib68)). Collaborative frameworks such as Co-STORM extend this to multi-agent scenarios, representing queries, tool calls, and knowledge integration as traversable graph nodes to support task decomposition and adaptive reasoning.

Tool Usage and Management.
Graph-enhanced approaches to tool management overcome limitations of traditional dependency modeling by effectively capturing complex relationships like parameter passing, functional collaboration, and resource management. Graph RAG-Tool Fusion¬†(Lumer et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib58)) models tools as graph nodes within a dual-layer architecture of core system APIs and domain-specific tools, encoding direct and indirect dependencies as edges. It uses a two-stage retrieval process: vector-based tool retrieval followed by a graph-based depth-first search to assemble dependency-compliant toolsets.

### 9.2. Multi-Model Collaboration

Multi-model collaboration has emerged as a pivotal strategy for enhancing task complexity handling and domain adaptability in RAG systems¬†(Chen et¬†al., [2025a](https://arxiv.org/html/2504.15909v2#bib.bib14)). By integrating the strengths of different models, this approach achieves optimized performance. For example, the CR-Planner¬†(Li et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib53)) combines general-purpose generation models (e.g., GPT-4) with domain-specific critic models (e.g., Llama-3-8B). This hybrid system dynamically orchestrates subgoal planning and execution evaluation, utilizing MCTS to generate high-quality training data. Similarly, UAR¬†(Cheng et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib15))employs intent-aware and knowledge-requirement classifiers to dynamically trigger retrieval, decoupling lightweight classification tasks from resource-intensive decoding operations of LLMs. Furthermore, Adaptive-RAG ¬†(Jeong et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib42)) deploys small-complexity classifiers to route queries into different levels of processing strategies, balancing response speed for simple queries with deep reasoning for complex ones. These strategies form a closed ‚Äùgeneration-evaluation‚Äùloop, leveraging complementary strengths across models to achieve improved accuracy and computational efficiency.

### 9.3. Multi-Modal Collaboration

The breakthrough in Chain-of-Thought (CoT) capabilities of language models has catalyzed the transition of multimodal reasoning from perceptual-level integration to cognitive-level reasoning, promoting Multimodal Collaborative Reasoning as a key trend¬†(Bi et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib5)) By deeply integrating the logical reasoning capabilities of language models with the spatial-semantic representation of multimodal data, it significantly enhances information synthesis in complex scenarios¬†(Abootorabi et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib3)). For instance, in the medical domain, multimodal RAG systems such as MedCoT¬†(Liu et¬†al., [2024](https://arxiv.org/html/2504.15909v2#bib.bib57)) utilize hierarchical expert systems to integrate CT imaging and pathology reports, enabling knowledge graph validation of diagnostic hypotheses and reducing misdiagnosis risks. Future research will likely focus on robust cross-modal knowledge alignment, progressive knowledge distillation, and adaptive reasoning frameworks.

### 9.4. Customized Reinforcement Learning

The application of reinforcement learning (RL) in RAG systems has become instrumental in improving module coordination and enhancing overall efficiency. Recent studies focus on designing reward mechanisms tailored to the specific needs of RAG systems. Frameworks such as RAG-Gym¬†(Xiong et¬†al., [2025b](https://arxiv.org/html/2504.15909v2#bib.bib97)) and DeepRAG¬†(Guan et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib25)) model reasoning processes using Markov Decision Processes and introduce fine-grained process supervision mechanisms. Additionally, ReARTeR¬†(Lee et¬†al., [2025](https://arxiv.org/html/2504.15909v2#bib.bib50)) and SmartRAG¬†(Gao et¬†al., [2024a](https://arxiv.org/html/2504.15909v2#bib.bib21)) incorporate trust-aware reward strategies and end-to-end policy optimization to achieve superior accuracy and robustness. Opportunities remain for further exploring automated reward modeling with LLMs to facilitate fine-grained supervision.

## 10. Conclusion

This paper has systematically reviewed the synergistic integration of Retrieval-Augmented Generation (RAG) and reasoning, providing a formal definition of reasoning within the RAG framework as a structured, multi-step, goal-driven process that dynamically combines parametric and retrieved knowledge to address complex problems.

We presented a comprehensive taxonomy covering the purposes, collaboration paradigms, and implementation methods underlying RAG+Reasoning systems. The synergy enables more precise retrieval informed by logical analysis and enhances reasoning with contextually relevant, up-to-date knowledge beyond parametric limitations.

While the enhanced reasoning capabilities allow tackling complex knowledge-intensive tasks such as deep research, expert-level problem solving, and domain-specific decision support, practical challenges remain. These include computational and token costs that grow non-linearly, risks of overthinking leading to inefficiency and error propagation, and the lack of evaluation frameworks that effectively assess intermediate reasoning quality alongside final results.

To bridge the gap from theory to real-world application, we proposed practical design guidelines tailored to diverse domains like finance, healthcare, law, and personal assistants, emphasizing adaptability to heterogeneous, dynamic knowledge sources and strict requirements for output reliability and traceability.

Finally, we identified promising directions for future research, including graph-structured knowledge integration, multimodal and multi-model collaborative reasoning architectures, and advanced reinforcement learning techniques for optimizing retrieval-reasoning workflows.

Overall, this work establishes both a theoretical foundation and practical roadmap to drive the development of next-generation RAG+Reasoning systems capable of robust, transparent, and efficient cognition, paving the way for impactful applications across academia and industry.

## References

* (1)
* Abdallah et¬†al. (2025)

  Abdelrahman Abdallah, Bhawna Piryani, Jamshid Mozafari, Mohammed Ali, and Adam Jatowt. 2025.
  Rankify: A comprehensive python toolkit for retrieval, re-ranking, and retrieval-augmented generation.
  *arXiv preprint arXiv:2502.02464* (2025).
* Abootorabi et¬†al. (2025)

  Mohammad¬†Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh¬†Soleymani Baghshah, and Ehsaneddin Asgari. 2025.
  Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation.
  *arXiv preprint arXiv:2502.08826* (2025).
* Asai et¬†al. (2023)

  Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023.
  Self-rag: Learning to retrieve, generate, and critique through self-reflection. In *The Twelfth International Conference on Learning Representations*.
* Bi et¬†al. (2025b)

  Jing Bi, Susan Liang, Xiaofei Zhou, Pinxin Liu, Junjia Guo, Yunlong Tang, Luchuan Song, Chao Huang, Guangyu Sun, Jinxi He, et¬†al. 2025b.
  Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1).
  *arXiv preprint arXiv:2504.03151* (2025).
* Bi et¬†al. (2025a)

  Yuxi Bi, Yunfan Gao, and Haofen Wang. 2025a.
  StePO-Rec: Towards Personalized Outfit Styling Assistant via Knowledge-Guided Multi-Step Reasoning.
  *arXiv preprint arXiv:2504.09915* (2025).
* Chen et¬†al. (2025b)

  Mingyang Chen, Tianpeng Li, Haoze Sun, Yijie Zhou, Chenzheng Zhu, Fan Yang, Zenan Zhou, Weipeng Chen, Haofen Wang, Jeff¬†Z Pan, et¬†al. 2025b.
  Learning to Reason with Search for LLMs via Reinforcement Learning.
  *arXiv preprint arXiv:2503.19470* (2025).
* Chen et¬†al. (2025f)

  Peter¬†Baile Chen, Yi Zhang, Michael Cafarella, and Dan Roth. 2025f.
  Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method.
  *arXiv preprint arXiv:2501.18539* (2025).
* Chen et¬†al. (2025c)

  Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, and Wangxiang Che. 2025c.
  Towards reasoning era: A survey of long chain-of-thought for reasoning large language models.
  *arXiv preprint arXiv:2503.09567* (2025).
* Chen et¬†al. (2023)

  Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia. 2023.
  Theoremqa: A theorem-driven question answering dataset.
  *arXiv preprint arXiv:2305.12524* (2023).
* Chen et¬†al. (2024)

  Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, et¬†al. 2024.
  Do not think that much for 2+ 3=? on the overthinking of o1-like llms.
  *arXiv preprint arXiv:2412.21187* (2024).
* Chen et¬†al. (2025d)

  Yixiang Chen, Penglei Sun, Xiang Li, and Xiaowen Chu. 2025d.
  MRD-RAG: Enhancing Medical Diagnosis with Multi-Round Retrieval-Augmented Generation.
  *arXiv preprint arXiv:2504.07724* (2025).
* Chen et¬†al. (2025e)

  Yiqun Chen, Lingyong Yan, Weiwei Sun, Xinyu Ma, Yi Zhang, Shuaiqiang Wang, Dawei Yin, Yiming Yang, and Jiaxin Mao. 2025e.
  Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning.
  *arXiv preprint arXiv:2501.15228* (2025).
* Chen et¬†al. (2025a)

  Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, and Philip¬†S Yu. 2025a.
  Harnessing Multiple Large Language Models: A Survey on LLM Ensemble.
  *arXiv preprint arXiv:2502.18036* (2025).
* Cheng et¬†al. (2024)

  Qinyuan Cheng, Xiaonan Li, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, and Xipeng Qiu. 2024.
  Unified active retrieval for retrieval augmented generation.
  *arXiv preprint arXiv:2406.12534* (2024).
* Cuadron et¬†al. (2025)

  Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis¬†Gaspar Schroeder, Tian Xia, Huanzhi Mao, et¬†al. 2025.
  The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks.
  *arXiv preprint arXiv:2502.08235* (2025).
* Dao and Le (2025)

  Alan Dao and Thinh Le. 2025.
  ReZero: Enhancing LLM search ability by trying one-more-time.
  arXiv:2504.11001¬†[cs.CL]
  <https://arxiv.org/abs/2504.11001>
* Dettmers et¬†al. (2023)

  Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.
  Qlora: Efficient finetuning of quantized llms.
  *Advances in neural information processing systems* 36 (2023), 10088‚Äì10115.
* Edge et¬†al. (2024)

  Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert¬†Osazuwa Ness, and Jonathan Larson. 2024.
  From local to global: A graph rag approach to query-focused summarization.
  *arXiv preprint arXiv:2404.16130* (2024).
* Fan et¬†al. (2025)

  Chenrui Fan, Ming Li, Lichao Sun, and Tianyi Zhou. 2025.
  Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?
  *arXiv preprint arXiv:2504.06514* (2025).
* Gao et¬†al. (2024a)

  Jingsheng Gao, Linxu Li, Weiyuan Li, Yuzhuo Fu, and Bin Dai. 2024a.
  SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback.
  *arXiv preprint arXiv:2410.18141* (2024).
* Gao et¬†al. (2023)

  Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023.
  Retrieval-augmented generation for large language models: A survey.
  *arXiv preprint arXiv:2312.10997* (2023).
* Gao et¬†al. (2024b)

  Yunfan Gao, Yun Xiong, Meng Wang, and Haofen Wang. 2024b.
  Modular rag: Transforming rag systems into lego-like reconfigurable frameworks.
  *arXiv preprint arXiv:2407.21059* (2024).
* Gao et¬†al. (2025)

  Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, and S¬†Kevin Zhou. 2025.
  FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs.
  *arXiv preprint arXiv:2501.09957* (2025).
* Guan et¬†al. (2025)

  Xinyan Guan, Jiali Zeng, Fandong Meng, Chunlei Xin, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, and Jie Zhou. 2025.
  DeepRAG: Thinking to Retrieval Step by Step for Large Language Models.
  *arXiv preprint arXiv:2502.01142* (2025).
* Guo et¬†al. (2025a)

  Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et¬†al. 2025a.
  Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
  *arXiv preprint arXiv:2501.12948* (2025).
* Guo et¬†al. (2025b)

  Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et¬†al. 2025b.
  Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
  *arXiv preprint arXiv:2501.12948* (2025).
* Guo et¬†al. (2024)

  Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, and Chao Huang. 2024.
  Lightrag: Simple and fast retrieval-augmented generation.
  (2024).
* Guti√©rrez et¬†al. (2025)

  Bernal¬†Jim√©nez Guti√©rrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, and Yu Su. 2025.
  From RAG to Memory: Non-Parametric Continual Learning for Large Language Models.
  *arXiv preprint arXiv:2502.14802* (2025).
* He et¬†al. (2024)

  Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen¬†Leng Thai, Junhao Shen, Jinyi Hu, Xu Han, Yujie Huang, Yuxiang Zhang, et¬†al. 2024.
  Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems.
  *arXiv preprint arXiv:2402.14008* (2024).
* He et¬†al. (2025)

  Yancheng He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge Zhang, Zhongyuan Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, et¬†al. 2025.
  Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?
  *arXiv preprint arXiv:2502.19361* (2025).
* Ho et¬†al. (2020)

  Xanh Ho, Anh-Khoa¬†Duong Nguyen, Saku Sugawara, and Akiko Aizawa. 2020.
  Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps.
  *arXiv preprint arXiv:2011.01060* (2020).
* Hong et¬†al. (2025)

  Yubin Hong, Chaofan Li, Jingyi Zhang, and Yingxia Shao. 2025.
  FG-RAG: Enhancing Query-Focused Summarization with Context-Aware Fine-Grained Graph RAG.
  *arXiv preprint arXiv:2504.07103* (2025).
* Hongjin et¬†al. (2024)

  SU Hongjin, Howard Yen, Mengzhou Xia, Weijia Shi, Niklas Muennighoff, Han-yu Wang, Liu Haisu, Quan Shi, Zachary¬†S Siegel, Michael Tang, et¬†al. 2024.
  BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval. In *The Thirteenth International Conference on Learning Representations*.
* Hsu et¬†al. (2024)

  Sheryl Hsu, Omar Khattab, Chelsea Finn, and Archit Sharma. 2024.
  Grounding by trying: Llms with reinforcement learning-enhanced retrieval.
  *arXiv preprint arXiv:2410.23214* (2024).
* Hu (2025)

  Jian Hu. 2025.
  REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models.
  *arXiv preprint arXiv:2501.03262* (2025).
* Hu et¬†al. (2025)

  Yunhai Hu, Yilun Zhao, Chen Zhao, and Arman Cohan. 2025.
  MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search.
  *arXiv preprint arXiv:2503.20757* (2025).
* Huot et¬†al. (2024)

  Fantine Huot, Reinald¬†Kim Amplayo, Jennimaria Palomaki, Alice¬†Shoshana Jakobovits, Elizabeth Clark, and Mirella Lapata. 2024.
  Agents‚Äô Room: Narrative Generation through Multi-step Collaboration.
  *arXiv preprint arXiv:2410.02603* (2024).
* Islam et¬†al. (2024)

  Shayekh¬†Bin Islam, Md¬†Asib Rahman, KSM Hossain, Enamul Hoque, Shafiq Joty, and Md¬†Rizwan Parvez. 2024.
  Open-rag: Enhanced retrieval-augmented reasoning with open-source large language models.
  *arXiv preprint arXiv:2410.01782* (2024).
* Jaech et¬†al. (2024)

  Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et¬†al. 2024.
  Openai o1 system card.
  *arXiv preprint arXiv:2412.16720* (2024).
* Jain et¬†al. (2024)

  Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. 2024.
  Livecodebench: Holistic and contamination free evaluation of large language models for code.
  *arXiv preprint arXiv:2403.07974* (2024).
* Jeong et¬†al. (2024)

  Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung¬†Ju Hwang, and Jong¬†C Park. 2024.
  Adaptive-rag: Learning to adapt retrieval-augmented large language models through question complexity.
  *arXiv preprint arXiv:2403.14403* (2024).
* Jiang (2025)

  Pengcheng Jiang. 2025.
  DeepRetrieval: Powerful Query Generation for Information Retrieval with Reinforcement Learning.
  *arXiv preprint arXiv:2503.00223* (2025).
* Jiang et¬†al. (2024a)

  Yucheng Jiang, Yijia Shao, Dekun Ma, Sina¬†J Semnani, and Monica¬†S Lam. 2024a.
  Into the unknown unknowns: Engaged human learning through participation in language model agent conversations.
  *arXiv preprint arXiv:2408.15232* (2024).
* Jiang et¬†al. (2024b)

  Yucheng Jiang, Yijia Shao, Dekun Ma, Sina¬†J Semnani, and Monica¬†S Lam. 2024b.
  Into the unknown unknowns: Engaged human learning through participation in language model agent conversations.
  *arXiv preprint arXiv:2408.15232* (2024).
* Jiang et¬†al. (2023)

  Zhengbao Jiang, Frank¬†F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.
  Active retrieval augmented generation. In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*. 7969‚Äì7992.
* Joshi et¬†al. (2024)

  Ashutosh Joshi, Sheikh¬†Muhammad Sarwar, Samarth Varshney, Sreyashi Nag, Shrivats Agrawal, and Juhi Naik. 2024.
  REAPER: Reasoning based retrieval planning for complex RAG systems. In *Proceedings of the 33rd ACM International Conference on Information and Knowledge Management*. 4621‚Äì4628.
* Kwiatkowski et¬†al. (2019)

  Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et¬†al. 2019.
  Natural questions: a benchmark for question answering research.
  *Transactions of the Association for Computational Linguistics* 7 (2019), 453‚Äì466.
* Lee et¬†al. (2024)

  Myeonghwa Lee, Seonho An, and Min-Soo Kim. 2024.
  PlanRAG: A plan-then-retrieval augmented generation for generative large language models as decision makers. In *Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)*. 6537‚Äì6555.
* Lee et¬†al. (2025)

  Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, and Juanzi Li. 2025.
  ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation.
  *arXiv preprint arXiv:2503.21729* (2025).
* Li et¬†al. (2024c)

  Jinzheng Li, Jingshu Zhang, Hongguang Li, and Yiqing Shen. 2024c.
  An Agent Framework for Real-Time Financial Information Searching with Large Language Models.
  *arXiv preprint arXiv:2502.15684* (2024).
* Li et¬†al. (2025a)

  Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng Dou. 2025a.
  Search-o1: Agentic search-enhanced large reasoning models.
  *arXiv preprint arXiv:2501.05366* (2025).
* Li et¬†al. (2024a)

  Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, and Lidong Bing. 2024a.
  Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks.
  *arXiv preprint arXiv:2410.01428* (2024).
* Li et¬†al. (2024b)

  Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, and Lidong Bing. 2024b.
  Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks.
  *arXiv preprint arXiv:2410.01428* (2024).
* Li et¬†al. (2025b)

  Zhuoqun Li, Haiyang Yu, Xuanang Chen, Hongyu Lin, Yaojie Lu, Fei Huang, Xianpei Han, Yongbin Li, and Le Sun. 2025b.
  Deepsolution: Boosting complex engineering solution design via tree-based exploration and bi-point thinking.
  *arXiv preprint arXiv:2502.20730* (2025).
* Lightman et¬†al. (2023)

  Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023.
  Let‚Äôs verify step by step. In *The Twelfth International Conference on Learning Representations*.
* Liu et¬†al. (2024)

  Jiaxiang Liu, Yuan Wang, Jiawei Du, Joey¬†Tianyi Zhou, and Zuozhu Liu. 2024.
  Medcot: Medical chain of thought via hierarchical expert.
  *arXiv preprint arXiv:2412.13736* (2024).
* Lumer et¬†al. (2025)

  Elias Lumer, Pradeep¬†Honaganahalli Basavaraju, Myles Mason, James¬†A Burke, and Vamse¬†Kumar Subbiah. 2025.
  Graph RAG-Tool Fusion.
  *arXiv preprint arXiv:2502.07223* (2025).
* Luo et¬†al. (2025)

  Haoran Luo, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu¬†Anh Tuan, et¬†al. 2025.
  KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search.
  *arXiv preprint arXiv:2501.18922* (2025).
* Lyu et¬†al. (2025)

  Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang, Hao Wu, Huanyong Liu, Tong Xu, and Enhong Chen. 2025.
  Crud-rag: A comprehensive chinese benchmark for retrieval-augmented generation of large language models.
  *ACM Transactions on Information Systems* 43, 2 (2025), 1‚Äì32.
* Ma et¬†al. (2024)

  Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Cehao Yang, Jiaxin Mao, and Jian Guo. 2024.
  Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning with Knowledge-guided Retrieval Augmented Generation.
  *arXiv preprint arXiv:2407.10805* (2024).
* Ma et¬†al. (2023)

  Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023.
  Query rewriting in retrieval-augmented large language models. In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*. 5303‚Äì5315.
* Mialon et¬†al. (2023)

  Gr√©goire Mialon, Cl√©mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023.
  Gaia: a benchmark for general ai assistants. In *The Twelfth International Conference on Learning Representations*.
* Muennighoff et¬†al. (2025)

  Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang¬†Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Cand√®s, and Tatsunori Hashimoto. 2025.
  s1: Simple test-time scaling.
  *arXiv preprint arXiv:2501.19393* (2025).
* Patil et¬†al. (2024)

  Shishir¬†G Patil, Tianjun Zhang, Xin Wang, and Joseph¬†E Gonzalez. 2024.
  Gorilla: Large language model connected with massive apis.
  *Advances in Neural Information Processing Systems* 37 (2024), 126544‚Äì126565.
* Petroni et¬†al. (2020)

  Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De¬†Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, et¬†al. 2020.
  KILT: a benchmark for knowledge intensive language tasks.
  *arXiv preprint arXiv:2009.02252* (2020).
* Pezeshkpour and Hruschka (2025)

  Pouya Pezeshkpour and Estevam Hruschka. 2025.
  Insight-RAG: Enhancing LLMs with Insight-Driven Augmentation.
  *arXiv preprint arXiv:2504.00187* (2025).
* Rein et¬†al. (2024)

  David Rein, Betty¬†Li Hou, Asa¬†Cooper Stickland, Jackson Petty, Richard¬†Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel¬†R Bowman. 2024.
  Gpqa: A graduate-level google-proof q&a benchmark. In *First Conference on Language Modeling*.
* Shao et¬†al. (2023)

  Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023.
  Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.
  *arXiv preprint arXiv:2305.15294* (2023).
* Shao et¬†al. (2024)

  Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et¬†al. 2024.
  Deepseekmath: Pushing the limits of mathematical reasoning in open language models.
  *arXiv preprint arXiv:2402.03300* (2024).
* Shi et¬†al. (2024a)

  Quan Shi, Michael Tang, Karthik Narasimhan, and Shunyu Yao. 2024a.
  Can Language Models Solve Olympiad Programming?
  *arXiv preprint arXiv:2404.10952* (2024).
* Shi et¬†al. (2024b)

  Quan Shi, Michael Tang, Karthik Narasimhan, and Shunyu Yao. 2024b.
  Can Language Models Solve Olympiad Programming?
  *arXiv preprint arXiv:2404.10952* (2024).
* Song et¬†al. (2025)

  Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne¬†Xin Zhao, Lei Fang, and Ji-Rong Wen. 2025.
  R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning.
  *arXiv preprint arXiv:2503.05592* (2025).
* Srinivas and Runkana (2025)

  Sakhinana¬†Sagar Srinivas and Venkataramana Runkana. 2025.
  Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding.
  *arXiv preprint arXiv:2504.01281* (2025).
* Sui et¬†al. (2025)

  Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Hanjie Chen, Xia Hu, et¬†al. 2025.
  Stop overthinking: A survey on efficient reasoning for large language models.
  *arXiv preprint arXiv:2503.16419* (2025).
* Sun et¬†al. (2025)

  Zhongxiang Sun, Qipeng Wang, Weijie Yu, Xiaoxue Zang, Kai Zheng, Jun Xu, Xiao Zhang, Song Yang, and Han Li. 2025.
  ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding.
  *arXiv preprint arXiv:2501.07861* (2025).
* Talmor and Berant (2018)

  Alon Talmor and Jonathan Berant. 2018.
  The web as a knowledge-base for answering complex questions.
  *arXiv preprint arXiv:1803.06643* (2018).
* Tran et¬†al. (2024)

  Hieu Tran, Zonghai Yao, Junda Wang, Yifan Zhang, Zhichao Yang, and Hong Yu. 2024.
  RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models.
  *arXiv preprint arXiv:2412.02830* (2024).
* Trivedi et¬†al. (2022a)

  Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022a.
  Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.
  *arXiv preprint arXiv:2212.10509* (2022).
* Trivedi et¬†al. (2022b)

  Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022b.
  MuSiQue: Multihop Questions via Single-hop Question Composition.
  *Transactions of the Association for Computational Linguistics* 10 (2022), 539‚Äì554.
* Vu et¬†al. (2023)

  Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le, et¬†al. 2023.
  Freshllms: Refreshing large language models with search engine augmentation.
  *arXiv preprint arXiv:2310.03214* (2023).
* Wang et¬†al. (2025c)

  Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, and Dong Yu. 2025c.
  Don‚Äôt Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls.
  *arXiv preprint arXiv:2502.11183* (2025).
* Wang et¬†al. (2025b)

  Jinyu Wang, Jingjing Fu, Rui Wang, Lei Song, and Jiang Bian. 2025b.
  PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation.
  *arXiv preprint arXiv:2501.11551* (2025).
* Wang et¬†al. (2025a)

  Liang Wang, Haonan Chen, Nan Yang, Xiaolong Huang, Zhicheng Dou, and Furu Wei. 2025a.
  Chain-of-Retrieval Augmented Generation.
  *arXiv preprint arXiv:2501.14342* (2025).
* Wang et¬†al. (2024e)

  Ruobing Wang, Daren Zha, Shi Yu, Qingfei Zhao, Yuxuan Chen, Yixuan Wang, Shuo Wang, Yukun Yan, Zhenghao Liu, Xu Han, et¬†al. 2024e.
  Retriever-and-Memory: Towards Adaptive Note-Enhanced Retrieval-Augmented Generation.
  *arXiv preprint arXiv:2410.08821* (2024).
* Wang et¬†al. (2024b)

  Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, and Haofen Wang. 2024b.
  Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT. In *Proceedings of the 32nd ACM International Conference on Multimedia*. 4757‚Äì4765.
* Wang et¬†al. (2024c)

  Shuting Wang, Jiongnan Liu, Shiren Song, Jiehan Cheng, Yuqi Fu, Peidong Guo, Kun Fang, Yutao Zhu, and Zhicheng Dou. 2024c.
  Domainrag: A chinese benchmark for evaluating domain-specific retrieval-augmented generation.
  *arXiv preprint arXiv:2406.05654* (2024).
* Wang et¬†al. (2023)

  Xidong Wang, Guiming¬†Hardy Chen, Dingjie Song, Zhiyi Zhang, Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, et¬†al. 2023.
  Cmb: A comprehensive medical benchmark in chinese.
  *arXiv preprint arXiv:2308.08833* (2023).
* Wang et¬†al. (2024d)

  Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, et¬†al. 2024d.
  Searching for best practices in retrieval-augmented generation.
  *arXiv preprint arXiv:2407.01219* (2024).
* Wang et¬†al. (2024a)

  Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, and Wei Shi. 2024a.
  Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs.
  *arXiv preprint arXiv:2409.19401* (2024).
* Wang et¬†al. (2025d)

  Zhengren Wang, Jiayang Yu, Dongsheng Ma, Zhe Chen, Yu Wang, Zhiyu Li, Feiyu Xiong, Yanfeng Wang, Linpeng Tang, Wentao Zhang, et¬†al. 2025d.
  RARE: Retrieval-Augmented Reasoning Modeling.
  *arXiv preprint arXiv:2503.23513* (2025).
* Weng et¬†al. (2024)

  Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, and Linyi Yang. 2024.
  Cycleresearcher: Improving automated research via automated review.
  *arXiv preprint arXiv:2411.00816* (2024).
* Wu et¬†al. (2025b)

  Junde Wu, Jiayuan Zhu, and Yuyuan Liu. 2025b.
  Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research.
  *arXiv preprint arXiv:2502.04644* (2025).
* Wu et¬†al. (2025a)

  Wenjie Wu, Yongcheng Jing, Yingjie Wang, Wenbin Hu, and Dacheng Tao. 2025a.
  Graph-augmented reasoning: Evolving step-by-step knowledge graph retrieval for llm reasoning.
  *arXiv preprint arXiv:2503.01642* (2025).
* Xi et¬†al. (2025)

  Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, and Huajun Chen. 2025.
  OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking.
  *arXiv preprint arXiv:2501.09751* (2025).
* Xiao et¬†al. (2025)

  Liang Xiao, Wen Dai, Shuai Chen, Bin Qin, Chongyang Shi, Haopeng Jing, and Tianyu Guo. 2025.
  Retrieval-Augmented Generation by Evidence Retroactivity in LLMs.
  *arXiv preprint arXiv:2501.05475* (2025).
* Xiong et¬†al. (2025b)

  Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, et¬†al. 2025b.
  Rag-gym: Optimizing reasoning and search agents with process supervision.
  *arXiv preprint arXiv:2502.13957* (2025).
* Xiong et¬†al. (2025c)

  Guanming Xiong, Haochen Li, and Wen Zhao. 2025c.
  MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering.
  *arXiv preprint arXiv:2502.13428* (2025).
* Xiong et¬†al. (2025a)

  Ruibin Xiong, Yimeng Chen, Dmitrii Khizbullin, and J√ºrgen Schmidhuber. 2025a.
  Beyond Outlining: Heterogeneous Recursive Planning for Adaptive Long-form Writing with Language Models.
  *arXiv preprint arXiv:2503.08275* (2025).
* Xu et¬†al. (2025)

  Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, et¬†al. 2025.
  Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models.
  *arXiv preprint arXiv:2501.09686* (2025).
* Xu et¬†al. (2024)

  Zhipeng Xu, Zhenghao Liu, Yukun Yan, Shuo Wang, Shi Yu, Zheni Zeng, Chaojun Xiao, Zhiyuan Liu, Ge Yu, and Chenyan Xiong. 2024.
  ActiveRAG: Autonomously Knowledge Assimilation and Accommodation through Retrieval-Augmented Agents.
  *arXiv preprint arXiv:2402.13547* (2024).
* Yan et¬†al. (2025)

  Ruiran Yan, Zheng Liu, and Defu Lian. 2025.
  O1 embedder: Let retrievers think before action.
  *arXiv preprint arXiv:2502.07555* (2025).
* Zhang et¬†al. (2024)

  Xiaoming Zhang, Ming Wang, Xiaocui Yang, Daling Wang, Shi Feng, and Yifei Zhang. 2024.
  Hierarchical Retrieval-Augmented Generation Model with Rethink for Multi-hop Question Answering.
  *arXiv preprint arXiv:2408.11875* (2024).
* Zhang et¬†al. (2025)

  Zhuocheng Zhang, Yang Feng, and Min Zhang. 2025.
  LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic Planning over Rewriting Augmented Searchers.
  *arXiv preprint arXiv:2502.18139* (2025).
* Zhao et¬†al. (2024)

  Bowen Zhao, Zander Brumbaugh, Yizhong Wang, Hannaneh Hajishirzi, and Noah¬†A Smith. 2024.
  Set the clock: Temporal alignment of pretrained language models.
  *arXiv preprint arXiv:2402.16797* (2024).
* Zhao et¬†al. (2025)

  Xuejiao Zhao, Siyan Liu, Su-Yin Yang, and Chunyan Miao. 2025.
  MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot.
  *arXiv preprint arXiv:2502.04413* (2025).
* Zheng et¬†al. (2025)

  Yuxiang Zheng, Dayuan Fu, Xiangkun Hu, Xiaojie Cai, Lyumanshan Ye, Pengrui Lu, and Pengfei Liu. 2025.
  DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments.
  *arXiv preprint arXiv:2504.03160* (2025).
* Zhong et¬†al. (2025)

  Yijie Zhong, Feifan Wu, Mengying Guo, Xiaolian Zhang, Meng Wang, and Haofen Wang. 2025.
  Meta-PKE: Memory-Enhanced Task-Adaptive Personal Knowledge Extraction in Daily Life.
  *Information Processing & Management* 62, 4 (2025), 104097.
* Zhou et¬†al. (2024)

  Yujia Zhou, Zheng Liu, Jiajie Jin, Jian-Yun Nie, and Zhicheng Dou. 2024.
  Metacognitive retrieval-augmented large language models. In *Proceedings of the ACM Web Conference 2024*. 1453‚Äì1463.
* Zhu et¬†al. (2025b)

  Jiachen Zhu, Congmin Zheng, Jianghao Lin, Kounianhua Du, Ying Wen, Yong Yu, Jun Wang, and Weinan Zhang. 2025b.
  Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning.
  *arXiv preprint arXiv:2502.14361* (2025).
* Zhu et¬†al. (2025a)

  Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, and Wei Hu. 2025a.
  Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering.
  *arXiv preprint arXiv:2502.14245* (2025).

## Appendix

### Agentic RAG Symbol Reference System

The following table presents a complete symbol reference system with formally defined mathematical notations for all core concepts.

Table 3. Basic states and system components

| Symbol | Type | Definition & Description |
| --- | --- | --- |
| St=(Ht,Ct)subscriptùëÜùë°subscriptùêªùë°subscriptùê∂ùë°S\_{t}=(H\_{t},C\_{t})italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT = ( italic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) | Composite state | Complete system state at timestep tùë°titalic\_t, containing historical information and context vectors |
| Htsubscriptùêªùë°H\_{t}italic\_H start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | Vector/Set | Historical information aggregation |
| Ctsubscriptùê∂ùë°C\_{t}italic\_C start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | Vector | Contextual embedding vectors |
| qtsubscriptùëûùë°q\_{t}italic\_q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | Vector | Vector representation of current query at step tùë°titalic\_t |
| ùí¶tsubscriptùí¶ùë°\mathcal{K}\_{t}caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | Set | Dynamic knowledge base (Initialized as ùí¶0=‚àÖsubscriptùí¶0\mathcal{K}\_{0}=\emptysetcaligraphic\_K start\_POSTSUBSCRIPT 0 end\_POSTSUBSCRIPT = ‚àÖ) |

Table 4. Action space and policy definitions

| Symbol | Type | Definition & Description |
| --- | --- | --- |
| ùíúùíú\mathcal{A}caligraphic\_A | Set | Action space, e.g., ùíú={Retrieve,Generate,Verify,Terminate}ùíúRetrieveGenerateVerifyTerminate\mathcal{A}=\{\text{Retrieve},\text{Generate},\text{Verify},\text{Terminate}\}caligraphic\_A = { Retrieve , Generate , Verify , Terminate } |
| atsubscriptùëéùë°a\_{t}italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | Scalar | Selected action at timestep tùë°titalic\_t (at‚ààùíúsubscriptùëéùë°ùíúa\_{t}\in\mathcal{A}italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚àà caligraphic\_A) |
| œÄ‚Å¢(St;Œò)ùúã  subscriptùëÜùë°Œò\pi(S\_{t};\Theta)italic\_œÄ ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ; roman\_Œò ) | Function | Policy function with parameters ŒòŒò\Thetaroman\_Œò, mapping states to action probability distributions (œÄ:ùíÆ‚ÜíŒî‚Å¢(ùíú):ùúã‚ÜíùíÆŒîùíú\pi:\mathcal{S}\to\Delta(\mathcal{A})italic\_œÄ : caligraphic\_S ‚Üí roman\_Œî ( caligraphic\_A )) |

Table 5. State transition mechanisms

| Symbol | Type | Definition & Description |
| --- | --- | --- |
| Œ¥ùõø\deltaitalic\_Œ¥ | Function | State transition function, update rule St+1=Œ¥‚Å¢(St,‚ãÖ)subscriptùëÜùë°1ùõøsubscriptùëÜùë°‚ãÖS\_{t+1}=\delta(S\_{t},\cdot)italic\_S start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = italic\_Œ¥ ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , ‚ãÖ ) |
| ùíØasubscriptùíØùëé\mathcal{T}\_{a}caligraphic\_T start\_POSTSUBSCRIPT italic\_a end\_POSTSUBSCRIPT | Function | Low-level state transition operation for action aùëéaitalic\_a (e.g., ùíØRetrievesubscriptùíØRetrieve\mathcal{T}\_{\text{Retrieve}}caligraphic\_T start\_POSTSUBSCRIPT Retrieve end\_POSTSUBSCRIPT denotes retrieval) |
| ‚Ñõ‚Ñõ\mathcal{R}caligraphic\_R | Function | Retrieval function, ‚Ñõ‚Å¢(St)‚ÑõsubscriptùëÜùë°\mathcal{R}(S\_{t})caligraphic\_R ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ) returns retrieval results |
| ‚àò\circ‚àò | Operator | Function composition operator (e.g., f‚àòg‚Å¢(x)=f‚Å¢(g‚Å¢(x))ùëìùëîùë•ùëìùëîùë•f\circ g(x)=f(g(x))italic\_f ‚àò italic\_g ( italic\_x ) = italic\_f ( italic\_g ( italic\_x ) )) |

Table 6. Feedback and optimization components

| Symbol | Type | Definition & Description |
| --- | --- | --- |
| R‚Å¢(St,at,St+1)ùëÖsubscriptùëÜùë°subscriptùëéùë°subscriptùëÜùë°1R(S\_{t},a\_{t},S\_{t+1})italic\_R ( italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_S start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ) | Function | Reward function, outputs reward value rtsubscriptùëüùë°r\_{t}italic\_r start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT |
| ùïÄ‚Å¢(‚ãÖ)ùïÄ‚ãÖ\mathbb{I}(\cdot)blackboard\_I ( ‚ãÖ ) | Function | Indicator function (returns 1 if condition holds, else 0) |
| ‚àáŒ∏J‚Å¢(Œ∏)subscript‚àáùúÉùêΩùúÉ\nabla\_{\theta}J(\theta)‚àá start\_POSTSUBSCRIPT italic\_Œ∏ end\_POSTSUBSCRIPT italic\_J ( italic\_Œ∏ ) | Operator | Policy gradient for optimizing policy parameters ŒòŒò\Thetaroman\_Œò |
| Œ≥ùõæ\gammaitalic\_Œ≥ | Scalar | Discount factor for cumulative reward calculation |

Table 7. Submodule-specific symbols

| Symbol | Type | Definition & Description |
| --- | --- | --- |
| Œ®Œ®\Psiroman\_Œ® | Function | Reasoning function, generates intermediate reasoning results |
| ŒìŒì\Gammaroman\_Œì | Function | Decision function, produces final outputs (e.g., answers) |
| œà‚Å¢(‚ãÖ)ùúì‚ãÖ\psi(\cdot)italic\_œà ( ‚ãÖ ) | Function | Branch selector for reflective reasoning path selection |
| œï‚Å¢(‚ãÖ)italic-œï‚ãÖ\phi(\cdot)italic\_œï ( ‚ãÖ ) | Function | Confidence mapping function (evaluations to scalar confidence) |
| œÑùúè\tauitalic\_œÑ | Scalar | Decision threshold for triggering specific operations (e.g., verification/termination) |

### Symbol Design Hierarchy

* ‚Ä¢

  Base states/actions: Standard font (St,at
  subscriptùëÜùë°subscriptùëéùë°S\_{t},a\_{t}italic\_S start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT)
* ‚Ä¢

  Sets/spaces: Calligraphic font (ùíú,ùí¶t
  ùíúsubscriptùí¶ùë°\mathcal{A},\mathcal{K}\_{t}caligraphic\_A , caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT)
* ‚Ä¢

  Core mechanism functions: Uppercase Greek (Œ®,Œì
  Œ®Œì\Psi,\Gammaroman\_Œ® , roman\_Œì)
* ‚Ä¢

  Operational functions: Calligraphic font (‚Ñõ,ùíØa
  ‚ÑõsubscriptùíØùëé\mathcal{R},\mathcal{T}\_{a}caligraphic\_R , caligraphic\_T start\_POSTSUBSCRIPT italic\_a end\_POSTSUBSCRIPT)
* ‚Ä¢

  Auxiliary functions: Lowercase Greek (Œ¥,œï
  ùõøitalic-œï\delta,\phiitalic\_Œ¥ , italic\_œï) or blackboard bold (ùïÄùïÄ\mathbb{I}blackboard\_I)

### Annotation Guidelines

* ‚Ä¢

  Symbol disambiguation:

  + ‚Äì

    ‚Ñõ‚Ñõ\mathcal{R}caligraphic\_R strictly denotes retrieval function (vs. reward RùëÖRitalic\_R)
  + ‚Äì

    Œ¥ùõø\deltaitalic\_Œ¥ exclusively represents state transitions (vs. branch selector œàùúì\psiitalic\_œà)
* ‚Ä¢

  Dynamic extensions:

  + ‚Äì

    Action space ùíúùíú\mathcal{A}caligraphic\_A and knowledge base ùí¶tsubscriptùí¶ùë°\mathcal{K}\_{t}caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT support incremental updates:
    ùí¶t+1=ùí¶t‚äïRetrieve‚Å¢(qt)subscriptùí¶ùë°1direct-sumsubscriptùí¶ùë°Retrievesubscriptùëûùë°\mathcal{K}\_{t+1}=\mathcal{K}\_{t}\oplus\text{Retrieve}(q\_{t})caligraphic\_K start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT = caligraphic\_K start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ‚äï Retrieve ( italic\_q start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT )

Generated on Thu Apr 24 12:39:21 2025 by [LaTeXML![Mascot Sammy](data:image/png;base64...)](http://dlmf.nist.gov/LaTeXML/)